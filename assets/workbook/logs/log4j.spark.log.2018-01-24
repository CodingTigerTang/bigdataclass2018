18/01/24 16:08:05 INFO SparkContext: Running Spark version 2.1.0
18/01/24 16:08:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/01/24 16:08:05 INFO SecurityManager: Changing view acls to: rstudio-user
18/01/24 16:08:05 INFO SecurityManager: Changing modify acls to: rstudio-user
18/01/24 16:08:05 INFO SecurityManager: Changing view acls groups to: 
18/01/24 16:08:05 INFO SecurityManager: Changing modify acls groups to: 
18/01/24 16:08:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rstudio-user); groups with view permissions: Set(); users  with modify permissions: Set(rstudio-user); groups with modify permissions: Set()
18/01/24 16:08:05 INFO Utils: Successfully started service 'sparkDriver' on port 39737.
18/01/24 16:08:05 INFO SparkEnv: Registering MapOutputTracker
18/01/24 16:08:05 INFO SparkEnv: Registering BlockManagerMaster
18/01/24 16:08:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/01/24 16:08:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/01/24 16:08:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ad244274-0425-47af-8db0-561f8843d638
18/01/24 16:08:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/01/24 16:08:05 INFO SparkEnv: Registering OutputCommitCoordinator
18/01/24 16:08:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/01/24 16:08:06 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/01/24 16:08:06 INFO SparkContext: Added JAR file:/home/rstudio-user/R/x86_64-pc-linux-gnu-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:39737/jars/sparklyr-2.1-2.11.jar with timestamp 1516810086069
18/01/24 16:08:06 INFO Executor: Starting executor ID driver on host localhost
18/01/24 16:08:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33521.
18/01/24 16:08:06 INFO NettyBlockTransferService: Server created on 127.0.0.1:33521
18/01/24 16:08:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/01/24 16:08:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 33521, None)
18/01/24 16:08:06 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:33521 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 33521, None)
18/01/24 16:08:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 33521, None)
18/01/24 16:08:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 33521, None)
18/01/24 16:08:09 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/01/24 16:08:09 INFO SharedState: Warehouse path is 'file:/home/rstudio-user/bigdataclass2018/workbook/spark-warehouse'.
18/01/24 16:08:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/01/24 16:08:09 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/01/24 16:08:09 INFO ObjectStore: ObjectStore, initialize called
18/01/24 16:08:09 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/01/24 16:08:09 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/01/24 16:08:11 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/01/24 16:08:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 16:08:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 16:08:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 16:08:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 16:08:12 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/01/24 16:08:12 INFO ObjectStore: Initialized ObjectStore
18/01/24 16:08:12 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/01/24 16:08:12 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/01/24 16:08:13 INFO HiveMetaStore: Added admin role in metastore
18/01/24 16:08:13 INFO HiveMetaStore: Added public role in metastore
18/01/24 16:08:13 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/01/24 16:08:13 INFO HiveMetaStore: 0: get_all_databases
18/01/24 16:08:13 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_all_databases	
18/01/24 16:08:13 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/01/24 16:08:13 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/01/24 16:08:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 16:08:13 INFO SessionState: Created local directory: /tmp/b33140af-a6ad-4709-8c8c-a0325e9c9129_resources
18/01/24 16:08:13 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio-user/b33140af-a6ad-4709-8c8c-a0325e9c9129
18/01/24 16:08:13 INFO SessionState: Created local directory: /tmp/rstudio-user/b33140af-a6ad-4709-8c8c-a0325e9c9129
18/01/24 16:08:13 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio-user/b33140af-a6ad-4709-8c8c-a0325e9c9129/_tmp_space.db
18/01/24 16:08:13 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/rstudio-user/bigdataclass2018/workbook/spark-warehouse
18/01/24 16:08:13 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:13 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:13 INFO HiveMetaStore: 0: get_database: global_temp
18/01/24 16:08:13 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/01/24 16:08:13 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/01/24 16:08:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:08:17 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:17 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:17 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:17 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:08:17 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:08:18 INFO CodeGenerator: Code generated in 254.829822 ms
18/01/24 16:08:18 INFO SparkContext: Starting job: collect at utils.scala:58
18/01/24 16:08:18 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/01/24 16:08:18 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/01/24 16:08:18 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:08:18 INFO DAGScheduler: Missing parents: List()
18/01/24 16:08:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
18/01/24 16:08:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/01/24 16:08:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/01/24 16:08:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:33521 (size: 4.6 KB, free: 366.3 MB)
18/01/24 16:08:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/01/24 16:08:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
18/01/24 16:08:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/01/24 16:08:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
18/01/24 16:08:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/01/24 16:08:18 INFO Executor: Fetching spark://127.0.0.1:39737/jars/sparklyr-2.1-2.11.jar with timestamp 1516810086069
18/01/24 16:08:18 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:39737 after 10 ms (0 ms spent in bootstraps)
18/01/24 16:08:18 INFO Utils: Fetching spark://127.0.0.1:39737/jars/sparklyr-2.1-2.11.jar to /tmp/spark-e6ef4e5c-39a2-4d28-b9d3-e186585d373c/userFiles-8fbcff12-10c1-498e-bcdf-87c5485b3e01/fetchFileTemp3072331850262373405.tmp
18/01/24 16:08:18 INFO Executor: Adding file:/tmp/spark-e6ef4e5c-39a2-4d28-b9d3-e186585d373c/userFiles-8fbcff12-10c1-498e-bcdf-87c5485b3e01/sparklyr-2.1-2.11.jar to class loader
18/01/24 16:08:18 INFO CodeGenerator: Code generated in 14.700517 ms
18/01/24 16:08:18 INFO CodeGenerator: Code generated in 11.989662 ms
18/01/24 16:08:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
18/01/24 16:08:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 233 ms on localhost (executor driver) (1/1)
18/01/24 16:08:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/01/24 16:08:18 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.254 s
18/01/24 16:08:18 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.402991 s
18/01/24 16:08:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:08:21 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:21 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:21 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:21 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:08:21 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:08:21 INFO SparkSqlParser: Parsing command: flights
18/01/24 16:08:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz1`
WHERE (0 = 1)
18/01/24 16:08:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:08:22 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:22 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:22 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:22 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:08:22 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:08:22 INFO CodeGenerator: Code generated in 10.520842 ms
18/01/24 16:08:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:08:22 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:22 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:22 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:08:22 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:08:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:08:22 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:08:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
18/01/24 16:08:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610451d809a7
18/01/24 16:08:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610451d809a7` AS `zzz3`
WHERE (0 = 1)
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610455547202
18/01/24 16:08:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610455547202` AS `zzz4`
WHERE (0 = 1)
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61041b1093b8
18/01/24 16:08:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61041b1093b8` AS `zzz5`
WHERE (0 = 1)
18/01/24 16:08:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:08:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610451d809a7`
18/01/24 16:08:26 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_c8ac219c04ff
18/01/24 16:08:26 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_c8ac219c04ff`) `qibeoammfo`) `qkyoruvxll`
18/01/24 16:08:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:33521 in memory (size: 4.6 KB, free: 366.3 MB)
18/01/24 16:08:27 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_d3a1007ec66b
18/01/24 16:08:27 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_d3a1007ec66b`) `qibeoammfo`) `qkyoruvxll`
18/01/24 16:08:27 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_e648ca7701ae
18/01/24 16:08:27 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_e648ca7701ae`) `qibeoammfo`) `qkyoruvxll`
18/01/24 16:08:27 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:08:27 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:08:27 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, dayofmonth: string, dayofweek: string, deptime: string ... 27 more fields>
18/01/24 16:08:27 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:08:28 INFO CodeGenerator: Code generated in 110.221365 ms
18/01/24 16:08:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.9 KB, free 366.0 MB)
18/01/24 16:08:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
18/01/24 16:08:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:33521 (size: 23.9 KB, free: 366.3 MB)
18/01/24 16:08:28 INFO SparkContext: Created broadcast 1 from rdd at LogisticRegression.scala:321
18/01/24 16:08:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:08:28 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:08:28 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:08:28 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, dayofmonth: string, dayofweek: string, deptime: string ... 27 more fields>
18/01/24 16:08:28 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:08:28 INFO CodeGenerator: Code generated in 90.974869 ms
18/01/24 16:08:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 293.9 KB, free 365.7 MB)
18/01/24 16:08:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.7 MB)
18/01/24 16:08:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:33521 (size: 23.9 KB, free: 366.3 MB)
18/01/24 16:08:28 INFO SparkContext: Created broadcast 2 from rdd at LogisticRegression.scala:330
18/01/24 16:08:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:08:28 INFO Instrumentation: LogisticRegression-logistic_regression_610474782d95-1552963405-1: training: numPartitions=6 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
18/01/24 16:08:28 INFO Instrumentation: LogisticRegression-logistic_regression_610474782d95-1552963405-1: {"elasticNetParam":0.0,"fitIntercept":true,"threshold":0.5,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
18/01/24 16:08:28 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:352
18/01/24 16:08:28 INFO DAGScheduler: Registering RDD 30 (treeAggregate at LogisticRegression.scala:352)
18/01/24 16:08:28 INFO DAGScheduler: Got job 1 (treeAggregate at LogisticRegression.scala:352) with 2 output partitions
18/01/24 16:08:28 INFO DAGScheduler: Final stage: ResultStage 2 (treeAggregate at LogisticRegression.scala:352)
18/01/24 16:08:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
18/01/24 16:08:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
18/01/24 16:08:28 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[30] at treeAggregate at LogisticRegression.scala:352), which has no missing parents
18/01/24 16:08:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 48.1 KB, free 365.6 MB)
18/01/24 16:08:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 19.5 KB, free 365.6 MB)
18/01/24 16:08:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:33521 (size: 19.5 KB, free: 366.2 MB)
18/01/24 16:08:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
18/01/24 16:08:28 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[30] at treeAggregate at LogisticRegression.scala:352)
18/01/24 16:08:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 6 tasks
18/01/24 16:08:28 INFO ContextCleaner: Cleaned accumulator 1
18/01/24 16:08:28 INFO ContextCleaner: Cleaned accumulator 0
18/01/24 16:08:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:08:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:08:28 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:08:28 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:08:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/01/24 16:08:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
18/01/24 16:08:28 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
18/01/24 16:08:28 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
18/01/24 16:08:28 INFO CodeGenerator: Code generated in 46.036121 ms
18/01/24 16:08:28 INFO CodeGenerator: Code generated in 12.780744 ms
18/01/24 16:08:28 INFO CodeGenerator: Code generated in 10.688669 ms
18/01/24 16:08:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_5.csv, range: 0-58235665, partition values: [empty row]
18/01/24 16:08:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_8.csv, range: 0-58779678, partition values: [empty row]
18/01/24 16:08:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_7.csv, range: 0-60303224, partition values: [empty row]
18/01/24 16:08:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_4.csv, range: 0-57382100, partition values: [empty row]
18/01/24 16:08:29 INFO CodeGenerator: Code generated in 21.069373 ms
18/01/24 16:08:31 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:08:31 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:08:31 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:08:32 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:08:35 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:08:35 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:08:35 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:08:35 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:08:38 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:08:38 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:08:38 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:08:38 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:08:39 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_6.csv, range: 0-58449479, partition values: [empty row]
18/01/24 16:08:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_2.csv, range: 0-54560133, partition values: [empty row]
18/01/24 16:08:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_1.csv, range: 0-58119869, partition values: [empty row]
18/01/24 16:08:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_3.csv, range: 0-59109692, partition values: [empty row]
18/01/24 16:08:40 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:08:41 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:08:41 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:08:41 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:08:43 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:08:44 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:08:44 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:08:44 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:08:46 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:08:46 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:08:47 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:08:47 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:08:49 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (6  times so far)
18/01/24 16:08:53 INFO MemoryStore: Block rdd_28_3 stored as values in memory (estimated size 943.6 KB, free 188.2 MB)
18/01/24 16:08:53 INFO BlockManagerInfo: Added rdd_28_3 in memory on 127.0.0.1:33521 (size: 943.6 KB, free: 365.3 MB)
18/01/24 16:08:53 INFO MemoryStore: Block rdd_28_1 stored as values in memory (estimated size 1001.1 KB, free 271.2 MB)
18/01/24 16:08:53 INFO BlockManagerInfo: Added rdd_28_1 in memory on 127.0.0.1:33521 (size: 1001.1 KB, free: 364.3 MB)
18/01/24 16:08:53 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3274 bytes result sent to driver
18/01/24 16:08:53 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 3187 bytes result sent to driver
18/01/24 16:08:53 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:08:53 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
18/01/24 16:08:53 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:08:53 INFO Executor: Running task 5.0 in stage 1.0 (TID 6)
18/01/24 16:08:53 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 25025 ms on localhost (executor driver) (1/6)
18/01/24 16:08:53 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 25031 ms on localhost (executor driver) (2/6)
18/01/24 16:08:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_10.csv, range: 0-53984260, partition values: [empty row]
18/01/24 16:08:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_9.csv, range: 0-51858178, partition values: [empty row]
18/01/24 16:08:54 INFO MemoryStore: Block rdd_28_2 stored as values in memory (estimated size 984.6 KB, free 312.3 MB)
18/01/24 16:08:54 INFO BlockManagerInfo: Added rdd_28_2 in memory on 127.0.0.1:33521 (size: 984.6 KB, free: 363.4 MB)
18/01/24 16:08:54 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 3187 bytes result sent to driver
18/01/24 16:08:54 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 25575 ms on localhost (executor driver) (3/6)
18/01/24 16:08:54 INFO MemoryStore: Block rdd_28_0 stored as values in memory (estimated size 1009.2 KB, free 305.8 MB)
18/01/24 16:08:54 INFO BlockManagerInfo: Added rdd_28_0 in memory on 127.0.0.1:33521 (size: 1009.2 KB, free: 362.4 MB)
18/01/24 16:08:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 3187 bytes result sent to driver
18/01/24 16:08:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 25681 ms on localhost (executor driver) (4/6)
18/01/24 16:08:56 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 168.0 MB to disk (0  time so far)
18/01/24 16:08:56 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 168.0 MB to disk (0  time so far)
18/01/24 16:08:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_12.csv, range: 0-52930976, partition values: [empty row]
18/01/24 16:08:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_11.csv, range: 0-50867158, partition values: [empty row]
18/01/24 16:09:00 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 168.0 MB to disk (1  time so far)
18/01/24 16:09:00 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 168.0 MB to disk (1  time so far)
18/01/24 16:09:03 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 168.0 MB to disk (2  times so far)
18/01/24 16:09:03 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 168.0 MB to disk (2  times so far)
18/01/24 16:09:05 INFO MemoryStore: Block rdd_28_5 stored as values in memory (estimated size 861.6 KB, free 334.9 MB)
18/01/24 16:09:05 INFO BlockManagerInfo: Added rdd_28_5 in memory on 127.0.0.1:33521 (size: 861.6 KB, free: 361.5 MB)
18/01/24 16:09:05 INFO Executor: Finished task 5.0 in stage 1.0 (TID 6). 3274 bytes result sent to driver
18/01/24 16:09:05 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 12056 ms on localhost (executor driver) (5/6)
18/01/24 16:09:06 INFO MemoryStore: Block rdd_28_4 stored as values in memory (estimated size 894.5 KB, free 360.1 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added rdd_28_4 in memory on 127.0.0.1:33521 (size: 894.5 KB, free: 360.7 MB)
18/01/24 16:09:06 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 3187 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 12223 ms on localhost (executor driver) (6/6)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ShuffleMapStage 1 (treeAggregate at LogisticRegression.scala:352) finished in 37.256 s
18/01/24 16:09:06 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:06 INFO DAGScheduler: running: Set()
18/01/24 16:09:06 INFO DAGScheduler: waiting: Set(ResultStage 2)
18/01/24 16:09:06 INFO DAGScheduler: failed: Set()
18/01/24 16:09:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[32] at treeAggregate at LogisticRegression.scala:352), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.1 KB, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1861.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:33521 (size: 1861.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[32] at treeAggregate at LogisticRegression.scala:352)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 7, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 8, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 2.0 (TID 8)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 7)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 7). 2840 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 7) in 39 ms on localhost (executor driver) (1/2)
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 2.0 (TID 8). 2840 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 8) in 42 ms on localhost (executor driver) (2/2)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ResultStage 2 (treeAggregate at LogisticRegression.scala:352) finished in 0.043 s
18/01/24 16:09:06 INFO DAGScheduler: Job 1 finished: treeAggregate at LogisticRegression.scala:352, took 37.493730 s
18/01/24 16:09:06 INFO Instrumentation: LogisticRegression-logistic_regression_610474782d95-1552963405-1: {"numClasses":2}
18/01/24 16:09:06 INFO Instrumentation: LogisticRegression-logistic_regression_610474782d95-1552963405-1: {"numFeatures":2}
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 56.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 85.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:33521 (size: 85.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 5 from broadcast at LogisticRegression.scala:435
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 80.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 153.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:33521 (size: 153.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 6 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:06 INFO DAGScheduler: Registering RDD 34 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Got job 2 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:06 INFO DAGScheduler: Final stage: ResultStage 4 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
18/01/24 16:09:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
18/01/24 16:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[34] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 48.3 KB, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.6 KB, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[34] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 6 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 3.0 (TID 9)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:06 INFO Executor: Running task 3.0 in stage 3.0 (TID 12)
18/01/24 16:09:06 INFO Executor: Running task 2.0 in stage 3.0 (TID 11)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 3.0 (TID 10)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 9). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 13, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 62 ms on localhost (executor driver) (1/6)
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 3.0 (TID 10). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 2.0 in stage 3.0 (TID 11). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 3.0 in stage 3.0 (TID 12). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Running task 4.0 in stage 3.0 (TID 13)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 14, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 12) in 67 ms on localhost (executor driver) (2/6)
18/01/24 16:09:06 INFO Executor: Running task 5.0 in stage 3.0 (TID 14)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 10) in 68 ms on localhost (executor driver) (3/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 11) in 68 ms on localhost (executor driver) (4/6)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:06 INFO Executor: Finished task 4.0 in stage 3.0 (TID 13). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 13) in 23 ms on localhost (executor driver) (5/6)
18/01/24 16:09:06 INFO Executor: Finished task 5.0 in stage 3.0 (TID 14). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 14) in 17 ms on localhost (executor driver) (6/6)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ShuffleMapStage 3 (treeAggregate at LogisticRegression.scala:1670) finished in 0.087 s
18/01/24 16:09:06 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:06 INFO DAGScheduler: running: Set()
18/01/24 16:09:06 INFO DAGScheduler: waiting: Set(ResultStage 4)
18/01/24 16:09:06 INFO DAGScheduler: failed: Set()
18/01/24 16:09:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[36] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.0 KB, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[36] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 15, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 16, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 4.0 (TID 16)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 15)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 4.0 (TID 16). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 15). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 16) in 8 ms on localhost (executor driver) (1/2)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 15) in 16 ms on localhost (executor driver) (2/2)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ResultStage 4 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
18/01/24 16:09:06 INFO DAGScheduler: Job 2 finished: treeAggregate at LogisticRegression.scala:1670, took 0.114454 s
18/01/24 16:09:06 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/01/24 16:09:06 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/01/24 16:09:06 INFO TorrentBroadcast: Destroying Broadcast(6) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:33521 in memory (size: 153.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 80.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 162.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 9 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:06 INFO DAGScheduler: Registering RDD 38 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Got job 3 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:06 INFO DAGScheduler: Final stage: ResultStage 6 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
18/01/24 16:09:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
18/01/24 16:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[38] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.9 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[38] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 6 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 5.0 (TID 17)
18/01/24 16:09:06 INFO Executor: Running task 2.0 in stage 5.0 (TID 19)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 5.0 (TID 18)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:06 INFO Executor: Running task 3.0 in stage 5.0 (TID 20)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:06 INFO Executor: Finished task 3.0 in stage 5.0 (TID 20). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 2.0 in stage 5.0 (TID 19). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 21, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:06 INFO Executor: Running task 4.0 in stage 5.0 (TID 21)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 22, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 20) in 48 ms on localhost (executor driver) (1/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 19) in 48 ms on localhost (executor driver) (2/6)
18/01/24 16:09:06 INFO Executor: Running task 5.0 in stage 5.0 (TID 22)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 5.0 (TID 17). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 5.0 (TID 18). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 17) in 76 ms on localhost (executor driver) (3/6)
18/01/24 16:09:06 INFO Executor: Finished task 5.0 in stage 5.0 (TID 22). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 4.0 in stage 5.0 (TID 21). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 18) in 76 ms on localhost (executor driver) (4/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 22) in 29 ms on localhost (executor driver) (5/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 21) in 30 ms on localhost (executor driver) (6/6)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ShuffleMapStage 5 (treeAggregate at LogisticRegression.scala:1670) finished in 0.078 s
18/01/24 16:09:06 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:06 INFO DAGScheduler: running: Set()
18/01/24 16:09:06 INFO DAGScheduler: waiting: Set(ResultStage 6)
18/01/24 16:09:06 INFO DAGScheduler: failed: Set()
18/01/24 16:09:06 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[40] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.7 KB, free 359.9 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.9 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[40] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 23, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 24, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 6.0 (TID 23)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 6.0 (TID 24)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 6.0 (TID 23). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 6.0 (TID 24). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 23) in 10 ms on localhost (executor driver) (1/2)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 24) in 8 ms on localhost (executor driver) (2/2)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ResultStage 6 (treeAggregate at LogisticRegression.scala:1670) finished in 0.011 s
18/01/24 16:09:06 INFO DAGScheduler: Job 3 finished: treeAggregate at LogisticRegression.scala:1670, took 0.104266 s
18/01/24 16:09:06 INFO TorrentBroadcast: Destroying Broadcast(9) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:06 INFO LBFGS: Step Size: 3.552
18/01/24 16:09:06 INFO LBFGS: Val and Grad Norm: 0.369772 (rel: 0.283) 0.351835
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 80.0 B, free 359.9 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.9 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 12 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:06 INFO DAGScheduler: Registering RDD 42 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Got job 4 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:06 INFO DAGScheduler: Final stage: ResultStage 8 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/01/24 16:09:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/01/24 16:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[42] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 7.0 with 6 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 26, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 27, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 28, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 7.0 (TID 25)
18/01/24 16:09:06 INFO Executor: Running task 2.0 in stage 7.0 (TID 27)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 7.0 (TID 26)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:06 INFO Executor: Running task 3.0 in stage 7.0 (TID 28)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 7.0 (TID 26). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 3.0 in stage 7.0 (TID 28). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 7.0 (TID 25). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 29, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:06 INFO Executor: Finished task 2.0 in stage 7.0 (TID 27). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 30, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 28) in 27 ms on localhost (executor driver) (1/6)
18/01/24 16:09:06 INFO Executor: Running task 5.0 in stage 7.0 (TID 30)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 25) in 28 ms on localhost (executor driver) (2/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 27) in 28 ms on localhost (executor driver) (3/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 26) in 28 ms on localhost (executor driver) (4/6)
18/01/24 16:09:06 INFO Executor: Running task 4.0 in stage 7.0 (TID 29)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:06 INFO Executor: Finished task 4.0 in stage 7.0 (TID 29). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 29) in 12 ms on localhost (executor driver) (5/6)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:06 INFO Executor: Finished task 5.0 in stage 7.0 (TID 30). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 30) in 19 ms on localhost (executor driver) (6/6)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ShuffleMapStage 7 (treeAggregate at LogisticRegression.scala:1670) finished in 0.047 s
18/01/24 16:09:06 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:06 INFO DAGScheduler: running: Set()
18/01/24 16:09:06 INFO DAGScheduler: waiting: Set(ResultStage 8)
18/01/24 16:09:06 INFO DAGScheduler: failed: Set()
18/01/24 16:09:06 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[44] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 31, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 32, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 8.0 (TID 32)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 8.0 (TID 31)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 8.0 (TID 32). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 32) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 8.0 (TID 31). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 31) in 8 ms on localhost (executor driver) (2/2)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ResultStage 8 (treeAggregate at LogisticRegression.scala:1670) finished in 0.009 s
18/01/24 16:09:06 INFO DAGScheduler: Job 4 finished: treeAggregate at LogisticRegression.scala:1670, took 0.069269 s
18/01/24 16:09:06 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:06 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:06 INFO LBFGS: Val and Grad Norm: 0.234126 (rel: 0.367) 0.0720299
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 15 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:06 INFO DAGScheduler: Registering RDD 46 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO DAGScheduler: Got job 5 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:06 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
18/01/24 16:09:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
18/01/24 16:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 48.3 KB, free 359.8 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[46] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 35, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 36, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO ContextCleaner: Cleaned shuffle 3
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 9.0 (TID 33)
18/01/24 16:09:06 INFO Executor: Running task 2.0 in stage 9.0 (TID 35)
18/01/24 16:09:06 INFO Executor: Running task 3.0 in stage 9.0 (TID 36)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 9.0 (TID 34)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:33521 in memory (size: 1861.0 B, free: 360.6 MB)
18/01/24 16:09:06 INFO ContextCleaner: Cleaned shuffle 1
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.7 MB)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:06 INFO Executor: Finished task 3.0 in stage 9.0 (TID 36). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 37, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 36) in 11 ms on localhost (executor driver) (1/6)
18/01/24 16:09:06 INFO Executor: Running task 4.0 in stage 9.0 (TID 37)
18/01/24 16:09:06 INFO Executor: Finished task 2.0 in stage 9.0 (TID 35). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:06 INFO Executor: Finished task 4.0 in stage 9.0 (TID 37). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 38, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 35) in 19 ms on localhost (executor driver) (2/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 37) in 10 ms on localhost (executor driver) (3/6)
18/01/24 16:09:06 INFO Executor: Running task 5.0 in stage 9.0 (TID 38)
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 9.0 (TID 34). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 34) in 22 ms on localhost (executor driver) (4/6)
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 9.0 (TID 33). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 33) in 29 ms on localhost (executor driver) (5/6)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:06 INFO Executor: Finished task 5.0 in stage 9.0 (TID 38). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 38) in 11 ms on localhost (executor driver) (6/6)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ShuffleMapStage 9 (treeAggregate at LogisticRegression.scala:1670) finished in 0.036 s
18/01/24 16:09:06 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:06 INFO DAGScheduler: running: Set()
18/01/24 16:09:06 INFO DAGScheduler: waiting: Set(ResultStage 10)
18/01/24 16:09:06 INFO DAGScheduler: failed: Set()
18/01/24 16:09:06 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.7 KB, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.0 KB, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO ContextCleaner: Cleaned shuffle 2
18/01/24 16:09:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 39, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 40, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 10.0 (TID 39)
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 10.0 (TID 40)
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 10.0 (TID 40). 3323 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 40) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 10.0 (TID 39). 3410 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 39) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/01/24 16:09:06 INFO DAGScheduler: ResultStage 10 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:06 INFO DAGScheduler: Job 5 finished: treeAggregate at LogisticRegression.scala:1670, took 0.056965 s
18/01/24 16:09:06 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:06 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:06 INFO LBFGS: Val and Grad Norm: 0.183400 (rel: 0.217) 0.0603916
18/01/24 16:09:06 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 80.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 162.0 B, free 360.0 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.7 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 18 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:06 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:06 INFO DAGScheduler: Registering RDD 50 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Got job 6 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:06 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/01/24 16:09:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/01/24 16:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:06 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.9 MB)
18/01/24 16:09:06 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:06 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:06 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[50] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:06 INFO TaskSchedulerImpl: Adding task set 11.0 with 6 tasks
18/01/24 16:09:06 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 43, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 44, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:06 INFO Executor: Running task 0.0 in stage 11.0 (TID 41)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:06 INFO Executor: Running task 1.0 in stage 11.0 (TID 42)
18/01/24 16:09:06 INFO Executor: Running task 2.0 in stage 11.0 (TID 43)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:06 INFO Executor: Running task 3.0 in stage 11.0 (TID 44)
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:06 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:06 INFO Executor: Finished task 1.0 in stage 11.0 (TID 42). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 0.0 in stage 11.0 (TID 41). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO Executor: Finished task 3.0 in stage 11.0 (TID 44). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 45, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 46, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 42) in 21 ms on localhost (executor driver) (1/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 44) in 21 ms on localhost (executor driver) (2/6)
18/01/24 16:09:06 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 41) in 22 ms on localhost (executor driver) (3/6)
18/01/24 16:09:06 INFO Executor: Running task 5.0 in stage 11.0 (TID 46)
18/01/24 16:09:06 INFO Executor: Finished task 2.0 in stage 11.0 (TID 43). 2392 bytes result sent to driver
18/01/24 16:09:06 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 43) in 24 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 11.0 (TID 45)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 11.0 (TID 46). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 46) in 10 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 11.0 (TID 45). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 45) in 16 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 11 (treeAggregate at LogisticRegression.scala:1670) finished in 0.036 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 12)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 3.7 KB, free 359.9 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.9 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[52] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 47, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 48, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 12.0 (TID 48)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 12.0 (TID 48). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 12.0 (TID 47)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 48) in 5 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 12.0 (TID 47). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 47) in 9 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 12 (treeAggregate at LogisticRegression.scala:1670) finished in 0.009 s
18/01/24 16:09:07 INFO DAGScheduler: Job 6 finished: treeAggregate at LogisticRegression.scala:1670, took 0.055301 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.125345 (rel: 0.317) 0.0411886
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 80.0 B, free 359.9 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.9 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 21 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 54 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 7 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 14 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[54] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 50, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 51, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 52, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 49)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 13.0 (TID 52)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 13.0 (TID 50)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 13.0 (TID 51)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 13.0 (TID 50). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 13.0 (TID 51). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 53, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 54, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 50) in 15 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 51) in 16 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 13.0 (TID 54)
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 49). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 49) in 18 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 13.0 (TID 52). 2479 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 52) in 18 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 13.0 (TID 54). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 13.0 (TID 53)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 54) in 12 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 13.0 (TID 53). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 53) in 25 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 13 (treeAggregate at LogisticRegression.scala:1670) finished in 0.042 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 14)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 55, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 56, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 14.0 (TID 56)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 14.0 (TID 55)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 14.0 (TID 56). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 14.0 (TID 55). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 56) in 7 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 55) in 11 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 14 (treeAggregate at LogisticRegression.scala:1670) finished in 0.011 s
18/01/24 16:09:07 INFO DAGScheduler: Job 7 finished: treeAggregate at LogisticRegression.scala:1670, took 0.063147 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0881779 (rel: 0.297) 0.0203737
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 24 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 58 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 8 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 48.3 KB, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[58] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 15.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 59, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 60, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 15.0 (TID 58)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 15.0 (TID 59)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 15.0 (TID 60)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 15.0 (TID 57)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 15.0 (TID 60). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 61, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 60) in 14 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 15.0 (TID 61)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 15.0 (TID 58). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 15.0 (TID 57). 2479 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 62, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 58) in 20 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 57) in 21 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 15.0 (TID 59). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 15.0 (TID 62)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 59) in 20 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 15.0 (TID 61). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 61) in 10 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 15.0 (TID 62). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 62) in 9 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 15 (treeAggregate at LogisticRegression.scala:1670) finished in 0.028 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 16)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[60] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 63, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 64, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 16.0 (TID 64)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 16.0 (TID 63)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 16.0 (TID 63). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 16.0 (TID 64). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 63) in 7 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 64) in 7 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 16 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
18/01/24 16:09:07 INFO DAGScheduler: Job 8 finished: treeAggregate at LogisticRegression.scala:1670, took 0.049287 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0635006 (rel: 0.280) 0.00766923
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 27 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 62 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 9 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 18 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 48.3 KB, free 359.7 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.7 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[62] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 17.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 67, localhost, executor driver, partition 2, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 68, localhost, executor driver, partition 3, PROCESS_LOCAL, 6649 bytes)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 17.0 (TID 67)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 17.0 (TID 68)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 17.0 (TID 65)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 17.0 (TID 66)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 17.0 (TID 68). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 17.0 (TID 67). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 17.0 (TID 65). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 69, localhost, executor driver, partition 4, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 17.0 (TID 69)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 68) in 27 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 70, localhost, executor driver, partition 5, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 67) in 30 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 17.0 (TID 66). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 66) in 32 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 65) in 36 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 17.0 (TID 70)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 17.0 (TID 69). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 69) in 14 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 17.0 (TID 70). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 70) in 15 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 17 (treeAggregate at LogisticRegression.scala:1670) finished in 0.020 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 18)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.7 KB, free 359.7 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.7 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[64] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 71, localhost, executor driver, partition 0, ANY, 5817 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 72, localhost, executor driver, partition 1, ANY, 5817 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 18.0 (TID 72)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 18.0 (TID 71)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 18.0 (TID 71). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 18.0 (TID 72). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 71) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 72) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 18 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
18/01/24 16:09:07 INFO DAGScheduler: Job 9 finished: treeAggregate at LogisticRegression.scala:1670, took 0.061777 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(27) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0480386 (rel: 0.243) 0.0135999
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 80.0 B, free 359.7 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.7 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 30 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 66 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 10 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 20 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[66] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 19.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 75, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 76, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 19.0 (TID 73)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 19.0 (TID 74)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 19.0 (TID 75)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 19.0 (TID 76)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 19.0 (TID 74). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 19.0 (TID 73). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 19.0 (TID 77, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 74) in 22 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 19.0 (TID 77)
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 19.0 (TID 76). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 19.0 (TID 75). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 19.0 (TID 78, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 76) in 25 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 19.0 (TID 78)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 19.0 (TID 77). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 19.0 (TID 77) in 9 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 19.0 (TID 78). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 73) in 38 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 19.0 (TID 78) in 9 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 75) in 34 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 19 (treeAggregate at LogisticRegression.scala:1670) finished in 0.037 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 20)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 20 (MapPartitionsRDD[68] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 79, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 80, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 20.0 (TID 80)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 20.0 (TID 79)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 20.0 (TID 80). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 80) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 20.0 (TID 79). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 79) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 20 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:07 INFO DAGScheduler: Job 10 finished: treeAggregate at LogisticRegression.scala:1670, took 0.054274 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(30) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0377294 (rel: 0.215) 0.0196221
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 80.0 B, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 33 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 70 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 11 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 22 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[70] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 21.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 83, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 84, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 21.0 (TID 83)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 21.0 (TID 81)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 21.0 (TID 82)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 21.0 (TID 84)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 21.0 (TID 83). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 21.0 (TID 85, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 21.0 (TID 85)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 83) in 18 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 21.0 (TID 81). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 21.0 (TID 82). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 21.0 (TID 86, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 81) in 27 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 21.0 (TID 84). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 82) in 25 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 84) in 26 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 21.0 (TID 85). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 21.0 (TID 85) in 9 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 21.0 (TID 86)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 21.0 (TID 86). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 21.0 (TID 86) in 10 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 21 (treeAggregate at LogisticRegression.scala:1670) finished in 0.010 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 22)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 22 (MapPartitionsRDD[72] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 87, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 88, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 22.0 (TID 87)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 22.0 (TID 88)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 22.0 (TID 87). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 22.0 (TID 88). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 88) in 6 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 87) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 22 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
18/01/24 16:09:07 INFO DAGScheduler: Job 11 finished: treeAggregate at LogisticRegression.scala:1670, took 0.059147 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(33) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0301828 (rel: 0.200) 0.0212931
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 80.0 B, free 359.5 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 36 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 74 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 12 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 24 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 48.3 KB, free 359.5 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[74] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 23.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 91, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 92, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 23.0 (TID 89)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 23.0 (TID 90)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 23.0 (TID 92)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 23.0 (TID 91)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 23.0 (TID 92). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 23.0 (TID 93, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 23.0 (TID 91). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 23.0 (TID 94, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 23.0 (TID 94)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 23.0 (TID 90). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 91) in 16 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 90) in 17 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 92) in 16 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 23.0 (TID 93)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 23.0 (TID 89). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 89) in 23 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 23.0 (TID 93). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 23.0 (TID 93) in 14 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 23.0 (TID 94). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 23.0 (TID 94) in 11 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 23 (treeAggregate at LogisticRegression.scala:1670) finished in 0.027 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 24)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 3.7 KB, free 359.5 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 24 (MapPartitionsRDD[76] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 95, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 96, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 24.0 (TID 96)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 24.0 (TID 95)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 24.0 (TID 96). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 96) in 5 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 24.0 (TID 95). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 95) in 5 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 24 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:07 INFO DAGScheduler: Job 12 finished: treeAggregate at LogisticRegression.scala:1670, took 0.041210 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(36) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0225356 (rel: 0.253) 0.0101512
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 80.0 B, free 359.5 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 39 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 78 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 13 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 26 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.4 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[78] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 25.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 99, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 100, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 25.0 (TID 97)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 25.0 (TID 98)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 25.0 (TID 99)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 25.0 (TID 100)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 25.0 (TID 97). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 25.0 (TID 101, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 25.0 (TID 101)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 97) in 11 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 25.0 (TID 99). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 25.0 (TID 102, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 25.0 (TID 102)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 99) in 16 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 25.0 (TID 100). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 100) in 24 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 25.0 (TID 98). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 98) in 34 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 25.0 (TID 101). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 25.0 (TID 101) in 33 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 25.0 (TID 102). 2479 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 25.0 (TID 102) in 36 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 25 (treeAggregate at LogisticRegression.scala:1670) finished in 0.053 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 26)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 3.7 KB, free 359.4 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.4 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[80] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 26.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 103, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 104, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 26.0 (TID 104)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 26.0 (TID 103)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 26.0 (TID 104). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 104) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 26.0 (TID 103). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 103) in 9 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 26 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
18/01/24 16:09:07 INFO DAGScheduler: Job 13 finished: treeAggregate at LogisticRegression.scala:1670, took 0.073230 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(39) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0171674 (rel: 0.238) 0.00352636
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 80.0 B, free 359.4 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.4 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 42 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 82 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 14 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.3 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[82] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 27.0 (TID 106)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 27.0 (TID 108)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 27.0 (TID 105)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 27.0 (TID 107)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 27.0 (TID 106). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 109, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 27.0 (TID 109)
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 27.0 (TID 107). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 106) in 10 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 110, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 107) in 12 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 27.0 (TID 110)
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 27.0 (TID 108). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 108) in 13 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 27.0 (TID 105). 2465 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 27.0 (TID 110). 2465 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 105) in 34 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 110) in 22 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 7
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 27.0 (TID 109). 2465 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 109) in 27 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 27 (treeAggregate at LogisticRegression.scala:1670) finished in 0.037 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 28)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 3.7 KB, free 359.4 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.4 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 28 (MapPartitionsRDD[84] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 111, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 112, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 28.0 (TID 112)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 28.0 (TID 111)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 28.0 (TID 112). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 112) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 28.0 (TID 111). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 111) in 8 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 28 (treeAggregate at LogisticRegression.scala:1670) finished in 0.009 s
18/01/24 16:09:07 INFO DAGScheduler: Job 14 finished: treeAggregate at LogisticRegression.scala:1670, took 0.053894 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(42) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 8
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0127469 (rel: 0.257) 0.00377211
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 80.0 B, free 359.4 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 45 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 9
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 86 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 15 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 30 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 48.3 KB, free 359.5 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.5 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[86] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 29.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 115, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 116, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 29.0 (TID 113)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 29.0 (TID 115)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 29.0 (TID 114)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 29.0 (TID 116)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 10
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 29.0 (TID 113). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 29.0 (TID 115). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 117, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 29.0 (TID 117)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 118, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 115) in 25 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 113) in 26 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 11
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 29.0 (TID 118)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 12
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 4
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 29.0 (TID 114). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 29.0 (TID 116). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 114) in 31 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 116) in 32 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 5
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO ContextCleaner: Cleaned shuffle 6
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 29.0 (TID 117). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 117) in 20 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 29.0 (TID 118). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 118) in 21 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 29 (treeAggregate at LogisticRegression.scala:1670) finished in 0.037 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 30)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 3.7 KB, free 359.9 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.9 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 30 (MapPartitionsRDD[88] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 119, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 120, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 30.0 (TID 119)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 30.0 (TID 120)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 30.0 (TID 120). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 120) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 30.0 (TID 119). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 119) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 30 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:07 INFO DAGScheduler: Job 15 finished: treeAggregate at LogisticRegression.scala:1670, took 0.060102 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(45) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 80.0 B, free 359.9 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.9 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 48 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 90 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 16 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 32 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[90] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 31.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 123, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 124, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 31.0 (TID 121)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 31.0 (TID 122)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 31.0 (TID 123)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 31.0 (TID 124)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 31.0 (TID 123). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 31.0 (TID 121). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 31.0 (TID 124). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 31.0 (TID 122). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 31.0 (TID 125, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 31.0 (TID 126, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 31.0 (TID 126)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 124) in 18 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 122) in 19 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 121) in 20 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 123) in 19 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 31.0 (TID 125)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 31.0 (TID 126). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 31.0 (TID 126) in 8 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 31.0 (TID 125). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 31.0 (TID 125) in 22 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 31 (treeAggregate at LogisticRegression.scala:1670) finished in 0.040 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 32)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[92] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 127, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 128, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 32.0 (TID 128)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 32.0 (TID 127)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 32.0 (TID 127). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 32.0 (TID 128). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 127) in 6 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 128) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 32 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:07 INFO DAGScheduler: Job 16 finished: treeAggregate at LogisticRegression.scala:1670, took 0.055516 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(48) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO StrongWolfeLineSearch: Line search t: 0.1 fval: 0.3830748543535169 rhs: 0.012745193518030037 cdd: 6.546808259769802
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 51 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 94 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 17 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 34 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 48.3 KB, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[94] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 33.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 131, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 132, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 33.0 (TID 129)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 33.0 (TID 130)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 33.0 (TID 131)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 33.0 (TID 132)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 33.0 (TID 129). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 33.0 (TID 132). 2479 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 133, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 134, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 33.0 (TID 130). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 132) in 15 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 129) in 16 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 130) in 15 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 33.0 (TID 131). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 33.0 (TID 133)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 131) in 17 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 33.0 (TID 134)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 33.0 (TID 134). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 134) in 16 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 33.0 (TID 133). 2479 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 133) in 21 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 33 (treeAggregate at LogisticRegression.scala:1670) finished in 0.036 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 34)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 34 (MapPartitionsRDD[96] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 34.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 135, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 136, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 34.0 (TID 135)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 34.0 (TID 135). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 34.0 (TID 136)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 135) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 34.0 (TID 136). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 136) in 7 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 34 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
18/01/24 16:09:07 INFO DAGScheduler: Job 17 finished: treeAggregate at LogisticRegression.scala:1670, took 0.055623 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(51) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO StrongWolfeLineSearch: Line search t: 0.010000000000000002 fval: 0.016101030842035235 rhs: 0.012746752097808208 cdd: 0.8288962867388718
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 54 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 98 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 18 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 48.3 KB, free 359.7 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.7 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[98] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 35.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 138, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 139, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 140, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 35.0 (TID 139)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 35.0 (TID 137)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 35.0 (TID 138)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 35.0 (TID 140)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 35.0 (TID 139). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 35.0 (TID 141, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 35.0 (TID 141)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 139) in 16 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 35.0 (TID 137). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 35.0 (TID 140). 2479 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 35.0 (TID 142, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 35.0 (TID 142)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 137) in 23 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 140) in 23 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 35.0 (TID 141). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 35.0 (TID 141) in 9 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 35.0 (TID 142). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 35.0 (TID 142) in 6 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 35.0 (TID 138). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 138) in 28 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 35 (treeAggregate at LogisticRegression.scala:1670) finished in 0.012 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 36)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 3.7 KB, free 359.7 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.7 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 36 (MapPartitionsRDD[100] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 143, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 144, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 36.0 (TID 143)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 36.0 (TID 144)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 36.0 (TID 144). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 36.0 (TID 143). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 144) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 143) in 3 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 36 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
18/01/24 16:09:07 INFO DAGScheduler: Job 18 finished: treeAggregate at LogisticRegression.scala:1670, took 0.041023 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO StrongWolfeLineSearch: Line search t: 0.0016654242254360505 fval: 0.012603066113821185 rhs: 0.012746896432266673 cdd: -5.581182985981564E-6
18/01/24 16:09:07 INFO LBFGS: Step Size: 0.001665
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.0126031 (rel: 0.0113) 0.000605440
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 80.0 B, free 359.7 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.7 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 57 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 102 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 19 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 38 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[102] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 146, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 147, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 148, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 37.0 (TID 145)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 37.0 (TID 146)
18/01/24 16:09:07 INFO Executor: Running task 3.0 in stage 37.0 (TID 148)
18/01/24 16:09:07 INFO Executor: Running task 2.0 in stage 37.0 (TID 147)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:07 INFO Executor: Finished task 2.0 in stage 37.0 (TID 147). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 149, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:07 INFO Executor: Running task 4.0 in stage 37.0 (TID 149)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 147) in 11 ms on localhost (executor driver) (1/6)
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 37.0 (TID 145). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 3.0 in stage 37.0 (TID 148). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 37.0 (TID 146). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:07 INFO Executor: Finished task 4.0 in stage 37.0 (TID 149). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 150, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:07 INFO Executor: Running task 5.0 in stage 37.0 (TID 150)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 146) in 19 ms on localhost (executor driver) (2/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 149) in 8 ms on localhost (executor driver) (3/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 145) in 21 ms on localhost (executor driver) (4/6)
18/01/24 16:09:07 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 148) in 20 ms on localhost (executor driver) (5/6)
18/01/24 16:09:07 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:07 INFO Executor: Finished task 5.0 in stage 37.0 (TID 150). 2392 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 150) in 8 ms on localhost (executor driver) (6/6)
18/01/24 16:09:07 INFO DAGScheduler: ShuffleMapStage 37 (treeAggregate at LogisticRegression.scala:1670) finished in 0.020 s
18/01/24 16:09:07 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:07 INFO DAGScheduler: running: Set()
18/01/24 16:09:07 INFO DAGScheduler: waiting: Set(ResultStage 38)
18/01/24 16:09:07 INFO DAGScheduler: failed: Set()
18/01/24 16:09:07 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[104] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 151, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:07 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 152, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:07 INFO Executor: Running task 1.0 in stage 38.0 (TID 152)
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO Executor: Running task 0.0 in stage 38.0 (TID 151)
18/01/24 16:09:07 INFO Executor: Finished task 1.0 in stage 38.0 (TID 152). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:07 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 152) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:07 INFO Executor: Finished task 0.0 in stage 38.0 (TID 151). 3323 bytes result sent to driver
18/01/24 16:09:07 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 151) in 5 ms on localhost (executor driver) (2/2)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/01/24 16:09:07 INFO DAGScheduler: ResultStage 38 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:07 INFO DAGScheduler: Job 19 finished: treeAggregate at LogisticRegression.scala:1670, took 0.039594 s
18/01/24 16:09:07 INFO TorrentBroadcast: Destroying Broadcast(57) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:07 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:07 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO LBFGS: Val and Grad Norm: 0.00935708 (rel: 0.258) 0.000490252
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 80.0 B, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 60 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:07 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:07 INFO DAGScheduler: Registering RDD 106 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Got job 20 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:07 INFO DAGScheduler: Final stage: ResultStage 40 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
18/01/24 16:09:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
18/01/24 16:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:07 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:07 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:07 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[106] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:07 INFO TaskSchedulerImpl: Adding task set 39.0 with 6 tasks
18/01/24 16:09:07 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 154, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 155, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 156, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 39.0 (TID 153)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 39.0 (TID 154)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 39.0 (TID 156)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 39.0 (TID 155)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 39.0 (TID 153). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 39.0 (TID 156). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 157, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 158, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 39.0 (TID 158)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 153) in 13 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 39.0 (TID 157)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 156) in 12 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 39.0 (TID 158). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 158) in 8 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 39.0 (TID 157). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 157) in 11 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 39.0 (TID 155). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 155) in 22 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 39.0 (TID 154). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 154) in 24 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 39 (treeAggregate at LogisticRegression.scala:1670) finished in 0.023 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 40)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[108] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 159, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 160, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 40.0 (TID 160)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 40.0 (TID 160). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 40.0 (TID 159)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 160) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 40.0 (TID 159). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 159) in 9 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 40 (treeAggregate at LogisticRegression.scala:1670) finished in 0.008 s
18/01/24 16:09:08 INFO DAGScheduler: Job 20 finished: treeAggregate at LogisticRegression.scala:1670, took 0.046235 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.00671303 (rel: 0.283) 0.000401443
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 80.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 63 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 110 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 21 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 48.3 KB, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[110] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 41.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 162, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 163, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 164, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 41.0 (TID 161)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 41.0 (TID 162)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 41.0 (TID 163)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 41.0 (TID 164)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 41.0 (TID 162). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 41.0 (TID 163). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 41.0 (TID 161). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 41.0 (TID 165, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 41.0 (TID 164). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 41.0 (TID 165)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 162) in 19 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 41.0 (TID 166, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 164) in 20 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 41.0 (TID 165). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 41.0 (TID 165) in 9 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 41.0 (TID 166)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 161) in 29 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 163) in 27 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 41.0 (TID 166). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 41.0 (TID 166) in 15 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 41 (treeAggregate at LogisticRegression.scala:1670) finished in 0.035 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 42)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.7 KB, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[112] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 167, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 168, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 42.0 (TID 168)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 42.0 (TID 168). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 168) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 42.0 (TID 167)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 42.0 (TID 167). 3410 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 167) in 11 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 42 (treeAggregate at LogisticRegression.scala:1670) finished in 0.007 s
18/01/24 16:09:08 INFO DAGScheduler: Job 21 finished: treeAggregate at LogisticRegression.scala:1670, took 0.055784 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(63) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 80.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 66 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 114 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 22 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 44 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.4 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[114] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 43.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 169, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 170, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 171, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 172, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 43.0 (TID 171)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 43.0 (TID 169)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 43.0 (TID 170)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 43.0 (TID 172)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 43.0 (TID 169). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 43.0 (TID 173, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 169) in 10 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 43.0 (TID 172). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 43.0 (TID 171). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 43.0 (TID 174, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 43.0 (TID 174)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 172) in 16 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 43.0 (TID 173)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 43.0 (TID 170). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 170) in 17 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 43.0 (TID 174). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 171) in 32 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 43.0 (TID 174) in 17 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 43.0 (TID 173). 2479 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 43.0 (TID 173) in 24 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 43 (treeAggregate at LogisticRegression.scala:1670) finished in 0.032 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 44)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 3.7 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.4 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 44 (MapPartitionsRDD[116] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 175, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 176, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 44.0 (TID 176)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 44.0 (TID 175)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 44.0 (TID 175). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 175) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 44.0 (TID 176). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 176) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 44 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:08 INFO DAGScheduler: Job 22 finished: treeAggregate at LogisticRegression.scala:1670, took 0.046931 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO StrongWolfeLineSearch: Line search t: 0.13437450494131065 fval: 0.006403991999496783 rhs: 0.006712957795403882 cdd: 5.39770257608337E-4
18/01/24 16:09:08 INFO LBFGS: Step Size: 0.1344
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.00640399 (rel: 0.0460) 0.000744429
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 80.0 B, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.4 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 69 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 118 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 23 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 46 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[118] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 45.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 178, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 179, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 180, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 45.0 (TID 179)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 45.0 (TID 177)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 45.0 (TID 180)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 45.0 (TID 178)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 45.0 (TID 179). 2479 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 45.0 (TID 181, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 45.0 (TID 181)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 179) in 10 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 45.0 (TID 180). 2479 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 45.0 (TID 182, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 180) in 14 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 45.0 (TID 181). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 45.0 (TID 182)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 45.0 (TID 181) in 7 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 45.0 (TID 178). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 45.0 (TID 177). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 178) in 26 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 177) in 26 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 45.0 (TID 182). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 45.0 (TID 182) in 15 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 45 (treeAggregate at LogisticRegression.scala:1670) finished in 0.029 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 46)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 3.7 KB, free 359.3 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[120] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 183, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 184, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 46.0 (TID 184)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 46.0 (TID 184). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 46.0 (TID 183)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 184) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 46.0 (TID 183). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 183) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 46 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:08 INFO DAGScheduler: Job 23 finished: treeAggregate at LogisticRegression.scala:1670, took 0.043016 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(69) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.00435385 (rel: 0.320) 0.000395596
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 80.0 B, free 359.3 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 72 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 122 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 24 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 48 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 48.3 KB, free 359.3 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.4 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[122] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 47.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 185, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 186, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 187, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 188, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 47.0 (TID 185)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 47.0 (TID 187)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 47.0 (TID 185). 2465 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 47.0 (TID 188)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 47.0 (TID 189, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 13
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 47.0 (TID 189)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 47.0 (TID 186)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 185) in 25 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 14
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 47.0 (TID 189). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 47.0 (TID 190, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 47.0 (TID 190)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 47.0 (TID 189) in 9 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 47.0 (TID 188). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 47.0 (TID 186). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 188) in 29 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 186) in 30 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 47.0 (TID 187). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 187) in 30 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 15
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 16
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 17
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 47.0 (TID 190). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 47.0 (TID 190) in 10 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 47 (treeAggregate at LogisticRegression.scala:1670) finished in 0.038 s
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 18
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 48)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 3.7 KB, free 359.7 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.7 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 48 (MapPartitionsRDD[124] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 19
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 191, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 192, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 48.0 (TID 192)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 48.0 (TID 191)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 20
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 48.0 (TID 192). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 192) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 48.0 (TID 191). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 191) in 5 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 21
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 48 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:08 INFO DAGScheduler: Job 24 finished: treeAggregate at LogisticRegression.scala:1670, took 0.051532 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(72) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.00266942 (rel: 0.387) 0.000231714
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 80.0 B, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 22
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 75 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.7 MB)
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 126 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 25 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 50 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[126] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 49.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 194, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 195, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 196, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 49.0 (TID 194)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 49.0 (TID 195)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 49.0 (TID 196)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 49.0 (TID 193)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 49.0 (TID 193). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 49.0 (TID 194). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 49.0 (TID 195). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 49.0 (TID 196). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 49.0 (TID 197, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 49.0 (TID 198, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 194) in 13 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 193) in 13 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 195) in 13 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 196) in 13 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 49.0 (TID 197)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 49.0 (TID 198)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 49.0 (TID 198). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 49.0 (TID 198) in 8 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 49.0 (TID 197). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 49.0 (TID 197) in 9 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 49 (treeAggregate at LogisticRegression.scala:1670) finished in 0.018 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 50)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 3.7 KB, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 50 (MapPartitionsRDD[128] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 199, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 200, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 50.0 (TID 200)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 50.0 (TID 200). 3236 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 50.0 (TID 199)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 200) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 50.0 (TID 199). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 199) in 5 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 50 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:08 INFO DAGScheduler: Job 25 finished: treeAggregate at LogisticRegression.scala:1670, took 0.035276 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(75) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.00144493 (rel: 0.459) 0.000125636
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 80.0 B, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 78 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 130 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 26 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 52 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[130] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 51.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 202, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 203, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 204, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 51.0 (TID 204)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 51.0 (TID 203)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 51.0 (TID 202)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 51.0 (TID 204). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 51.0 (TID 205, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 51.0 (TID 201)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 204) in 7 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 51.0 (TID 203). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 51.0 (TID 206, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 51.0 (TID 206)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 203) in 8 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 51.0 (TID 202). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 51.0 (TID 205)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 202) in 12 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 51.0 (TID 201). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 201) in 15 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 51.0 (TID 206). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 51.0 (TID 206) in 7 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 51.0 (TID 205). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 51.0 (TID 205) in 12 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 51 (treeAggregate at LogisticRegression.scala:1670) finished in 0.020 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 52)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 52 (MapPartitionsRDD[132] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 207, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 208, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 52.0 (TID 208)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 52.0 (TID 207)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 52.0 (TID 208). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 208) in 4 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 52.0 (TID 207). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 207) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 52 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:08 INFO DAGScheduler: Job 26 finished: treeAggregate at LogisticRegression.scala:1670, took 0.033633 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(78) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.000718263 (rel: 0.503) 6.23655e-05
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 81 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 134 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 27 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 54 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 48.3 KB, free 359.8 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[134] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 53.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 210, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 211, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 212, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 53.0 (TID 209)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 53.0 (TID 210)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 53.0 (TID 212)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 53.0 (TID 211)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 53.0 (TID 212). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 53.0 (TID 211). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 53.0 (TID 213, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 53.0 (TID 214, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 212) in 11 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 211) in 13 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 53.0 (TID 214)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 53.0 (TID 209). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 53.0 (TID 214). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 53.0 (TID 210). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 53.0 (TID 213)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 209) in 24 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 53.0 (TID 214) in 9 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 53.0 (TID 213). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 53.0 (TID 213) in 15 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 210) in 28 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 53 (treeAggregate at LogisticRegression.scala:1670) finished in 0.031 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 54)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 54 (MapPartitionsRDD[136] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 215, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 216, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 54.0 (TID 216)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 54.0 (TID 215)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 54.0 (TID 216). 3410 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 216) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 54.0 (TID 215). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 215) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 54 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
18/01/24 16:09:08 INFO DAGScheduler: Job 27 finished: treeAggregate at LogisticRegression.scala:1670, took 0.043151 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(81) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.000354693 (rel: 0.506) 3.05387e-05
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 84 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 138 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 28 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 56 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 55)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 48.3 KB, free 359.7 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.7 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[138] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 218, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 219, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 220, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 55.0 (TID 217)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 55.0 (TID 218)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 55.0 (TID 219)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 55.0 (TID 220)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 55.0 (TID 218). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 55.0 (TID 220). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 221, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 222, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 55.0 (TID 217). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 218) in 17 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 220) in 16 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 55.0 (TID 222)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 217) in 17 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 55.0 (TID 219). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 55.0 (TID 221)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 219) in 21 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 55.0 (TID 222). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 222) in 8 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 55.0 (TID 221). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 221) in 12 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 55 (treeAggregate at LogisticRegression.scala:1670) finished in 0.029 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 56)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 3.7 KB, free 359.7 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.7 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 56 (MapPartitionsRDD[140] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 56.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 223, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 224, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 56.0 (TID 224)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 56.0 (TID 223)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 56.0 (TID 224). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 224) in 2 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 56.0 (TID 223). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 223) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 56 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:08 INFO DAGScheduler: Job 28 finished: treeAggregate at LogisticRegression.scala:1670, took 0.039997 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(84) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 0.000175812 (rel: 0.504) 1.49923e-05
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 80.0 B, free 359.7 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.7 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 87 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 142 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 29 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 58 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[142] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 57.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 225, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 226, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 227, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 228, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 57.0 (TID 227)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 57.0 (TID 228)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 57.0 (TID 228). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 229, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 57.0 (TID 226)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 228) in 8 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 57.0 (TID 227). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 230, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 57.0 (TID 225)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 57.0 (TID 229)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 57.0 (TID 226). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 227) in 14 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 57.0 (TID 230)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 226) in 15 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 57.0 (TID 230). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 57.0 (TID 230) in 12 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 57.0 (TID 229). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 229) in 16 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 57.0 (TID 225). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 225) in 29 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 57 (treeAggregate at LogisticRegression.scala:1670) finished in 0.029 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 58)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 58 (MapPartitionsRDD[144] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 58.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 231, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 232, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 58.0 (TID 232)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 58.0 (TID 231)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 58.0 (TID 231). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 231) in 5 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 58.0 (TID 232). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 232) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 58 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:08 INFO DAGScheduler: Job 29 finished: treeAggregate at LogisticRegression.scala:1670, took 0.042598 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(87) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 8.75366e-05 (rel: 0.502) 7.41537e-06
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 80.0 B, free 359.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 90 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 146 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 30 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 60 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[146] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 59.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 234, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 235, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 236, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 59.0 (TID 233)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 59.0 (TID 235)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 59.0 (TID 234)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 59.0 (TID 236)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 59.0 (TID 236). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 59.0 (TID 234). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 59.0 (TID 235). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 59.0 (TID 233). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 59.0 (TID 237, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 59.0 (TID 236) in 16 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 59.0 (TID 237)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 59.0 (TID 238, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 233) in 18 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 59.0 (TID 235) in 18 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 59.0 (TID 238)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 234) in 20 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 59.0 (TID 238). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 59.0 (TID 238) in 7 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 59.0 (TID 237). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 59.0 (TID 237) in 9 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 59 (treeAggregate at LogisticRegression.scala:1670) finished in 0.026 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 60)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 60 (MapPartitionsRDD[148] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 60.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 239, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 240, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 60.0 (TID 239)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 60.0 (TID 240)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 60.0 (TID 239). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 239) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 60.0 (TID 240). 3236 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 240) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 60 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
18/01/24 16:09:08 INFO DAGScheduler: Job 30 finished: treeAggregate at LogisticRegression.scala:1670, took 0.038022 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(90) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 6.66755e-05 (rel: 0.238) 0.000147904
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 80.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 93 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 150 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 31 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 62 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 48.3 KB, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[150] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 61.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 242, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 61.0 (TID 243, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 61.0 (TID 244, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 61.0 (TID 241)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 61.0 (TID 242)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 61.0 (TID 243)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 61.0 (TID 244)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 61.0 (TID 241). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 61.0 (TID 245, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 241) in 23 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 61.0 (TID 243). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 61.0 (TID 246, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 61.0 (TID 245)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 61.0 (TID 246)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 61.0 (TID 243) in 24 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 61.0 (TID 242). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 242) in 28 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 61.0 (TID 244). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 61.0 (TID 244) in 28 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 61.0 (TID 245). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 61.0 (TID 246). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 61.0 (TID 245) in 14 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 61.0 (TID 246) in 11 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 61 (treeAggregate at LogisticRegression.scala:1670) finished in 0.014 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 62)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 3.7 KB, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 62 (MapPartitionsRDD[152] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 247, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 248, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 62.0 (TID 248)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 62.0 (TID 247)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 62.0 (TID 248). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 248) in 6 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 62.0 (TID 247). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 247) in 10 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 62 (treeAggregate at LogisticRegression.scala:1670) finished in 0.010 s
18/01/24 16:09:08 INFO DAGScheduler: Job 31 finished: treeAggregate at LogisticRegression.scala:1670, took 0.055311 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(93) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 1.71890e-05 (rel: 0.742) 2.27142e-05
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 80.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 96 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 154 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 32 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 64 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 63)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[154] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.4 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[154] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 63.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 249, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 250, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 251, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 252, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 63.0 (TID 249)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 63.0 (TID 251)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 63.0 (TID 249). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 63.0 (TID 252)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 63.0 (TID 251). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 63.0 (TID 250)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 63.0 (TID 252). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 63.0 (TID 250). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 63.0 (TID 253, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 249) in 16 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 63.0 (TID 254, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 251) in 15 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 252) in 15 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 63.0 (TID 253)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 250) in 17 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 63.0 (TID 254)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 63.0 (TID 254). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 63.0 (TID 254) in 10 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 63.0 (TID 253). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 63.0 (TID 253) in 19 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 63 (treeAggregate at LogisticRegression.scala:1670) finished in 0.034 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 64)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[156] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 3.7 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.4 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 64 (MapPartitionsRDD[156] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 255, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 256, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 64.0 (TID 255)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 64.0 (TID 256)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 64.0 (TID 255). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 64.0 (TID 256). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 255) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 256) in 5 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 64 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:08 INFO DAGScheduler: Job 32 finished: treeAggregate at LogisticRegression.scala:1670, took 0.048915 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(96) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 1.13187e-05 (rel: 0.342) 1.36677e-05
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 80.0 B, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.4 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 99 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 158 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 33 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 66 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[158] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[158] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 65.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 257, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 258, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 259, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 260, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 65.0 (TID 260)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 65.0 (TID 259)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 65.0 (TID 257)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 65.0 (TID 257). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 65.0 (TID 258)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 65.0 (TID 261, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 257) in 9 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 65.0 (TID 261)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 65.0 (TID 260). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 65.0 (TID 262, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 65.0 (TID 260) in 14 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 65.0 (TID 259). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 65.0 (TID 262)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 65.0 (TID 259) in 15 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 65.0 (TID 261). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 65.0 (TID 261) in 8 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 65.0 (TID 262). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 65.0 (TID 258). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 65.0 (TID 262) in 12 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 258) in 26 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 65 (treeAggregate at LogisticRegression.scala:1670) finished in 0.025 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 66)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[160] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 3.7 KB, free 359.3 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 66 (MapPartitionsRDD[160] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 66.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 263, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 264, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 66.0 (TID 264)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 66.0 (TID 263)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 66.0 (TID 264). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 264) in 6 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 66.0 (TID 263). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 263) in 9 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 66 (treeAggregate at LogisticRegression.scala:1670) finished in 0.009 s
18/01/24 16:09:08 INFO DAGScheduler: Job 33 finished: treeAggregate at LogisticRegression.scala:1670, took 0.045813 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(99) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 5.12563e-06 (rel: 0.547) 5.30138e-06
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 80.0 B, free 359.3 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 102 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 23
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 162 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 34 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 68 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[162] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 48.3 KB, free 359.4 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.3 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 24
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 25
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 26
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 27
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 28
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 29
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[162] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 67.0 with 6 tasks
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 266, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 267, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 268, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 67.0 (TID 266)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 67.0 (TID 265)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 67.0 (TID 267)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 67.0 (TID 268)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 67.0 (TID 267). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 67.0 (TID 266). 2479 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 269, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 67.0 (TID 269)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 67.0 (TID 267) in 21 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 67.0 (TID 268). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 67.0 (TID 265). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 30
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 67.0 (TID 270, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 67.0 (TID 268) in 25 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 265) in 26 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 67.0 (TID 270)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 266) in 25 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 67.0 (TID 269). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 67.0 (TID 269) in 10 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 67.0 (TID 270). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 31
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 67.0 (TID 270) in 7 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 67 (treeAggregate at LogisticRegression.scala:1670) finished in 0.034 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 68)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[164] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO ContextCleaner: Cleaned shuffle 32
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 360.7 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 68 (MapPartitionsRDD[164] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 68.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 271, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 272, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 68.0 (TID 271)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 68.0 (TID 272)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 68.0 (TID 271). 3236 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 271) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 68.0 (TID 272). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 272) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 68 (treeAggregate at LogisticRegression.scala:1670) finished in 0.003 s
18/01/24 16:09:08 INFO DAGScheduler: Job 34 finished: treeAggregate at LogisticRegression.scala:1670, took 0.061844 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(102) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 2.68531e-06 (rel: 0.476) 2.44764e-06
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 80.0 B, free 360.0 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 162.0 B, free 360.0 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.7 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.7 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 105 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 166 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 35 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 70 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 69)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[166] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[166] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 69.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 273, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 274, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 275, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 276, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 69.0 (TID 273)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 69.0 (TID 275)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 69.0 (TID 276)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 69.0 (TID 274)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 69.0 (TID 274). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 277, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 69.0 (TID 277)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 274) in 16 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 69.0 (TID 273). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 4.0 in stage 69.0 (TID 277). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 69.0 (TID 275). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 69.0 (TID 276). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 278, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 69.0 (TID 278)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 273) in 25 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 276) in 27 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 275) in 28 ms on localhost (executor driver) (4/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 277) in 13 ms on localhost (executor driver) (5/6)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 69.0 (TID 278). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 278) in 8 ms on localhost (executor driver) (6/6)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ShuffleMapStage 69 (treeAggregate at LogisticRegression.scala:1670) finished in 0.016 s
18/01/24 16:09:08 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:08 INFO DAGScheduler: running: Set()
18/01/24 16:09:08 INFO DAGScheduler: waiting: Set(ResultStage 70)
18/01/24 16:09:08 INFO DAGScheduler: failed: Set()
18/01/24 16:09:08 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[168] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 3.7 KB, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (MapPartitionsRDD[168] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 279, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 280, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 70.0 (TID 279)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 70.0 (TID 280)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 0.0 in stage 70.0 (TID 279). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 279) in 2 ms on localhost (executor driver) (1/2)
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 70.0 (TID 280). 3323 bytes result sent to driver
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 280) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
18/01/24 16:09:08 INFO DAGScheduler: ResultStage 70 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:08 INFO DAGScheduler: Job 35 finished: treeAggregate at LogisticRegression.scala:1670, took 0.046959 s
18/01/24 16:09:08 INFO TorrentBroadcast: Destroying Broadcast(105) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:08 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:08 INFO LBFGS: Val and Grad Norm: 1.32839e-06 (rel: 0.505) 1.04316e-06
18/01/24 16:09:08 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 80.0 B, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.9 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 108 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:08 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:08 INFO DAGScheduler: Registering RDD 170 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Got job 36 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:08 INFO DAGScheduler: Final stage: ResultStage 72 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
18/01/24 16:09:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
18/01/24 16:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[170] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 48.3 KB, free 359.9 MB)
18/01/24 16:09:08 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:08 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:08 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[170] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:08 INFO TaskSchedulerImpl: Adding task set 71.0 with 6 tasks
18/01/24 16:09:08 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 281, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 282, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 283, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 284, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:08 INFO Executor: Running task 2.0 in stage 71.0 (TID 283)
18/01/24 16:09:08 INFO Executor: Running task 1.0 in stage 71.0 (TID 282)
18/01/24 16:09:08 INFO Executor: Running task 0.0 in stage 71.0 (TID 281)
18/01/24 16:09:08 INFO Executor: Running task 3.0 in stage 71.0 (TID 284)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:08 INFO Executor: Finished task 3.0 in stage 71.0 (TID 284). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO Executor: Finished task 2.0 in stage 71.0 (TID 283). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:08 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 285, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:08 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 286, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:08 INFO Executor: Running task 4.0 in stage 71.0 (TID 285)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 283) in 11 ms on localhost (executor driver) (1/6)
18/01/24 16:09:08 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 284) in 11 ms on localhost (executor driver) (2/6)
18/01/24 16:09:08 INFO Executor: Running task 5.0 in stage 71.0 (TID 286)
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:08 INFO Executor: Finished task 1.0 in stage 71.0 (TID 282). 2392 bytes result sent to driver
18/01/24 16:09:08 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:08 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 282) in 18 ms on localhost (executor driver) (3/6)
18/01/24 16:09:08 INFO Executor: Finished task 5.0 in stage 71.0 (TID 286). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 71.0 (TID 281). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Finished task 4.0 in stage 71.0 (TID 285). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 286) in 16 ms on localhost (executor driver) (4/6)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 285) in 19 ms on localhost (executor driver) (5/6)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 281) in 27 ms on localhost (executor driver) (6/6)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ShuffleMapStage 71 (treeAggregate at LogisticRegression.scala:1670) finished in 0.027 s
18/01/24 16:09:09 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:09 INFO DAGScheduler: running: Set()
18/01/24 16:09:09 INFO DAGScheduler: waiting: Set(ResultStage 72)
18/01/24 16:09:09 INFO DAGScheduler: failed: Set()
18/01/24 16:09:09 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[172] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (MapPartitionsRDD[172] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 287, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 288, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 72.0 (TID 288)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 72.0 (TID 288). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 288) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 72.0 (TID 287)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 72.0 (TID 287). 3331 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 287) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ResultStage 72 (treeAggregate at LogisticRegression.scala:1670) finished in 0.006 s
18/01/24 16:09:09 INFO DAGScheduler: Job 36 finished: treeAggregate at LogisticRegression.scala:1670, took 0.041276 s
18/01/24 16:09:09 INFO TorrentBroadcast: Destroying Broadcast(108) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:09 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:09 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:09 INFO LBFGS: Val and Grad Norm: 6.71425e-07 (rel: 0.495) 4.47254e-07
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 111 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:09 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:09 INFO DAGScheduler: Registering RDD 174 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Got job 37 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:09 INFO DAGScheduler: Final stage: ResultStage 74 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
18/01/24 16:09:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
18/01/24 16:09:09 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[174] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 48.3 KB, free 359.8 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.8 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[174] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 73.0 with 6 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 289, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 290, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 2.0 in stage 73.0 (TID 291, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 3.0 in stage 73.0 (TID 292, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO Executor: Running task 2.0 in stage 73.0 (TID 291)
18/01/24 16:09:09 INFO Executor: Running task 3.0 in stage 73.0 (TID 292)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 73.0 (TID 290)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 73.0 (TID 289)
18/01/24 16:09:09 INFO Executor: Finished task 3.0 in stage 73.0 (TID 292). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:09 INFO TaskSetManager: Starting task 4.0 in stage 73.0 (TID 293, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 3.0 in stage 73.0 (TID 292) in 8 ms on localhost (executor driver) (1/6)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:09 INFO Executor: Finished task 2.0 in stage 73.0 (TID 291). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Running task 4.0 in stage 73.0 (TID 293)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 5.0 in stage 73.0 (TID 294, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 2.0 in stage 73.0 (TID 291) in 14 ms on localhost (executor driver) (2/6)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:09 INFO Executor: Running task 5.0 in stage 73.0 (TID 294)
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 73.0 (TID 290). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 290) in 20 ms on localhost (executor driver) (3/6)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 73.0 (TID 289). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 289) in 23 ms on localhost (executor driver) (4/6)
18/01/24 16:09:09 INFO Executor: Finished task 4.0 in stage 73.0 (TID 293). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 4.0 in stage 73.0 (TID 293) in 17 ms on localhost (executor driver) (5/6)
18/01/24 16:09:09 INFO Executor: Finished task 5.0 in stage 73.0 (TID 294). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 5.0 in stage 73.0 (TID 294) in 15 ms on localhost (executor driver) (6/6)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ShuffleMapStage 73 (treeAggregate at LogisticRegression.scala:1670) finished in 0.028 s
18/01/24 16:09:09 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:09 INFO DAGScheduler: running: Set()
18/01/24 16:09:09 INFO DAGScheduler: waiting: Set(ResultStage 74)
18/01/24 16:09:09 INFO DAGScheduler: failed: Set()
18/01/24 16:09:09 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[176] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 3.7 KB, free 359.8 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.8 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 74 (MapPartitionsRDD[176] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 74.0 with 2 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 295, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 296, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 74.0 (TID 296)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 74.0 (TID 295)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 74.0 (TID 295). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 295) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 74.0 (TID 296). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 296) in 8 ms on localhost (executor driver) (2/2)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ResultStage 74 (treeAggregate at LogisticRegression.scala:1670) finished in 0.009 s
18/01/24 16:09:09 INFO DAGScheduler: Job 37 finished: treeAggregate at LogisticRegression.scala:1670, took 0.044234 s
18/01/24 16:09:09 INFO TorrentBroadcast: Destroying Broadcast(111) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:09 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:09 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:09 INFO LBFGS: Val and Grad Norm: 3.36416e-07 (rel: 0.499) 1.83983e-07
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 80.0 B, free 359.8 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.8 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 114 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:09 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:09 INFO DAGScheduler: Registering RDD 178 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Got job 38 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:09 INFO DAGScheduler: Final stage: ResultStage 76 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
18/01/24 16:09:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)
18/01/24 16:09:09 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[178] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 48.3 KB, free 359.7 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.7 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[178] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 75.0 with 6 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 297, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 298, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 299, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 300, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 75.0 (TID 297)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 75.0 (TID 298)
18/01/24 16:09:09 INFO Executor: Running task 2.0 in stage 75.0 (TID 299)
18/01/24 16:09:09 INFO Executor: Running task 3.0 in stage 75.0 (TID 300)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 75.0 (TID 298). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 301, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:09 INFO Executor: Running task 4.0 in stage 75.0 (TID 301)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 298) in 10 ms on localhost (executor driver) (1/6)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 75.0 (TID 297). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 302, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 297) in 14 ms on localhost (executor driver) (2/6)
18/01/24 16:09:09 INFO Executor: Running task 5.0 in stage 75.0 (TID 302)
18/01/24 16:09:09 INFO Executor: Finished task 3.0 in stage 75.0 (TID 300). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Finished task 2.0 in stage 75.0 (TID 299). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:09 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 300) in 19 ms on localhost (executor driver) (3/6)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 299) in 19 ms on localhost (executor driver) (4/6)
18/01/24 16:09:09 INFO Executor: Finished task 4.0 in stage 75.0 (TID 301). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 301) in 13 ms on localhost (executor driver) (5/6)
18/01/24 16:09:09 INFO Executor: Finished task 5.0 in stage 75.0 (TID 302). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 302) in 9 ms on localhost (executor driver) (6/6)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ShuffleMapStage 75 (treeAggregate at LogisticRegression.scala:1670) finished in 0.023 s
18/01/24 16:09:09 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:09 INFO DAGScheduler: running: Set()
18/01/24 16:09:09 INFO DAGScheduler: waiting: Set(ResultStage 76)
18/01/24 16:09:09 INFO DAGScheduler: failed: Set()
18/01/24 16:09:09 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[180] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 3.7 KB, free 359.7 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.7 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 76 (MapPartitionsRDD[180] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 303, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 304, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 76.0 (TID 304)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 76.0 (TID 303)
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 76.0 (TID 304). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 304) in 2 ms on localhost (executor driver) (1/2)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 76.0 (TID 303). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 303) in 6 ms on localhost (executor driver) (2/2)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ResultStage 76 (treeAggregate at LogisticRegression.scala:1670) finished in 0.005 s
18/01/24 16:09:09 INFO DAGScheduler: Job 38 finished: treeAggregate at LogisticRegression.scala:1670, took 0.035809 s
18/01/24 16:09:09 INFO TorrentBroadcast: Destroying Broadcast(114) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:09 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:09 INFO LBFGS: Val and Grad Norm: 1.69082e-07 (rel: 0.324) 7.26021e-08
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 80.0 B, free 359.7 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.7 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.6 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 117 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:09 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:09 INFO DAGScheduler: Registering RDD 182 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Got job 39 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:09 INFO DAGScheduler: Final stage: ResultStage 78 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
18/01/24 16:09:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 77)
18/01/24 16:09:09 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[182] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[182] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 77.0 with 6 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 305, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 306, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 307, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 308, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO Executor: Running task 3.0 in stage 77.0 (TID 308)
18/01/24 16:09:09 INFO Executor: Running task 2.0 in stage 77.0 (TID 307)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 77.0 (TID 305)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 77.0 (TID 306)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:09 INFO Executor: Finished task 3.0 in stage 77.0 (TID 308). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 77.0 (TID 306). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 77.0 (TID 305). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 309, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 310, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 308) in 15 ms on localhost (executor driver) (1/6)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 306) in 15 ms on localhost (executor driver) (2/6)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 305) in 15 ms on localhost (executor driver) (3/6)
18/01/24 16:09:09 INFO Executor: Running task 4.0 in stage 77.0 (TID 309)
18/01/24 16:09:09 INFO Executor: Finished task 2.0 in stage 77.0 (TID 307). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 307) in 16 ms on localhost (executor driver) (4/6)
18/01/24 16:09:09 INFO Executor: Running task 5.0 in stage 77.0 (TID 310)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:09 INFO Executor: Finished task 4.0 in stage 77.0 (TID 309). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 309) in 9 ms on localhost (executor driver) (5/6)
18/01/24 16:09:09 INFO Executor: Finished task 5.0 in stage 77.0 (TID 310). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 310) in 10 ms on localhost (executor driver) (6/6)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ShuffleMapStage 77 (treeAggregate at LogisticRegression.scala:1670) finished in 0.023 s
18/01/24 16:09:09 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:09 INFO DAGScheduler: running: Set()
18/01/24 16:09:09 INFO DAGScheduler: waiting: Set(ResultStage 78)
18/01/24 16:09:09 INFO DAGScheduler: failed: Set()
18/01/24 16:09:09 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[184] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.6 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (MapPartitionsRDD[184] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 311, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 312, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 78.0 (TID 312)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 78.0 (TID 311)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 78.0 (TID 312). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 312) in 2 ms on localhost (executor driver) (1/2)
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 78.0 (TID 311). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 311) in 4 ms on localhost (executor driver) (2/2)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ResultStage 78 (treeAggregate at LogisticRegression.scala:1670) finished in 0.004 s
18/01/24 16:09:09 INFO DAGScheduler: Job 39 finished: treeAggregate at LogisticRegression.scala:1670, took 0.035810 s
18/01/24 16:09:09 INFO TorrentBroadcast: Destroying Broadcast(117) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:09 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:09 INFO LBFGS: Val and Grad Norm: 8.48587e-08 (rel: 0.163) 2.66355e-08
18/01/24 16:09:09 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 80.0 B, free 359.6 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 162.0 B, free 359.6 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:33521 (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 120 from broadcast at LogisticRegression.scala:1657
18/01/24 16:09:09 INFO SparkContext: Starting job: treeAggregate at LogisticRegression.scala:1670
18/01/24 16:09:09 INFO DAGScheduler: Registering RDD 186 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Got job 40 (treeAggregate at LogisticRegression.scala:1670) with 2 output partitions
18/01/24 16:09:09 INFO DAGScheduler: Final stage: ResultStage 80 (treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
18/01/24 16:09:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 79)
18/01/24 16:09:09 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[186] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 48.3 KB, free 359.6 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 19.6 KB, free 359.6 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 360.5 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[186] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 79.0 with 6 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 313, localhost, executor driver, partition 0, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 314, localhost, executor driver, partition 1, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 315, localhost, executor driver, partition 2, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 316, localhost, executor driver, partition 3, PROCESS_LOCAL, 6650 bytes)
18/01/24 16:09:09 INFO Executor: Running task 2.0 in stage 79.0 (TID 315)
18/01/24 16:09:09 INFO Executor: Running task 3.0 in stage 79.0 (TID 316)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 79.0 (TID 314)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 79.0 (TID 313)
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_2 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_0 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_3 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_1 locally
18/01/24 16:09:09 INFO Executor: Finished task 3.0 in stage 79.0 (TID 316). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Finished task 2.0 in stage 79.0 (TID 315). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 317, localhost, executor driver, partition 4, PROCESS_LOCAL, 6652 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 316) in 12 ms on localhost (executor driver) (1/6)
18/01/24 16:09:09 INFO Executor: Running task 4.0 in stage 79.0 (TID 317)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 318, localhost, executor driver, partition 5, PROCESS_LOCAL, 6651 bytes)
18/01/24 16:09:09 INFO Executor: Running task 5.0 in stage 79.0 (TID 318)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 315) in 13 ms on localhost (executor driver) (2/6)
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 79.0 (TID 313). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_4 locally
18/01/24 16:09:09 INFO BlockManager: Found block rdd_28_5 locally
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 313) in 16 ms on localhost (executor driver) (3/6)
18/01/24 16:09:09 INFO Executor: Finished task 4.0 in stage 79.0 (TID 317). 2479 bytes result sent to driver
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 79.0 (TID 314). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 317) in 9 ms on localhost (executor driver) (4/6)
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 314) in 22 ms on localhost (executor driver) (5/6)
18/01/24 16:09:09 INFO Executor: Finished task 5.0 in stage 79.0 (TID 318). 2392 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 318) in 9 ms on localhost (executor driver) (6/6)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ShuffleMapStage 79 (treeAggregate at LogisticRegression.scala:1670) finished in 0.023 s
18/01/24 16:09:09 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:09 INFO DAGScheduler: running: Set()
18/01/24 16:09:09 INFO DAGScheduler: waiting: Set(ResultStage 80)
18/01/24 16:09:09 INFO DAGScheduler: failed: Set()
18/01/24 16:09:09 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[188] at treeAggregate at LogisticRegression.scala:1670), which has no missing parents
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 3.7 KB, free 359.6 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 2.0 KB, free 359.5 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 360.5 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 80 (MapPartitionsRDD[188] at treeAggregate at LogisticRegression.scala:1670)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks
18/01/24 16:09:09 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 319, localhost, executor driver, partition 0, ANY, 5818 bytes)
18/01/24 16:09:09 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 320, localhost, executor driver, partition 1, ANY, 5818 bytes)
18/01/24 16:09:09 INFO Executor: Running task 1.0 in stage 80.0 (TID 320)
18/01/24 16:09:09 INFO Executor: Running task 0.0 in stage 80.0 (TID 319)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 1.0 in stage 80.0 (TID 320). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 320) in 3 ms on localhost (executor driver) (1/2)
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 6 blocks
18/01/24 16:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:09 INFO Executor: Finished task 0.0 in stage 80.0 (TID 319). 3323 bytes result sent to driver
18/01/24 16:09:09 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 319) in 9 ms on localhost (executor driver) (2/2)
18/01/24 16:09:09 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/01/24 16:09:09 INFO DAGScheduler: ResultStage 80 (treeAggregate at LogisticRegression.scala:1670) finished in 0.009 s
18/01/24 16:09:09 INFO DAGScheduler: Job 40 finished: treeAggregate at LogisticRegression.scala:1670, took 0.037985 s
18/01/24 16:09:09 INFO TorrentBroadcast: Destroying Broadcast(120) (from destroy at LogisticRegression.scala:1711)
18/01/24 16:09:09 INFO LBFGS: Step Size: 1.000
18/01/24 16:09:09 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:33521 in memory (size: 162.0 B, free: 360.5 MB)
18/01/24 16:09:09 INFO LBFGS: Val and Grad Norm: 4.25996e-08 (rel: 0.0819) 8.69939e-09
18/01/24 16:09:09 INFO LBFGS: Converged because gradient converged
18/01/24 16:09:09 INFO TorrentBroadcast: Destroying Broadcast(5) (from destroy at LogisticRegression.scala:566)
18/01/24 16:09:09 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:33521 in memory (size: 85.0 B, free: 360.5 MB)
18/01/24 16:09:09 INFO MapPartitionsRDD: Removing RDD 28 from persistence list
18/01/24 16:09:09 INFO BlockManager: Removing RDD 28
18/01/24 16:09:09 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:09:09 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:09:09 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, dayofmonth: string, dayofweek: string, deptime: string ... 27 more fields>
18/01/24 16:09:09 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:09:09 INFO CodeGenerator: Code generated in 66.336678 ms
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 293.9 KB, free 364.8 MB)
18/01/24 16:09:09 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.8 MB)
18/01/24 16:09:09 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:33521 (size: 23.9 KB, free: 366.1 MB)
18/01/24 16:09:09 INFO SparkContext: Created broadcast 123 from rdd at LogisticRegression.scala:1176
18/01/24 16:09:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:09:09 INFO Instrumentation: LogisticRegression-logistic_regression_610474782d95-1552963405-1: training finished
18/01/24 16:09:17 INFO SparkContext: Starting job: sortByKey at BinaryClassificationMetrics.scala:155
18/01/24 16:09:17 INFO DAGScheduler: Registering RDD 193 (map at LogisticRegression.scala:1176)
18/01/24 16:09:17 INFO DAGScheduler: Got job 41 (sortByKey at BinaryClassificationMetrics.scala:155) with 6 output partitions
18/01/24 16:09:17 INFO DAGScheduler: Final stage: ResultStage 82 (sortByKey at BinaryClassificationMetrics.scala:155)
18/01/24 16:09:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
18/01/24 16:09:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
18/01/24 16:09:17 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[193] at map at LogisticRegression.scala:1176), which has no missing parents
18/01/24 16:09:17 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 55.6 KB, free 364.7 MB)
18/01/24 16:09:17 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 22.2 KB, free 364.7 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:33521 (size: 22.2 KB, free: 366.0 MB)
18/01/24 16:09:17 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:17 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[193] at map at LogisticRegression.scala:1176)
18/01/24 16:09:17 INFO TaskSchedulerImpl: Adding task set 81.0 with 6 tasks
18/01/24 16:09:17 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 321, localhost, executor driver, partition 0, PROCESS_LOCAL, 6646 bytes)
18/01/24 16:09:17 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 322, localhost, executor driver, partition 1, PROCESS_LOCAL, 6646 bytes)
18/01/24 16:09:17 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 323, localhost, executor driver, partition 2, PROCESS_LOCAL, 6646 bytes)
18/01/24 16:09:17 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 324, localhost, executor driver, partition 3, PROCESS_LOCAL, 6646 bytes)
18/01/24 16:09:17 INFO Executor: Running task 0.0 in stage 81.0 (TID 321)
18/01/24 16:09:17 INFO Executor: Running task 3.0 in stage 81.0 (TID 324)
18/01/24 16:09:17 INFO Executor: Running task 1.0 in stage 81.0 (TID 322)
18/01/24 16:09:17 INFO Executor: Running task 2.0 in stage 81.0 (TID 323)
18/01/24 16:09:17 INFO CodeGenerator: Code generated in 17.736422 ms
18/01/24 16:09:17 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_7.csv, range: 0-60303224, partition values: [empty row]
18/01/24 16:09:17 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_5.csv, range: 0-58235665, partition values: [empty row]
18/01/24 16:09:17 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_8.csv, range: 0-58779678, partition values: [empty row]
18/01/24 16:09:17 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_4.csv, range: 0-57382100, partition values: [empty row]
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 33
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 34
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 35
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 36
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 37
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.1 MB)
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 38
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.2 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.2 MB)
18/01/24 16:09:17 INFO ContextCleaner: Cleaned shuffle 39
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.2 MB)
18/01/24 16:09:17 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.2 MB)
18/01/24 16:09:19 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:09:19 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:09:19 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:09:19 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:09:21 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:09:21 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:09:22 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:09:22 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:09:24 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:09:24 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:09:24 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:09:24 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:09:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_1.csv, range: 0-58119869, partition values: [empty row]
18/01/24 16:09:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_2.csv, range: 0-54560133, partition values: [empty row]
18/01/24 16:09:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_6.csv, range: 0-58449479, partition values: [empty row]
18/01/24 16:09:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_3.csv, range: 0-59109692, partition values: [empty row]
18/01/24 16:09:27 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:09:27 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:09:27 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:09:27 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:09:30 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:09:30 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:09:30 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:09:30 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:09:32 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:09:33 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:09:33 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:09:33 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:09:36 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (6  times so far)
18/01/24 16:09:38 INFO Executor: Finished task 2.0 in stage 81.0 (TID 323). 2469 bytes result sent to driver
18/01/24 16:09:38 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 325, localhost, executor driver, partition 4, PROCESS_LOCAL, 6648 bytes)
18/01/24 16:09:38 INFO Executor: Running task 4.0 in stage 81.0 (TID 325)
18/01/24 16:09:38 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 323) in 21739 ms on localhost (executor driver) (1/6)
18/01/24 16:09:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_10.csv, range: 0-53984260, partition values: [empty row]
18/01/24 16:09:39 INFO Executor: Finished task 3.0 in stage 81.0 (TID 324). 2469 bytes result sent to driver
18/01/24 16:09:39 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 326, localhost, executor driver, partition 5, PROCESS_LOCAL, 6647 bytes)
18/01/24 16:09:39 INFO Executor: Running task 5.0 in stage 81.0 (TID 326)
18/01/24 16:09:39 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 324) in 22389 ms on localhost (executor driver) (2/6)
18/01/24 16:09:39 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_9.csv, range: 0-51858178, partition values: [empty row]
18/01/24 16:09:39 INFO Executor: Finished task 1.0 in stage 81.0 (TID 322). 2469 bytes result sent to driver
18/01/24 16:09:39 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 322) in 22492 ms on localhost (executor driver) (3/6)
18/01/24 16:09:40 INFO Executor: Finished task 0.0 in stage 81.0 (TID 321). 2469 bytes result sent to driver
18/01/24 16:09:40 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 321) in 23526 ms on localhost (executor driver) (4/6)
18/01/24 16:09:41 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 168.0 MB to disk (0  time so far)
18/01/24 16:09:42 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 168.0 MB to disk (0  time so far)
18/01/24 16:09:44 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_12.csv, range: 0-52930976, partition values: [empty row]
18/01/24 16:09:44 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_11.csv, range: 0-50867158, partition values: [empty row]
18/01/24 16:09:45 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 168.0 MB to disk (1  time so far)
18/01/24 16:09:45 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 168.0 MB to disk (1  time so far)
18/01/24 16:09:48 INFO UnsafeExternalSorter: Thread 95 spilling sort data of 168.0 MB to disk (2  times so far)
18/01/24 16:09:48 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 168.0 MB to disk (2  times so far)
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 81.0 (TID 326). 2469 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 326) in 11483 ms on localhost (executor driver) (5/6)
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 81.0 (TID 325). 2469 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 325) in 12366 ms on localhost (executor driver) (6/6)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ShuffleMapStage 81 (map at LogisticRegression.scala:1176) finished in 34.104 s
18/01/24 16:09:51 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:51 INFO DAGScheduler: running: Set()
18/01/24 16:09:51 INFO DAGScheduler: waiting: Set(ResultStage 82)
18/01/24 16:09:51 INFO DAGScheduler: failed: Set()
18/01/24 16:09:51 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[196] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 3.6 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:51 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 82 (MapPartitionsRDD[196] at sortByKey at BinaryClassificationMetrics.scala:155)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Adding task set 82.0 with 6 tasks
18/01/24 16:09:51 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 327, localhost, executor driver, partition 0, ANY, 5814 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 328, localhost, executor driver, partition 1, ANY, 5814 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 329, localhost, executor driver, partition 2, ANY, 5814 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 330, localhost, executor driver, partition 3, ANY, 5814 bytes)
18/01/24 16:09:51 INFO Executor: Running task 0.0 in stage 82.0 (TID 327)
18/01/24 16:09:51 INFO Executor: Running task 1.0 in stage 82.0 (TID 328)
18/01/24 16:09:51 INFO Executor: Running task 3.0 in stage 82.0 (TID 330)
18/01/24 16:09:51 INFO Executor: Running task 2.0 in stage 82.0 (TID 329)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 0.0 in stage 82.0 (TID 327). 2219 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 1.0 in stage 82.0 (TID 328). 2259 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 4.0 in stage 82.0 (TID 331, localhost, executor driver, partition 4, ANY, 5814 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 5.0 in stage 82.0 (TID 332, localhost, executor driver, partition 5, ANY, 5814 bytes)
18/01/24 16:09:51 INFO Executor: Running task 5.0 in stage 82.0 (TID 332)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 328) in 8 ms on localhost (executor driver) (1/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 327) in 8 ms on localhost (executor driver) (2/6)
18/01/24 16:09:51 INFO Executor: Finished task 3.0 in stage 82.0 (TID 330). 2211 bytes result sent to driver
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Running task 4.0 in stage 82.0 (TID 331)
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 82.0 (TID 332). 2060 bytes result sent to driver
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 330) in 11 ms on localhost (executor driver) (3/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 82.0 (TID 332) in 5 ms on localhost (executor driver) (4/6)
18/01/24 16:09:51 INFO Executor: Finished task 2.0 in stage 82.0 (TID 329). 2123 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 329) in 12 ms on localhost (executor driver) (5/6)
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 82.0 (TID 331). 2107 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 82.0 (TID 331) in 6 ms on localhost (executor driver) (6/6)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ResultStage 82 (sortByKey at BinaryClassificationMetrics.scala:155) finished in 0.014 s
18/01/24 16:09:51 INFO DAGScheduler: Job 41 finished: sortByKey at BinaryClassificationMetrics.scala:155, took 34.129518 s
18/01/24 16:09:51 INFO SparkContext: Starting job: count at BinaryClassificationMetrics.scala:163
18/01/24 16:09:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 163 bytes
18/01/24 16:09:51 INFO DAGScheduler: Registering RDD 194 (combineByKey at BinaryClassificationMetrics.scala:151)
18/01/24 16:09:51 INFO DAGScheduler: Got job 42 (count at BinaryClassificationMetrics.scala:163) with 6 output partitions
18/01/24 16:09:51 INFO DAGScheduler: Final stage: ResultStage 85 (count at BinaryClassificationMetrics.scala:163)
18/01/24 16:09:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
18/01/24 16:09:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
18/01/24 16:09:51 INFO DAGScheduler: Submitting ShuffleMapStage 84 (ShuffledRDD[194] at combineByKey at BinaryClassificationMetrics.scala:151), which has no missing parents
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 3.4 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 1933.0 B, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:33521 (size: 1933.0 B, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:51 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 84 (ShuffledRDD[194] at combineByKey at BinaryClassificationMetrics.scala:151)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Adding task set 84.0 with 6 tasks
18/01/24 16:09:51 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 333, localhost, executor driver, partition 0, ANY, 5715 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 334, localhost, executor driver, partition 1, ANY, 5715 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 335, localhost, executor driver, partition 2, ANY, 5715 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 336, localhost, executor driver, partition 3, ANY, 5715 bytes)
18/01/24 16:09:51 INFO Executor: Running task 0.0 in stage 84.0 (TID 333)
18/01/24 16:09:51 INFO Executor: Running task 3.0 in stage 84.0 (TID 336)
18/01/24 16:09:51 INFO Executor: Running task 1.0 in stage 84.0 (TID 334)
18/01/24 16:09:51 INFO Executor: Running task 2.0 in stage 84.0 (TID 335)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 2.0 in stage 84.0 (TID 335). 2051 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 4.0 in stage 84.0 (TID 337, localhost, executor driver, partition 4, ANY, 5715 bytes)
18/01/24 16:09:51 INFO Executor: Running task 4.0 in stage 84.0 (TID 337)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 335) in 14 ms on localhost (executor driver) (1/6)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 3.0 in stage 84.0 (TID 336). 2051 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 84.0 (TID 337). 2051 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 5.0 in stage 84.0 (TID 338, localhost, executor driver, partition 5, ANY, 5715 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 336) in 18 ms on localhost (executor driver) (2/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 84.0 (TID 337) in 5 ms on localhost (executor driver) (3/6)
18/01/24 16:09:51 INFO Executor: Running task 5.0 in stage 84.0 (TID 338)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 84.0 (TID 338). 1964 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 1.0 in stage 84.0 (TID 334). 2051 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 0.0 in stage 84.0 (TID 333). 2051 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 84.0 (TID 338) in 6 ms on localhost (executor driver) (4/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 334) in 25 ms on localhost (executor driver) (5/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 333) in 26 ms on localhost (executor driver) (6/6)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ShuffleMapStage 84 (combineByKey at BinaryClassificationMetrics.scala:151) finished in 0.027 s
18/01/24 16:09:51 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:09:51 INFO DAGScheduler: running: Set()
18/01/24 16:09:51 INFO DAGScheduler: waiting: Set(ResultStage 85)
18/01/24 16:09:51 INFO DAGScheduler: failed: Set()
18/01/24 16:09:51 INFO DAGScheduler: Submitting ResultStage 85 (ShuffledRDD[197] at sortByKey at BinaryClassificationMetrics.scala:155), which has no missing parents
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 3.1 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 1884.0 B, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:33521 (size: 1884.0 B, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:51 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 85 (ShuffledRDD[197] at sortByKey at BinaryClassificationMetrics.scala:155)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Adding task set 85.0 with 6 tasks
18/01/24 16:09:51 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 339, localhost, executor driver, partition 0, ANY, 5726 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 340, localhost, executor driver, partition 1, ANY, 5726 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 2.0 in stage 85.0 (TID 341, localhost, executor driver, partition 2, ANY, 5726 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 3.0 in stage 85.0 (TID 342, localhost, executor driver, partition 3, ANY, 5726 bytes)
18/01/24 16:09:51 INFO Executor: Running task 3.0 in stage 85.0 (TID 342)
18/01/24 16:09:51 INFO Executor: Running task 0.0 in stage 85.0 (TID 339)
18/01/24 16:09:51 INFO Executor: Running task 1.0 in stage 85.0 (TID 340)
18/01/24 16:09:51 INFO Executor: Running task 2.0 in stage 85.0 (TID 341)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 2.0 in stage 85.0 (TID 341). 1760 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 0.0 in stage 85.0 (TID 339). 1760 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 1.0 in stage 85.0 (TID 340). 1760 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 3.0 in stage 85.0 (TID 342). 1760 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 4.0 in stage 85.0 (TID 343, localhost, executor driver, partition 4, ANY, 5726 bytes)
18/01/24 16:09:51 INFO Executor: Running task 4.0 in stage 85.0 (TID 343)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 2.0 in stage 85.0 (TID 341) in 20 ms on localhost (executor driver) (1/6)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO TaskSetManager: Starting task 5.0 in stage 85.0 (TID 344, localhost, executor driver, partition 5, ANY, 5726 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 3.0 in stage 85.0 (TID 342) in 21 ms on localhost (executor driver) (2/6)
18/01/24 16:09:51 INFO Executor: Running task 5.0 in stage 85.0 (TID 344)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 340) in 23 ms on localhost (executor driver) (3/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 339) in 23 ms on localhost (executor driver) (4/6)
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 85.0 (TID 343). 1760 bytes result sent to driver
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 85.0 (TID 343) in 5 ms on localhost (executor driver) (5/6)
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 85.0 (TID 344). 1673 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 85.0 (TID 344) in 4 ms on localhost (executor driver) (6/6)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ResultStage 85 (count at BinaryClassificationMetrics.scala:163) finished in 0.012 s
18/01/24 16:09:51 INFO DAGScheduler: Job 42 finished: count at BinaryClassificationMetrics.scala:163, took 0.069243 s
18/01/24 16:09:51 INFO BinaryClassificationMetrics: Curve is too small (173) for 100 bins to be useful
18/01/24 16:09:51 INFO SparkContext: Starting job: collect at BinaryClassificationMetrics.scala:192
18/01/24 16:09:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 163 bytes
18/01/24 16:09:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 194 bytes
18/01/24 16:09:51 INFO DAGScheduler: Got job 43 (collect at BinaryClassificationMetrics.scala:192) with 6 output partitions
18/01/24 16:09:51 INFO DAGScheduler: Final stage: ResultStage 88 (collect at BinaryClassificationMetrics.scala:192)
18/01/24 16:09:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
18/01/24 16:09:51 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:51 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[199] at mapPartitions at BinaryClassificationMetrics.scala:188), which has no missing parents
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 4.0 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 2.2 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:33521 (size: 2.2 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:51 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 88 (MapPartitionsRDD[199] at mapPartitions at BinaryClassificationMetrics.scala:188)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Adding task set 88.0 with 6 tasks
18/01/24 16:09:51 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 345, localhost, executor driver, partition 0, ANY, 5812 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 346, localhost, executor driver, partition 1, ANY, 5812 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 347, localhost, executor driver, partition 2, ANY, 5812 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 3.0 in stage 88.0 (TID 348, localhost, executor driver, partition 3, ANY, 5812 bytes)
18/01/24 16:09:51 INFO Executor: Running task 1.0 in stage 88.0 (TID 346)
18/01/24 16:09:51 INFO Executor: Running task 0.0 in stage 88.0 (TID 345)
18/01/24 16:09:51 INFO Executor: Running task 2.0 in stage 88.0 (TID 347)
18/01/24 16:09:51 INFO Executor: Running task 3.0 in stage 88.0 (TID 348)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 2.0 in stage 88.0 (TID 347). 1887 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 3.0 in stage 88.0 (TID 348). 1887 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 4.0 in stage 88.0 (TID 349, localhost, executor driver, partition 4, ANY, 5812 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 347) in 6 ms on localhost (executor driver) (1/6)
18/01/24 16:09:51 INFO Executor: Running task 4.0 in stage 88.0 (TID 349)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 5.0 in stage 88.0 (TID 350, localhost, executor driver, partition 5, ANY, 5812 bytes)
18/01/24 16:09:51 INFO Executor: Running task 5.0 in stage 88.0 (TID 350)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 3.0 in stage 88.0 (TID 348) in 6 ms on localhost (executor driver) (2/6)
18/01/24 16:09:51 INFO Executor: Finished task 0.0 in stage 88.0 (TID 345). 1800 bytes result sent to driver
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 345) in 9 ms on localhost (executor driver) (3/6)
18/01/24 16:09:51 INFO Executor: Finished task 1.0 in stage 88.0 (TID 346). 1800 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 346) in 9 ms on localhost (executor driver) (4/6)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 88.0 (TID 350). 1887 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 88.0 (TID 349). 1800 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 88.0 (TID 350) in 4 ms on localhost (executor driver) (5/6)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 88.0 (TID 349) in 4 ms on localhost (executor driver) (6/6)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ResultStage 88 (collect at BinaryClassificationMetrics.scala:192) finished in 0.010 s
18/01/24 16:09:51 INFO DAGScheduler: Job 43 finished: collect at BinaryClassificationMetrics.scala:192, took 0.015789 s
18/01/24 16:09:51 INFO BinaryClassificationMetrics: Total counts: {numPos: 14759, numNeg: 55031}
18/01/24 16:09:51 INFO SparkContext: Starting job: collect at SlidingRDD.scala:81
18/01/24 16:09:51 INFO DAGScheduler: Got job 44 (collect at SlidingRDD.scala:81) with 8 output partitions
18/01/24 16:09:51 INFO DAGScheduler: Final stage: ResultStage 91 (collect at SlidingRDD.scala:81)
18/01/24 16:09:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
18/01/24 16:09:51 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:51 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[207] at mapPartitions at SlidingRDD.scala:78), which has no missing parents
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 6.1 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.2 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:33521 (size: 3.2 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:51 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 91 (MapPartitionsRDD[207] at mapPartitions at SlidingRDD.scala:78)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Adding task set 91.0 with 8 tasks
18/01/24 16:09:51 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 351, localhost, executor driver, partition 0, PROCESS_LOCAL, 6251 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 352, localhost, executor driver, partition 7, PROCESS_LOCAL, 6251 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 353, localhost, executor driver, partition 1, ANY, 5923 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 354, localhost, executor driver, partition 2, ANY, 5923 bytes)
18/01/24 16:09:51 INFO Executor: Running task 0.0 in stage 91.0 (TID 351)
18/01/24 16:09:51 INFO Executor: Running task 2.0 in stage 91.0 (TID 354)
18/01/24 16:09:51 INFO Executor: Running task 7.0 in stage 91.0 (TID 352)
18/01/24 16:09:51 INFO Executor: Finished task 7.0 in stage 91.0 (TID 352). 1159 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Running task 1.0 in stage 91.0 (TID 353)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 355, localhost, executor driver, partition 3, ANY, 5923 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 352) in 6 ms on localhost (executor driver) (1/8)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 0.0 in stage 91.0 (TID 351). 1080 bytes result sent to driver
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO MemoryStore: Block rdd_200_1 stored as values in memory (estimated size 2.4 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block rdd_200_0 stored as values in memory (estimated size 2.3 KB, free 365.2 MB)
18/01/24 16:09:51 INFO Executor: Running task 3.0 in stage 91.0 (TID 355)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 356, localhost, executor driver, partition 4, ANY, 5923 bytes)
18/01/24 16:09:51 INFO BlockManagerInfo: Added rdd_200_1 in memory on 127.0.0.1:33521 (size: 2.4 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 351) in 12 ms on localhost (executor driver) (2/8)
18/01/24 16:09:51 INFO BlockManagerInfo: Added rdd_200_0 in memory on 127.0.0.1:33521 (size: 2.3 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO Executor: Running task 4.0 in stage 91.0 (TID 356)
18/01/24 16:09:51 INFO Executor: Finished task 2.0 in stage 91.0 (TID 354). 2678 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 1.0 in stage 91.0 (TID 353). 2678 bytes result sent to driver
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO MemoryStore: Block rdd_200_2 stored as values in memory (estimated size 2.4 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added rdd_200_2 in memory on 127.0.0.1:33521 (size: 2.4 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 357, localhost, executor driver, partition 5, ANY, 5923 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 358, localhost, executor driver, partition 6, ANY, 5923 bytes)
18/01/24 16:09:51 INFO Executor: Running task 6.0 in stage 91.0 (TID 358)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 353) in 13 ms on localhost (executor driver) (3/8)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 354) in 13 ms on localhost (executor driver) (4/8)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Running task 5.0 in stage 91.0 (TID 357)
18/01/24 16:09:51 INFO MemoryStore: Block rdd_200_5 stored as values in memory (estimated size 2.4 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added rdd_200_5 in memory on 127.0.0.1:33521 (size: 2.4 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block rdd_200_3 stored as values in memory (estimated size 2.4 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added rdd_200_3 in memory on 127.0.0.1:33521 (size: 2.4 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO Executor: Finished task 6.0 in stage 91.0 (TID 358). 2678 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 358) in 4 ms on localhost (executor driver) (5/8)
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:09:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 91.0 (TID 356). 2678 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 356) in 11 ms on localhost (executor driver) (6/8)
18/01/24 16:09:51 INFO Executor: Finished task 3.0 in stage 91.0 (TID 355). 2678 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 355) in 23 ms on localhost (executor driver) (7/8)
18/01/24 16:09:51 INFO MemoryStore: Block rdd_200_4 stored as values in memory (estimated size 2.4 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:33521 in memory (size: 1884.0 B, free: 366.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added rdd_200_4 in memory on 127.0.0.1:33521 (size: 2.4 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:33521 in memory (size: 2.2 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 91.0 (TID 357). 2838 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 357) in 19 ms on localhost (executor driver) (8/8)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ResultStage 91 (collect at SlidingRDD.scala:81) finished in 0.032 s
18/01/24 16:09:51 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO DAGScheduler: Job 44 finished: collect at SlidingRDD.scala:81, took 0.040674 s
18/01/24 16:09:51 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:33521 in memory (size: 1933.0 B, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Starting job: aggregate at AreaUnderCurve.scala:45
18/01/24 16:09:51 INFO DAGScheduler: Got job 45 (aggregate at AreaUnderCurve.scala:45) with 7 output partitions
18/01/24 16:09:51 INFO DAGScheduler: Final stage: ResultStage 94 (aggregate at AreaUnderCurve.scala:45)
18/01/24 16:09:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
18/01/24 16:09:51 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:51 INFO DAGScheduler: Submitting ResultStage 94 (SlidingRDD[206] at RDD at SlidingRDD.scala:50), which has no missing parents
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 6.2 KB, free 365.2 MB)
18/01/24 16:09:51 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.3 KB, free 365.2 MB)
18/01/24 16:09:51 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:33521 (size: 3.3 KB, free: 366.2 MB)
18/01/24 16:09:51 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:51 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 94 (SlidingRDD[206] at RDD at SlidingRDD.scala:50)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Adding task set 94.0 with 7 tasks
18/01/24 16:09:51 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 359, localhost, executor driver, partition 1, PROCESS_LOCAL, 6462 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 360, localhost, executor driver, partition 2, PROCESS_LOCAL, 6462 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 361, localhost, executor driver, partition 3, PROCESS_LOCAL, 6462 bytes)
18/01/24 16:09:51 INFO TaskSetManager: Starting task 4.0 in stage 94.0 (TID 362, localhost, executor driver, partition 4, PROCESS_LOCAL, 6462 bytes)
18/01/24 16:09:51 INFO Executor: Running task 3.0 in stage 94.0 (TID 361)
18/01/24 16:09:51 INFO Executor: Running task 4.0 in stage 94.0 (TID 362)
18/01/24 16:09:51 INFO Executor: Running task 2.0 in stage 94.0 (TID 360)
18/01/24 16:09:51 INFO Executor: Running task 1.0 in stage 94.0 (TID 359)
18/01/24 16:09:51 INFO BlockManager: Found block rdd_200_3 locally
18/01/24 16:09:51 INFO Executor: Finished task 4.0 in stage 94.0 (TID 362). 1125 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 5.0 in stage 94.0 (TID 363, localhost, executor driver, partition 5, PROCESS_LOCAL, 6462 bytes)
18/01/24 16:09:51 INFO BlockManager: Found block rdd_200_1 locally
18/01/24 16:09:51 INFO TaskSetManager: Finished task 4.0 in stage 94.0 (TID 362) in 8 ms on localhost (executor driver) (1/7)
18/01/24 16:09:51 INFO BlockManager: Found block rdd_200_2 locally
18/01/24 16:09:51 INFO Executor: Finished task 2.0 in stage 94.0 (TID 360). 1125 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Running task 5.0 in stage 94.0 (TID 363)
18/01/24 16:09:51 INFO Executor: Finished task 3.0 in stage 94.0 (TID 361). 1125 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Starting task 6.0 in stage 94.0 (TID 364, localhost, executor driver, partition 6, PROCESS_LOCAL, 6462 bytes)
18/01/24 16:09:51 INFO Executor: Running task 6.0 in stage 94.0 (TID 364)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 360) in 9 ms on localhost (executor driver) (2/7)
18/01/24 16:09:51 INFO BlockManager: Found block rdd_200_0 locally
18/01/24 16:09:51 INFO BlockManager: Found block rdd_200_5 locally
18/01/24 16:09:51 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 365, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
18/01/24 16:09:51 INFO Executor: Running task 0.0 in stage 94.0 (TID 365)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 361) in 11 ms on localhost (executor driver) (3/7)
18/01/24 16:09:51 INFO Executor: Finished task 6.0 in stage 94.0 (TID 364). 1125 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 6.0 in stage 94.0 (TID 364) in 2 ms on localhost (executor driver) (4/7)
18/01/24 16:09:51 INFO BlockManager: Found block rdd_200_4 locally
18/01/24 16:09:51 INFO Executor: Finished task 0.0 in stage 94.0 (TID 365). 886 bytes result sent to driver
18/01/24 16:09:51 INFO Executor: Finished task 5.0 in stage 94.0 (TID 363). 1046 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 365) in 3 ms on localhost (executor driver) (5/7)
18/01/24 16:09:51 INFO TaskSetManager: Finished task 5.0 in stage 94.0 (TID 363) in 5 ms on localhost (executor driver) (6/7)
18/01/24 16:09:51 INFO Executor: Finished task 1.0 in stage 94.0 (TID 359). 1125 bytes result sent to driver
18/01/24 16:09:51 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 359) in 17 ms on localhost (executor driver) (7/7)
18/01/24 16:09:51 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
18/01/24 16:09:51 INFO DAGScheduler: ResultStage 94 (aggregate at AreaUnderCurve.scala:45) finished in 0.013 s
18/01/24 16:09:51 INFO DAGScheduler: Job 45 finished: aggregate at AreaUnderCurve.scala:45, took 0.020056 s
18/01/24 16:09:53 INFO CodeGenerator: Code generated in 9.425357 ms
18/01/24 16:09:53 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:09:53 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 6 output partitions
18/01/24 16:09:53 INFO DAGScheduler: Final stage: ResultStage 97 (collect at utils.scala:211)
18/01/24 16:09:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)
18/01/24 16:09:53 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:53 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[211] at collect at utils.scala:211), which has no missing parents
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 10.1 KB, free 365.2 MB)
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 4.8 KB, free 365.2 MB)
18/01/24 16:09:53 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:33521 (size: 4.8 KB, free: 366.2 MB)
18/01/24 16:09:53 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:53 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 97 (MapPartitionsRDD[211] at collect at utils.scala:211)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Adding task set 97.0 with 6 tasks
18/01/24 16:09:53 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 366, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 367, localhost, executor driver, partition 1, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 2.0 in stage 97.0 (TID 368, localhost, executor driver, partition 2, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 3.0 in stage 97.0 (TID 369, localhost, executor driver, partition 3, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO Executor: Running task 0.0 in stage 97.0 (TID 366)
18/01/24 16:09:53 INFO Executor: Running task 1.0 in stage 97.0 (TID 367)
18/01/24 16:09:53 INFO Executor: Running task 2.0 in stage 97.0 (TID 368)
18/01/24 16:09:53 INFO Executor: Running task 3.0 in stage 97.0 (TID 369)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_3 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_0 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_2 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_1 locally
18/01/24 16:09:53 INFO Executor: Finished task 3.0 in stage 97.0 (TID 369). 1956 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 2.0 in stage 97.0 (TID 368). 1955 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 1.0 in stage 97.0 (TID 367). 1956 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 0.0 in stage 97.0 (TID 366). 1927 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Starting task 4.0 in stage 97.0 (TID 370, localhost, executor driver, partition 4, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 5.0 in stage 97.0 (TID 371, localhost, executor driver, partition 5, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO Executor: Running task 5.0 in stage 97.0 (TID 371)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 3.0 in stage 97.0 (TID 369) in 9 ms on localhost (executor driver) (1/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 367) in 9 ms on localhost (executor driver) (2/6)
18/01/24 16:09:53 INFO Executor: Running task 4.0 in stage 97.0 (TID 370)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_5 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_4 locally
18/01/24 16:09:53 INFO Executor: Finished task 5.0 in stage 97.0 (TID 371). 1871 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Finished task 2.0 in stage 97.0 (TID 368) in 10 ms on localhost (executor driver) (3/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 366) in 10 ms on localhost (executor driver) (4/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 5.0 in stage 97.0 (TID 371) in 3 ms on localhost (executor driver) (5/6)
18/01/24 16:09:53 INFO Executor: Finished task 4.0 in stage 97.0 (TID 370). 1868 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Finished task 4.0 in stage 97.0 (TID 370) in 3 ms on localhost (executor driver) (6/6)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
18/01/24 16:09:53 INFO DAGScheduler: ResultStage 97 (collect at utils.scala:211) finished in 0.007 s
18/01/24 16:09:53 INFO DAGScheduler: Job 46 finished: collect at utils.scala:211, took 0.016873 s
18/01/24 16:09:53 INFO CodeGenerator: Code generated in 6.49909 ms
18/01/24 16:09:53 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:09:53 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 7 output partitions
18/01/24 16:09:53 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:211)
18/01/24 16:09:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)
18/01/24 16:09:53 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:53 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[217] at collect at utils.scala:211), which has no missing parents
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 10.8 KB, free 365.2 MB)
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 5.2 KB, free 365.2 MB)
18/01/24 16:09:53 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:33521 (size: 5.2 KB, free: 366.2 MB)
18/01/24 16:09:53 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:53 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 100 (MapPartitionsRDD[217] at collect at utils.scala:211)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Adding task set 100.0 with 7 tasks
18/01/24 16:09:53 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 372, localhost, executor driver, partition 1, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 2.0 in stage 100.0 (TID 373, localhost, executor driver, partition 2, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 3.0 in stage 100.0 (TID 374, localhost, executor driver, partition 3, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 4.0 in stage 100.0 (TID 375, localhost, executor driver, partition 4, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:53 INFO Executor: Running task 1.0 in stage 100.0 (TID 372)
18/01/24 16:09:53 INFO Executor: Running task 3.0 in stage 100.0 (TID 374)
18/01/24 16:09:53 INFO Executor: Running task 4.0 in stage 100.0 (TID 375)
18/01/24 16:09:53 INFO Executor: Running task 2.0 in stage 100.0 (TID 373)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_2 locally
18/01/24 16:09:53 INFO Executor: Finished task 3.0 in stage 100.0 (TID 374). 1751 bytes result sent to driver
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_3 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_1 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_0 locally
18/01/24 16:09:53 INFO Executor: Finished task 4.0 in stage 100.0 (TID 375). 1674 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 2.0 in stage 100.0 (TID 373). 1674 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 1.0 in stage 100.0 (TID 372). 1679 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Starting task 5.0 in stage 100.0 (TID 376, localhost, executor driver, partition 5, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:53 INFO Executor: Running task 5.0 in stage 100.0 (TID 376)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 6.0 in stage 100.0 (TID 377, localhost, executor driver, partition 6, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:53 INFO Executor: Running task 6.0 in stage 100.0 (TID 377)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 378, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 4.0 in stage 100.0 (TID 375) in 5 ms on localhost (executor driver) (1/7)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 2.0 in stage 100.0 (TID 373) in 5 ms on localhost (executor driver) (2/7)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 372) in 6 ms on localhost (executor driver) (3/7)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_5 locally
18/01/24 16:09:53 INFO TaskSetManager: Finished task 3.0 in stage 100.0 (TID 374) in 5 ms on localhost (executor driver) (4/7)
18/01/24 16:09:53 INFO Executor: Finished task 6.0 in stage 100.0 (TID 377). 1670 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Running task 0.0 in stage 100.0 (TID 378)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_4 locally
18/01/24 16:09:53 INFO Executor: Finished task 5.0 in stage 100.0 (TID 376). 1672 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 0.0 in stage 100.0 (TID 378). 1217 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Finished task 6.0 in stage 100.0 (TID 377) in 3 ms on localhost (executor driver) (5/7)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 5.0 in stage 100.0 (TID 376) in 3 ms on localhost (executor driver) (6/7)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 378) in 4 ms on localhost (executor driver) (7/7)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/01/24 16:09:53 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:211) finished in 0.009 s
18/01/24 16:09:53 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.014445 s
18/01/24 16:09:53 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:09:53 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 6 output partitions
18/01/24 16:09:53 INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:211)
18/01/24 16:09:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
18/01/24 16:09:53 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:53 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[221] at collect at utils.scala:211), which has no missing parents
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 10.1 KB, free 365.2 MB)
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.2 MB)
18/01/24 16:09:53 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:33521 (size: 4.7 KB, free: 366.2 MB)
18/01/24 16:09:53 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:53 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 103 (MapPartitionsRDD[221] at collect at utils.scala:211)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Adding task set 103.0 with 6 tasks
18/01/24 16:09:53 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 379, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 380, localhost, executor driver, partition 1, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 381, localhost, executor driver, partition 2, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 382, localhost, executor driver, partition 3, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO Executor: Running task 0.0 in stage 103.0 (TID 379)
18/01/24 16:09:53 INFO Executor: Running task 3.0 in stage 103.0 (TID 382)
18/01/24 16:09:53 INFO Executor: Running task 2.0 in stage 103.0 (TID 381)
18/01/24 16:09:53 INFO Executor: Running task 1.0 in stage 103.0 (TID 380)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_1 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_3 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_2 locally
18/01/24 16:09:53 INFO Executor: Finished task 3.0 in stage 103.0 (TID 382). 1964 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 2.0 in stage 103.0 (TID 381). 1879 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 383, localhost, executor driver, partition 4, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 384, localhost, executor driver, partition 5, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 381) in 6 ms on localhost (executor driver) (1/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 382) in 5 ms on localhost (executor driver) (2/6)
18/01/24 16:09:53 INFO Executor: Running task 5.0 in stage 103.0 (TID 384)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_0 locally
18/01/24 16:09:53 INFO Executor: Finished task 0.0 in stage 103.0 (TID 379). 1806 bytes result sent to driver
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_5 locally
18/01/24 16:09:53 INFO Executor: Finished task 1.0 in stage 103.0 (TID 380). 1962 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Running task 4.0 in stage 103.0 (TID 383)
18/01/24 16:09:53 INFO Executor: Finished task 5.0 in stage 103.0 (TID 384). 1863 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 379) in 8 ms on localhost (executor driver) (3/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 380) in 8 ms on localhost (executor driver) (4/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 384) in 2 ms on localhost (executor driver) (5/6)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_4 locally
18/01/24 16:09:53 INFO Executor: Finished task 4.0 in stage 103.0 (TID 383). 1874 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 383) in 4 ms on localhost (executor driver) (6/6)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
18/01/24 16:09:53 INFO DAGScheduler: ResultStage 103 (collect at utils.scala:211) finished in 0.008 s
18/01/24 16:09:53 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 0.013573 s
18/01/24 16:09:53 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61045aabec81
18/01/24 16:09:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61045aabec81` AS `zzz6`
WHERE (0 = 1)
18/01/24 16:09:53 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:09:53 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 6 output partitions
18/01/24 16:09:53 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:211)
18/01/24 16:09:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
18/01/24 16:09:53 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:53 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[226] at collect at utils.scala:211), which has no missing parents
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 10.1 KB, free 365.1 MB)
18/01/24 16:09:53 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 4.7 KB, free 365.1 MB)
18/01/24 16:09:53 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:33521 (size: 4.7 KB, free: 366.2 MB)
18/01/24 16:09:53 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:53 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 106 (MapPartitionsRDD[226] at collect at utils.scala:211)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Adding task set 106.0 with 6 tasks
18/01/24 16:09:53 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 385, localhost, executor driver, partition 0, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 386, localhost, executor driver, partition 1, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 2.0 in stage 106.0 (TID 387, localhost, executor driver, partition 2, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 3.0 in stage 106.0 (TID 388, localhost, executor driver, partition 3, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO Executor: Running task 0.0 in stage 106.0 (TID 385)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_0 locally
18/01/24 16:09:53 INFO Executor: Running task 1.0 in stage 106.0 (TID 386)
18/01/24 16:09:53 INFO Executor: Running task 2.0 in stage 106.0 (TID 387)
18/01/24 16:09:53 INFO Executor: Running task 3.0 in stage 106.0 (TID 388)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_1 locally
18/01/24 16:09:53 INFO Executor: Finished task 0.0 in stage 106.0 (TID 385). 1805 bytes result sent to driver
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_3 locally
18/01/24 16:09:53 INFO Executor: Finished task 1.0 in stage 106.0 (TID 386). 1785 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 3.0 in stage 106.0 (TID 388). 1705 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Starting task 4.0 in stage 106.0 (TID 389, localhost, executor driver, partition 4, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO TaskSetManager: Starting task 5.0 in stage 106.0 (TID 390, localhost, executor driver, partition 5, PROCESS_LOCAL, 5841 bytes)
18/01/24 16:09:53 INFO Executor: Running task 5.0 in stage 106.0 (TID 390)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 386) in 5 ms on localhost (executor driver) (1/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 3.0 in stage 106.0 (TID 388) in 5 ms on localhost (executor driver) (2/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 385) in 6 ms on localhost (executor driver) (3/6)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_5 locally
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_2 locally
18/01/24 16:09:53 INFO Executor: Finished task 5.0 in stage 106.0 (TID 390). 1695 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Finished task 2.0 in stage 106.0 (TID 387). 1705 bytes result sent to driver
18/01/24 16:09:53 INFO Executor: Running task 4.0 in stage 106.0 (TID 389)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 5.0 in stage 106.0 (TID 390) in 2 ms on localhost (executor driver) (4/6)
18/01/24 16:09:53 INFO TaskSetManager: Finished task 2.0 in stage 106.0 (TID 387) in 7 ms on localhost (executor driver) (5/6)
18/01/24 16:09:53 INFO BlockManager: Found block rdd_200_4 locally
18/01/24 16:09:53 INFO Executor: Finished task 4.0 in stage 106.0 (TID 389). 1706 bytes result sent to driver
18/01/24 16:09:53 INFO TaskSetManager: Finished task 4.0 in stage 106.0 (TID 389) in 4 ms on localhost (executor driver) (6/6)
18/01/24 16:09:53 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
18/01/24 16:09:53 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:211) finished in 0.009 s
18/01/24 16:09:53 INFO DAGScheduler: Job 49 finished: collect at utils.scala:211, took 0.014870 s
18/01/24 16:09:54 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:09:54 INFO DAGScheduler: Got job 50 (collect at utils.scala:211) with 8 output partitions
18/01/24 16:09:54 INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:211)
18/01/24 16:09:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)
18/01/24 16:09:54 INFO DAGScheduler: Missing parents: List()
18/01/24 16:09:54 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[233] at collect at utils.scala:211), which has no missing parents
18/01/24 16:09:54 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 10.9 KB, free 365.1 MB)
18/01/24 16:09:54 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 5.2 KB, free 365.1 MB)
18/01/24 16:09:54 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:33521 (size: 5.2 KB, free: 366.1 MB)
18/01/24 16:09:54 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:54 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 109 (MapPartitionsRDD[233] at collect at utils.scala:211)
18/01/24 16:09:54 INFO TaskSchedulerImpl: Adding task set 109.0 with 8 tasks
18/01/24 16:09:54 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 391, localhost, executor driver, partition 1, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:54 INFO TaskSetManager: Starting task 2.0 in stage 109.0 (TID 392, localhost, executor driver, partition 2, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:54 INFO TaskSetManager: Starting task 3.0 in stage 109.0 (TID 393, localhost, executor driver, partition 3, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:54 INFO TaskSetManager: Starting task 4.0 in stage 109.0 (TID 394, localhost, executor driver, partition 4, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:54 INFO Executor: Running task 1.0 in stage 109.0 (TID 391)
18/01/24 16:09:54 INFO Executor: Running task 3.0 in stage 109.0 (TID 393)
18/01/24 16:09:54 INFO Executor: Running task 4.0 in stage 109.0 (TID 394)
18/01/24 16:09:54 INFO Executor: Running task 2.0 in stage 109.0 (TID 392)
18/01/24 16:09:54 INFO BlockManager: Found block rdd_200_3 locally
18/01/24 16:09:54 INFO Executor: Finished task 4.0 in stage 109.0 (TID 394). 1686 bytes result sent to driver
18/01/24 16:09:54 INFO TaskSetManager: Starting task 5.0 in stage 109.0 (TID 395, localhost, executor driver, partition 5, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:54 INFO BlockManager: Found block rdd_200_0 locally
18/01/24 16:09:54 INFO TaskSetManager: Finished task 4.0 in stage 109.0 (TID 394) in 3 ms on localhost (executor driver) (1/8)
18/01/24 16:09:54 INFO Executor: Finished task 1.0 in stage 109.0 (TID 391). 1755 bytes result sent to driver
18/01/24 16:09:54 INFO BlockManager: Found block rdd_200_2 locally
18/01/24 16:09:54 INFO Executor: Finished task 3.0 in stage 109.0 (TID 393). 1771 bytes result sent to driver
18/01/24 16:09:54 INFO TaskSetManager: Starting task 6.0 in stage 109.0 (TID 396, localhost, executor driver, partition 6, PROCESS_LOCAL, 5950 bytes)
18/01/24 16:09:54 INFO Executor: Running task 6.0 in stage 109.0 (TID 396)
18/01/24 16:09:54 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 397, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
18/01/24 16:09:54 INFO Executor: Running task 0.0 in stage 109.0 (TID 397)
18/01/24 16:09:54 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 391) in 7 ms on localhost (executor driver) (2/8)
18/01/24 16:09:54 INFO TaskSetManager: Finished task 3.0 in stage 109.0 (TID 393) in 6 ms on localhost (executor driver) (3/8)
18/01/24 16:09:54 INFO BlockManager: Found block rdd_200_1 locally
18/01/24 16:09:54 INFO BlockManager: Found block rdd_200_5 locally
18/01/24 16:09:54 INFO Executor: Finished task 2.0 in stage 109.0 (TID 392). 1775 bytes result sent to driver
18/01/24 16:09:54 INFO Executor: Finished task 6.0 in stage 109.0 (TID 396). 1682 bytes result sent to driver
18/01/24 16:09:54 INFO Executor: Finished task 0.0 in stage 109.0 (TID 397). 1216 bytes result sent to driver
18/01/24 16:09:54 INFO TaskSetManager: Starting task 7.0 in stage 109.0 (TID 398, localhost, executor driver, partition 7, PROCESS_LOCAL, 6278 bytes)
18/01/24 16:09:54 INFO TaskSetManager: Finished task 2.0 in stage 109.0 (TID 392) in 8 ms on localhost (executor driver) (4/8)
18/01/24 16:09:54 INFO Executor: Running task 5.0 in stage 109.0 (TID 395)
18/01/24 16:09:54 INFO BlockManager: Found block rdd_200_4 locally
18/01/24 16:09:54 INFO Executor: Finished task 5.0 in stage 109.0 (TID 395). 1761 bytes result sent to driver
18/01/24 16:09:54 INFO TaskSetManager: Finished task 6.0 in stage 109.0 (TID 396) in 5 ms on localhost (executor driver) (5/8)
18/01/24 16:09:54 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 397) in 5 ms on localhost (executor driver) (6/8)
18/01/24 16:09:54 INFO Executor: Running task 7.0 in stage 109.0 (TID 398)
18/01/24 16:09:54 INFO TaskSetManager: Finished task 5.0 in stage 109.0 (TID 395) in 8 ms on localhost (executor driver) (7/8)
18/01/24 16:09:54 INFO Executor: Finished task 7.0 in stage 109.0 (TID 398). 1224 bytes result sent to driver
18/01/24 16:09:54 INFO TaskSetManager: Finished task 7.0 in stage 109.0 (TID 398) in 5 ms on localhost (executor driver) (8/8)
18/01/24 16:09:54 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
18/01/24 16:09:54 INFO DAGScheduler: ResultStage 109 (collect at utils.scala:211) finished in 0.013 s
18/01/24 16:09:54 INFO DAGScheduler: Job 50 finished: collect at utils.scala:211, took 0.016902 s
18/01/24 16:09:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610455547202`
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_f7042e4d4548
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_f7042e4d4548`) `qibeoammfo`) `qkyoruvxll`
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_7642733f4ee2
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_7642733f4ee2`) `qibeoammfo`) `qkyoruvxll`
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_c17d25532520
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_c17d25532520`) `qibeoammfo`) `qkyoruvxll`
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610426d5f889
18/01/24 16:09:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610426d5f889` AS `zzz7`
WHERE (0 = 1)
18/01/24 16:09:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:56 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_610426d5f889`
GROUP BY `delayed`, `prediction`
18/01/24 16:09:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:57 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_610426d5f889`
GROUP BY `delayed`, `prediction`
18/01/24 16:09:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:57 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_610426d5f889`
GROUP BY `delayed`, `prediction`
18/01/24 16:09:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:57 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_610426d5f889`
GROUP BY `delayed`, `prediction`
18/01/24 16:09:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:59 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_610426d5f889`
GROUP BY `delayed`, `prediction`
18/01/24 16:09:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:09:59 INFO SparkSqlParser: Parsing command: SELECT `delayed`, `prediction`, count(*) AS `n`
FROM `sparklyr_tmp_610426d5f889`
GROUP BY `delayed`, `prediction`
LIMIT 1000
18/01/24 16:09:59 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:09:59 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:09:59 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, dayofmonth: string, dayofweek: string, deptime: string ... 27 more fields>
18/01/24 16:09:59 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:09:59 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 48.469395 ms
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 62.648075 ms
18/01/24 16:09:59 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 293.9 KB, free 364.8 MB)
18/01/24 16:09:59 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.8 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:33521 (size: 23.9 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO SparkContext: Created broadcast 136 from collect at utils.scala:211
18/01/24 16:09:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:09:59 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:09:59 INFO DAGScheduler: Registering RDD 244 (collect at utils.scala:211)
18/01/24 16:09:59 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 1 output partitions
18/01/24 16:09:59 INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:211)
18/01/24 16:09:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
18/01/24 16:09:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
18/01/24 16:09:59 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[244] at collect at utils.scala:211), which has no missing parents
18/01/24 16:09:59 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 62.1 KB, free 364.7 MB)
18/01/24 16:09:59 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 25.7 KB, free 364.7 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:33521 (size: 25.7 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:996
18/01/24 16:09:59 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[244] at collect at utils.scala:211)
18/01/24 16:09:59 INFO TaskSchedulerImpl: Adding task set 110.0 with 6 tasks
18/01/24 16:09:59 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 399, localhost, executor driver, partition 0, PROCESS_LOCAL, 6587 bytes)
18/01/24 16:09:59 INFO TaskSetManager: Starting task 1.0 in stage 110.0 (TID 400, localhost, executor driver, partition 1, PROCESS_LOCAL, 6587 bytes)
18/01/24 16:09:59 INFO TaskSetManager: Starting task 2.0 in stage 110.0 (TID 401, localhost, executor driver, partition 2, PROCESS_LOCAL, 6587 bytes)
18/01/24 16:09:59 INFO TaskSetManager: Starting task 3.0 in stage 110.0 (TID 402, localhost, executor driver, partition 3, PROCESS_LOCAL, 6587 bytes)
18/01/24 16:09:59 INFO Executor: Running task 1.0 in stage 110.0 (TID 400)
18/01/24 16:09:59 INFO Executor: Running task 0.0 in stage 110.0 (TID 399)
18/01/24 16:09:59 INFO Executor: Running task 2.0 in stage 110.0 (TID 401)
18/01/24 16:09:59 INFO Executor: Running task 3.0 in stage 110.0 (TID 402)
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 6.095684 ms
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 4.449236 ms
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 22.254215 ms
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 10.662867 ms
18/01/24 16:09:59 INFO CodeGenerator: Code generated in 7.029944 ms
18/01/24 16:09:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_5.csv, range: 0-58235665, partition values: [empty row]
18/01/24 16:09:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_7.csv, range: 0-60303224, partition values: [empty row]
18/01/24 16:09:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_4.csv, range: 0-57382100, partition values: [empty row]
18/01/24 16:09:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_8.csv, range: 0-58779678, partition values: [empty row]
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:33521 in memory (size: 5.2 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:33521 in memory (size: 4.7 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:33521 in memory (size: 4.7 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:33521 in memory (size: 5.2 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:33521 in memory (size: 3.2 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:33521 in memory (size: 3.3 KB, free: 366.1 MB)
18/01/24 16:09:59 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:33521 in memory (size: 4.8 KB, free: 366.1 MB)
18/01/24 16:10:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:01 INFO UnsafeExternalSorter: Thread 100 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:10:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:01 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:10:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:01 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:10:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:02 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (0  time so far)
18/01/24 16:10:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:04 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:10:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:05 INFO UnsafeExternalSorter: Thread 100 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:10:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:05 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:10:05 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:05 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (1  time so far)
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 11841
18/01/24 16:10:07 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:33521 in memory (size: 22.2 KB, free: 366.1 MB)
18/01/24 16:10:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:33521 in memory (size: 19.5 KB, free: 366.2 MB)
18/01/24 16:10:07 INFO ContextCleaner: Cleaned shuffle 0
18/01/24 16:10:07 INFO BlockManager: Removing RDD 28
18/01/24 16:10:07 INFO ContextCleaner: Cleaned RDD 28
18/01/24 16:10:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:33521 in memory (size: 23.9 KB, free: 366.2 MB)
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 63
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 62
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 61
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 60
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 59
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 58
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 57
18/01/24 16:10:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:33521 in memory (size: 23.9 KB, free: 366.2 MB)
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 56
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 55
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 54
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 53
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 52
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 51
18/01/24 16:10:07 INFO ContextCleaner: Cleaned accumulator 50
18/01/24 16:10:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:07 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:10:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:08 INFO UnsafeExternalSorter: Thread 100 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:10:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:08 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:10:08 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:08 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (2  times so far)
18/01/24 16:10:10 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_2.csv, range: 0-54560133, partition values: [empty row]
18/01/24 16:10:10 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_6.csv, range: 0-58449479, partition values: [empty row]
18/01/24 16:10:10 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_1.csv, range: 0-58119869, partition values: [empty row]
18/01/24 16:10:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:11 INFO UnsafeExternalSorter: Thread 100 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:10:11 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_3.csv, range: 0-59109692, partition values: [empty row]
18/01/24 16:10:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:11 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:10:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:11 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:10:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:11 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (3  times so far)
18/01/24 16:10:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:14 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:10:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:14 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:10:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:14 INFO UnsafeExternalSorter: Thread 100 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:10:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:14 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (4  times so far)
18/01/24 16:10:16 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:16 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:10:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:17 INFO UnsafeExternalSorter: Thread 100 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:10:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:17 INFO UnsafeExternalSorter: Thread 94 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:10:17 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:17 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (5  times so far)
18/01/24 16:10:20 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:20 INFO UnsafeExternalSorter: Thread 85 spilling sort data of 84.0 MB to disk (6  times so far)
18/01/24 16:10:22 INFO Executor: Finished task 3.0 in stage 110.0 (TID 402). 2821 bytes result sent to driver
18/01/24 16:10:22 INFO TaskSetManager: Starting task 4.0 in stage 110.0 (TID 403, localhost, executor driver, partition 4, PROCESS_LOCAL, 6589 bytes)
18/01/24 16:10:22 INFO Executor: Running task 4.0 in stage 110.0 (TID 403)
18/01/24 16:10:22 INFO TaskSetManager: Finished task 3.0 in stage 110.0 (TID 402) in 22869 ms on localhost (executor driver) (1/6)
18/01/24 16:10:22 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_10.csv, range: 0-53984260, partition values: [empty row]
18/01/24 16:10:23 INFO Executor: Finished task 1.0 in stage 110.0 (TID 400). 2821 bytes result sent to driver
18/01/24 16:10:23 INFO TaskSetManager: Starting task 5.0 in stage 110.0 (TID 404, localhost, executor driver, partition 5, PROCESS_LOCAL, 6588 bytes)
18/01/24 16:10:23 INFO TaskSetManager: Finished task 1.0 in stage 110.0 (TID 400) in 23570 ms on localhost (executor driver) (2/6)
18/01/24 16:10:23 INFO Executor: Running task 5.0 in stage 110.0 (TID 404)
18/01/24 16:10:23 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_9.csv, range: 0-51858178, partition values: [empty row]
18/01/24 16:10:23 INFO Executor: Finished task 2.0 in stage 110.0 (TID 401). 2821 bytes result sent to driver
18/01/24 16:10:23 INFO TaskSetManager: Finished task 2.0 in stage 110.0 (TID 401) in 24028 ms on localhost (executor driver) (3/6)
18/01/24 16:10:24 INFO Executor: Finished task 0.0 in stage 110.0 (TID 399). 2821 bytes result sent to driver
18/01/24 16:10:24 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 399) in 25075 ms on localhost (executor driver) (4/6)
18/01/24 16:10:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:25 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 168.0 MB to disk (0  time so far)
18/01/24 16:10:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:25 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 168.0 MB to disk (0  time so far)
18/01/24 16:10:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_12.csv, range: 0-52930976, partition values: [empty row]
18/01/24 16:10:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/data/flight_2008_11.csv, range: 0-50867158, partition values: [empty row]
18/01/24 16:10:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:29 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 168.0 MB to disk (1  time so far)
18/01/24 16:10:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:29 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 168.0 MB to disk (1  time so far)
18/01/24 16:10:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:32 INFO UnsafeExternalSorter: Thread 96 spilling sort data of 168.0 MB to disk (2  times so far)
18/01/24 16:10:33 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.
18/01/24 16:10:33 INFO UnsafeExternalSorter: Thread 105 spilling sort data of 168.0 MB to disk (2  times so far)
18/01/24 16:10:35 INFO Executor: Finished task 4.0 in stage 110.0 (TID 403). 2821 bytes result sent to driver
18/01/24 16:10:35 INFO TaskSetManager: Finished task 4.0 in stage 110.0 (TID 403) in 13354 ms on localhost (executor driver) (5/6)
18/01/24 16:10:36 INFO Executor: Finished task 5.0 in stage 110.0 (TID 404). 2821 bytes result sent to driver
18/01/24 16:10:36 INFO TaskSetManager: Finished task 5.0 in stage 110.0 (TID 404) in 13008 ms on localhost (executor driver) (6/6)
18/01/24 16:10:36 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
18/01/24 16:10:36 INFO DAGScheduler: ShuffleMapStage 110 (collect at utils.scala:211) finished in 36.571 s
18/01/24 16:10:36 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:10:36 INFO DAGScheduler: running: Set()
18/01/24 16:10:36 INFO DAGScheduler: waiting: Set(ResultStage 111)
18/01/24 16:10:36 INFO DAGScheduler: failed: Set()
18/01/24 16:10:36 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[247] at collect at utils.scala:211), which has no missing parents
18/01/24 16:10:36 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 42.9 KB, free 365.5 MB)
18/01/24 16:10:36 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 19.6 KB, free 365.5 MB)
18/01/24 16:10:36 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 366.2 MB)
18/01/24 16:10:36 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[247] at collect at utils.scala:211)
18/01/24 16:10:36 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
18/01/24 16:10:36 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 405, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
18/01/24 16:10:36 INFO Executor: Running task 0.0 in stage 111.0 (TID 405)
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 6 blocks
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:10:36 INFO Executor: Finished task 0.0 in stage 111.0 (TID 405). 3193 bytes result sent to driver
18/01/24 16:10:36 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 405) in 8 ms on localhost (executor driver) (1/1)
18/01/24 16:10:36 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
18/01/24 16:10:36 INFO DAGScheduler: ResultStage 111 (collect at utils.scala:211) finished in 0.009 s
18/01/24 16:10:36 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 36.599547 s
18/01/24 16:10:36 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:10:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 156 bytes
18/01/24 16:10:36 INFO DAGScheduler: Got job 52 (collect at utils.scala:211) with 3 output partitions
18/01/24 16:10:36 INFO DAGScheduler: Final stage: ResultStage 113 (collect at utils.scala:211)
18/01/24 16:10:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
18/01/24 16:10:36 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:36 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[247] at collect at utils.scala:211), which has no missing parents
18/01/24 16:10:36 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 42.9 KB, free 365.5 MB)
18/01/24 16:10:36 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 19.6 KB, free 365.5 MB)
18/01/24 16:10:36 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:33521 (size: 19.6 KB, free: 366.2 MB)
18/01/24 16:10:36 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:36 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 113 (MapPartitionsRDD[247] at collect at utils.scala:211)
18/01/24 16:10:36 INFO TaskSchedulerImpl: Adding task set 113.0 with 3 tasks
18/01/24 16:10:36 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 406, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
18/01/24 16:10:36 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 407, localhost, executor driver, partition 3, PROCESS_LOCAL, 5860 bytes)
18/01/24 16:10:36 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 408, localhost, executor driver, partition 2, ANY, 5860 bytes)
18/01/24 16:10:36 INFO Executor: Running task 0.0 in stage 113.0 (TID 406)
18/01/24 16:10:36 INFO Executor: Running task 1.0 in stage 113.0 (TID 408)
18/01/24 16:10:36 INFO Executor: Running task 2.0 in stage 113.0 (TID 407)
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 6 blocks
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 6 blocks
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:10:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 16:10:36 INFO Executor: Finished task 0.0 in stage 113.0 (TID 406). 3280 bytes result sent to driver
18/01/24 16:10:36 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 406) in 6 ms on localhost (executor driver) (1/3)
18/01/24 16:10:36 INFO Executor: Finished task 2.0 in stage 113.0 (TID 407). 3193 bytes result sent to driver
18/01/24 16:10:36 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 407) in 6 ms on localhost (executor driver) (2/3)
18/01/24 16:10:36 INFO Executor: Finished task 1.0 in stage 113.0 (TID 408). 3226 bytes result sent to driver
18/01/24 16:10:36 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 408) in 7 ms on localhost (executor driver) (3/3)
18/01/24 16:10:36 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
18/01/24 16:10:36 INFO DAGScheduler: ResultStage 113 (collect at utils.scala:211) finished in 0.009 s
18/01/24 16:10:36 INFO DAGScheduler: Job 52 finished: collect at utils.scala:211, took 0.013093 s
18/01/24 16:10:36 INFO CodeGenerator: Code generated in 7.965018 ms
18/01/24 16:10:39 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/01/24 16:10:39 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/01/24 16:10:39 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/01/24 16:10:39 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/01/24 16:10:39 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:39 INFO DAGScheduler: Got job 53 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:39 INFO DAGScheduler: Final stage: ResultStage 114 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:39 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:39 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[249] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 71.4 KB, free 365.4 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 25.6 KB, free 365.4 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.2 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[249] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 409, localhost, executor driver, partition 0, PROCESS_LOCAL, 6321 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 114.0 (TID 409)
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161039_0114_m_000000_409' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata/_temporary/0/task_20180124161039_0114_m_000000
18/01/24 16:10:39 INFO SparkHadoopMapRedUtil: attempt_20180124161039_0114_m_000000_409: Committed
18/01/24 16:10:39 INFO Executor: Finished task 0.0 in stage 114.0 (TID 409). 1093 bytes result sent to driver
18/01/24 16:10:39 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 409) in 40 ms on localhost (executor driver) (1/1)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
18/01/24 16:10:39 INFO DAGScheduler: ResultStage 114 (saveAsTextFile at ReadWrite.scala:275) finished in 0.041 s
18/01/24 16:10:39 INFO DAGScheduler: Job 53 finished: saveAsTextFile at ReadWrite.scala:275, took 0.053793 s
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:39 INFO DAGScheduler: Got job 54 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:39 INFO DAGScheduler: Final stage: ResultStage 115 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:39 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:39 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[251] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 71.5 KB, free 365.3 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 25.6 KB, free 365.3 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[251] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 410, localhost, executor driver, partition 0, PROCESS_LOCAL, 7294 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 115.0 (TID 410)
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161039_0115_m_000000_410' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/_temporary/0/task_20180124161039_0115_m_000000
18/01/24 16:10:39 INFO SparkHadoopMapRedUtil: attempt_20180124161039_0115_m_000000_410: Committed
18/01/24 16:10:39 INFO Executor: Finished task 0.0 in stage 115.0 (TID 410). 1093 bytes result sent to driver
18/01/24 16:10:39 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 410) in 12 ms on localhost (executor driver) (1/1)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
18/01/24 16:10:39 INFO DAGScheduler: ResultStage 115 (saveAsTextFile at ReadWrite.scala:275) finished in 0.011 s
18/01/24 16:10:39 INFO DAGScheduler: Job 54 finished: saveAsTextFile at ReadWrite.scala:275, took 0.020310 s
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:39 INFO DAGScheduler: Got job 55 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:39 INFO DAGScheduler: Final stage: ResultStage 116 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:39 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:39 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[253] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 71.5 KB, free 365.2 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 25.6 KB, free 365.2 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[253] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 411, localhost, executor driver, partition 0, PROCESS_LOCAL, 6231 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 116.0 (TID 411)
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161039_0116_m_000000_411' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/_temporary/0/task_20180124161039_0116_m_000000
18/01/24 16:10:39 INFO SparkHadoopMapRedUtil: attempt_20180124161039_0116_m_000000_411: Committed
18/01/24 16:10:39 INFO Executor: Finished task 0.0 in stage 116.0 (TID 411). 1093 bytes result sent to driver
18/01/24 16:10:39 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 411) in 11 ms on localhost (executor driver) (1/1)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
18/01/24 16:10:39 INFO DAGScheduler: ResultStage 116 (saveAsTextFile at ReadWrite.scala:275) finished in 0.011 s
18/01/24 16:10:39 INFO DAGScheduler: Job 55 finished: saveAsTextFile at ReadWrite.scala:275, took 0.018623 s
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:39 INFO DAGScheduler: Got job 56 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:39 INFO DAGScheduler: Final stage: ResultStage 117 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:39 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:39 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[255] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 71.5 KB, free 365.1 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 25.6 KB, free 365.1 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[255] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 412, localhost, executor driver, partition 0, PROCESS_LOCAL, 6296 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 117.0 (TID 412)
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161039_0117_m_000000_412' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/_temporary/0/task_20180124161039_0117_m_000000
18/01/24 16:10:39 INFO SparkHadoopMapRedUtil: attempt_20180124161039_0117_m_000000_412: Committed
18/01/24 16:10:39 INFO Executor: Finished task 0.0 in stage 117.0 (TID 412). 1093 bytes result sent to driver
18/01/24 16:10:39 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 412) in 18 ms on localhost (executor driver) (1/1)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
18/01/24 16:10:39 INFO DAGScheduler: ResultStage 117 (saveAsTextFile at ReadWrite.scala:275) finished in 0.018 s
18/01/24 16:10:39 INFO DAGScheduler: Job 56 finished: saveAsTextFile at ReadWrite.scala:275, took 0.026198 s
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:39 INFO DAGScheduler: Got job 57 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:39 INFO DAGScheduler: Final stage: ResultStage 118 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:39 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:39 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[257] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 71.5 KB, free 365.0 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 25.6 KB, free 365.0 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[257] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 413, localhost, executor driver, partition 0, PROCESS_LOCAL, 6218 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 118.0 (TID 413)
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161039_0118_m_000000_413' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/_temporary/0/task_20180124161039_0118_m_000000
18/01/24 16:10:39 INFO SparkHadoopMapRedUtil: attempt_20180124161039_0118_m_000000_413: Committed
18/01/24 16:10:39 INFO Executor: Finished task 0.0 in stage 118.0 (TID 413). 1093 bytes result sent to driver
18/01/24 16:10:39 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 413) in 14 ms on localhost (executor driver) (1/1)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
18/01/24 16:10:39 INFO DAGScheduler: ResultStage 118 (saveAsTextFile at ReadWrite.scala:275) finished in 0.014 s
18/01/24 16:10:39 INFO DAGScheduler: Job 57 finished: saveAsTextFile at ReadWrite.scala:275, took 0.022804 s
18/01/24 16:10:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:39 INFO CodeGenerator: Code generated in 8.384992 ms
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:39 INFO SparkContext: Starting job: parquet at RFormula.scala:325
18/01/24 16:10:39 INFO DAGScheduler: Registering RDD 260 (parquet at RFormula.scala:325)
18/01/24 16:10:39 INFO DAGScheduler: Got job 58 (parquet at RFormula.scala:325) with 1 output partitions
18/01/24 16:10:39 INFO DAGScheduler: Final stage: ResultStage 120 (parquet at RFormula.scala:325)
18/01/24 16:10:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
18/01/24 16:10:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
18/01/24 16:10:39 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[260] at parquet at RFormula.scala:325), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 4.9 KB, free 365.0 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 3.0 KB, free 365.0 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:33521 (size: 3.0 KB, free: 366.0 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[260] at parquet at RFormula.scala:325)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 414, localhost, executor driver, partition 0, PROCESS_LOCAL, 6340 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 119.0 (TID 414)
18/01/24 16:10:39 INFO Executor: Finished task 0.0 in stage 119.0 (TID 414). 1554 bytes result sent to driver
18/01/24 16:10:39 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 414) in 4 ms on localhost (executor driver) (1/1)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
18/01/24 16:10:39 INFO DAGScheduler: ShuffleMapStage 119 (parquet at RFormula.scala:325) finished in 0.003 s
18/01/24 16:10:39 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:10:39 INFO DAGScheduler: running: Set()
18/01/24 16:10:39 INFO DAGScheduler: waiting: Set(ResultStage 120)
18/01/24 16:10:39 INFO DAGScheduler: failed: Set()
18/01/24 16:10:39 INFO DAGScheduler: Submitting ResultStage 120 (ShuffledRowRDD[261] at parquet at RFormula.scala:325), which has no missing parents
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 76.6 KB, free 364.9 MB)
18/01/24 16:10:39 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 28.3 KB, free 364.9 MB)
18/01/24 16:10:39 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:33521 (size: 28.3 KB, free: 366.0 MB)
18/01/24 16:10:39 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (ShuffledRowRDD[261] at parquet at RFormula.scala:325)
18/01/24 16:10:39 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
18/01/24 16:10:39 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 415, localhost, executor driver, partition 0, ANY, 5954 bytes)
18/01/24 16:10:39 INFO Executor: Running task 0.0 in stage 120.0 (TID 415)
18/01/24 16:10:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/01/24 16:10:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
18/01/24 16:10:40 INFO CodecPool: Got brand-new compressor [.snappy]
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161039_0120_m_000000_0' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/data/_temporary/0/task_20180124161039_0120_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161039_0120_m_000000_0: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 120.0 (TID 415). 2022 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 415) in 268 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 120 (parquet at RFormula.scala:325) finished in 0.269 s
18/01/24 16:10:40 INFO DAGScheduler: Job 58 finished: parquet at RFormula.scala:325, took 0.288674 s
18/01/24 16:10:40 INFO FileFormatWriter: Job null committed.
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:40 INFO DAGScheduler: Got job 59 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 121 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[264] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 71.5 KB, free 364.8 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 25.6 KB, free 364.8 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.0 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[264] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 416, localhost, executor driver, partition 0, PROCESS_LOCAL, 6267 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 121.0 (TID 416)
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0121_m_000000_416' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata/_temporary/0/task_20180124161040_0121_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0121_m_000000_416: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 121.0 (TID 416). 1093 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 416) in 13 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 121 (saveAsTextFile at ReadWrite.scala:275) finished in 0.014 s
18/01/24 16:10:40 INFO DAGScheduler: Job 59 finished: saveAsTextFile at ReadWrite.scala:275, took 0.025068 s
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:40 INFO DAGScheduler: Got job 60 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 122 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[266] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 71.5 KB, free 364.7 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 25.6 KB, free 364.7 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 366.0 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[266] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 417, localhost, executor driver, partition 0, PROCESS_LOCAL, 6234 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 122.0 (TID 417)
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0122_m_000000_417' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/_temporary/0/task_20180124161040_0122_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0122_m_000000_417: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 122.0 (TID 417). 1093 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 417) in 13 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 122 (saveAsTextFile at ReadWrite.scala:275) finished in 0.013 s
18/01/24 16:10:40 INFO DAGScheduler: Job 60 finished: saveAsTextFile at ReadWrite.scala:275, took 0.021662 s
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:40 INFO DAGScheduler: Got job 61 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 123 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[268] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 71.5 KB, free 364.6 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 25.6 KB, free 364.6 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.9 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[268] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 418, localhost, executor driver, partition 0, PROCESS_LOCAL, 6194 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 123.0 (TID 418)
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0123_m_000000_418' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/_temporary/0/task_20180124161040_0123_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0123_m_000000_418: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 123.0 (TID 418). 1093 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 418) in 26 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 123 (saveAsTextFile at ReadWrite.scala:275) finished in 0.026 s
18/01/24 16:10:40 INFO DAGScheduler: Job 61 finished: saveAsTextFile at ReadWrite.scala:275, took 0.034910 s
18/01/24 16:10:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO CodeGenerator: Code generated in 21.512705 ms
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO SparkContext: Starting job: parquet at RFormula.scala:490
18/01/24 16:10:40 INFO DAGScheduler: Registering RDD 271 (parquet at RFormula.scala:490)
18/01/24 16:10:40 INFO DAGScheduler: Got job 62 (parquet at RFormula.scala:490) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 125 (parquet at RFormula.scala:490)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 124)
18/01/24 16:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[271] at parquet at RFormula.scala:490), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 4.8 KB, free 364.6 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 2.9 KB, free 364.6 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:33521 (size: 2.9 KB, free: 365.9 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[271] at parquet at RFormula.scala:490)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 419, localhost, executor driver, partition 0, PROCESS_LOCAL, 6261 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 124.0 (TID 419)
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 124.0 (TID 419). 1554 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 419) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ShuffleMapStage 124 (parquet at RFormula.scala:490) finished in 0.003 s
18/01/24 16:10:40 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:10:40 INFO DAGScheduler: running: Set()
18/01/24 16:10:40 INFO DAGScheduler: waiting: Set(ResultStage 125)
18/01/24 16:10:40 INFO DAGScheduler: failed: Set()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 125 (ShuffledRowRDD[272] at parquet at RFormula.scala:490), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 76.6 KB, free 364.5 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 28.4 KB, free 364.5 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:33521 (size: 28.4 KB, free: 365.9 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (ShuffledRowRDD[272] at parquet at RFormula.scala:490)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 420, localhost, executor driver, partition 0, ANY, 5955 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 125.0 (TID 420)
18/01/24 16:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/01/24 16:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
18/01/24 16:10:40 INFO CodecPool: Got brand-new compressor [.snappy]
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0125_m_000000_0' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/data/_temporary/0/task_20180124161040_0125_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0125_m_000000_0: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 125.0 (TID 420). 1935 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 420) in 32 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 125 (parquet at RFormula.scala:490) finished in 0.032 s
18/01/24 16:10:40 INFO DAGScheduler: Job 62 finished: parquet at RFormula.scala:490, took 0.053858 s
18/01/24 16:10:40 INFO FileFormatWriter: Job null committed.
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:40 INFO DAGScheduler: Got job 63 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 126 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[275] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 71.5 KB, free 364.4 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 25.6 KB, free 364.4 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.9 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[275] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 421, localhost, executor driver, partition 0, PROCESS_LOCAL, 6177 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 126.0 (TID 421)
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0126_m_000000_421' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/_temporary/0/task_20180124161040_0126_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0126_m_000000_421: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 126.0 (TID 421). 1093 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 421) in 16 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 126 (saveAsTextFile at ReadWrite.scala:275) finished in 0.017 s
18/01/24 16:10:40 INFO DAGScheduler: Job 63 finished: saveAsTextFile at ReadWrite.scala:275, took 0.053652 s
18/01/24 16:10:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO CodeGenerator: Code generated in 9.006885 ms
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO SparkContext: Starting job: parquet at RFormula.scala:399
18/01/24 16:10:40 INFO DAGScheduler: Registering RDD 278 (parquet at RFormula.scala:399)
18/01/24 16:10:40 INFO DAGScheduler: Got job 64 (parquet at RFormula.scala:399) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 128 (parquet at RFormula.scala:399)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 127)
18/01/24 16:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[278] at parquet at RFormula.scala:399), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 4.8 KB, free 364.4 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 2.9 KB, free 364.4 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:33521 (size: 2.9 KB, free: 365.9 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[278] at parquet at RFormula.scala:399)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 422, localhost, executor driver, partition 0, PROCESS_LOCAL, 6229 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 127.0 (TID 422)
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 127.0 (TID 422). 1554 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 422) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ShuffleMapStage 127 (parquet at RFormula.scala:399) finished in 0.003 s
18/01/24 16:10:40 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:10:40 INFO DAGScheduler: running: Set()
18/01/24 16:10:40 INFO DAGScheduler: waiting: Set(ResultStage 128)
18/01/24 16:10:40 INFO DAGScheduler: failed: Set()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 128 (ShuffledRowRDD[279] at parquet at RFormula.scala:399), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 76.4 KB, free 364.3 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 28.3 KB, free 364.3 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:33521 (size: 28.3 KB, free: 365.9 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (ShuffledRowRDD[279] at parquet at RFormula.scala:399)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 423, localhost, executor driver, partition 0, ANY, 5955 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 128.0 (TID 423)
18/01/24 16:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/01/24 16:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
18/01/24 16:10:40 INFO CodecPool: Got brand-new compressor [.snappy]
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0128_m_000000_0' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/data/_temporary/0/task_20180124161040_0128_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0128_m_000000_0: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 128.0 (TID 423). 1935 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 423) in 15 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 128 (parquet at RFormula.scala:399) finished in 0.016 s
18/01/24 16:10:40 INFO DAGScheduler: Job 64 finished: parquet at RFormula.scala:399, took 0.033008 s
18/01/24 16:10:40 INFO FileFormatWriter: Job null committed.
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:40 INFO DAGScheduler: Got job 65 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 129 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[282] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 71.5 KB, free 364.2 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 25.6 KB, free 364.2 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.8 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[282] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 424, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 129.0 (TID 424)
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0129_m_000000_424' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/_temporary/0/task_20180124161040_0129_m_000000
18/01/24 16:10:40 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0129_m_000000_424: Committed
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 129.0 (TID 424). 1093 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 424) in 13 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ResultStage 129 (saveAsTextFile at ReadWrite.scala:275) finished in 0.014 s
18/01/24 16:10:40 INFO DAGScheduler: Job 65 finished: saveAsTextFile at ReadWrite.scala:275, took 0.023437 s
18/01/24 16:10:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO CodeGenerator: Code generated in 11.654076 ms
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO SparkContext: Starting job: parquet at LogisticRegression.scala:965
18/01/24 16:10:40 INFO DAGScheduler: Registering RDD 285 (parquet at LogisticRegression.scala:965)
18/01/24 16:10:40 INFO DAGScheduler: Got job 66 (parquet at LogisticRegression.scala:965) with 1 output partitions
18/01/24 16:10:40 INFO DAGScheduler: Final stage: ResultStage 131 (parquet at LogisticRegression.scala:965)
18/01/24 16:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
18/01/24 16:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
18/01/24 16:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[285] at parquet at LogisticRegression.scala:965), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 5.1 KB, free 364.2 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 3.0 KB, free 364.2 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:33521 (size: 3.0 KB, free: 365.8 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[285] at parquet at LogisticRegression.scala:965)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 425, localhost, executor driver, partition 0, PROCESS_LOCAL, 6413 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 130.0 (TID 425)
18/01/24 16:10:40 INFO Executor: Finished task 0.0 in stage 130.0 (TID 425). 1554 bytes result sent to driver
18/01/24 16:10:40 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 425) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
18/01/24 16:10:40 INFO DAGScheduler: ShuffleMapStage 130 (parquet at LogisticRegression.scala:965) finished in 0.003 s
18/01/24 16:10:40 INFO DAGScheduler: looking for newly runnable stages
18/01/24 16:10:40 INFO DAGScheduler: running: Set()
18/01/24 16:10:40 INFO DAGScheduler: waiting: Set(ResultStage 131)
18/01/24 16:10:40 INFO DAGScheduler: failed: Set()
18/01/24 16:10:40 INFO DAGScheduler: Submitting ResultStage 131 (ShuffledRowRDD[286] at parquet at LogisticRegression.scala:965), which has no missing parents
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 78.1 KB, free 364.1 MB)
18/01/24 16:10:40 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 28.7 KB, free 364.1 MB)
18/01/24 16:10:40 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:33521 (size: 28.7 KB, free: 365.8 MB)
18/01/24 16:10:40 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (ShuffledRowRDD[286] at parquet at LogisticRegression.scala:965)
18/01/24 16:10:40 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
18/01/24 16:10:40 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 426, localhost, executor driver, partition 0, ANY, 5955 bytes)
18/01/24 16:10:40 INFO Executor: Running task 0.0 in stage 131.0 (TID 426)
18/01/24 16:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
18/01/24 16:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
18/01/24 16:10:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "numClasses",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "numFeatures",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "interceptVector",
    "type" : {
      "type" : "udt",
      "class" : "org.apache.spark.ml.linalg.VectorUDT",
      "pyClass" : "pyspark.ml.linalg.VectorUDT",
      "sqlType" : {
        "type" : "struct",
        "fields" : [ {
          "name" : "type",
          "type" : "byte",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "size",
          "type" : "integer",
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "indices",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "values",
          "type" : {
            "type" : "array",
            "elementType" : "double",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        } ]
      }
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "coefficientMatrix",
    "type" : {
      "type" : "udt",
      "class" : "org.apache.spark.ml.linalg.MatrixUDT",
      "pyClass" : "pyspark.ml.linalg.MatrixUDT",
      "sqlType" : {
        "type" : "struct",
        "fields" : [ {
          "name" : "type",
          "type" : "byte",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "numRows",
          "type" : "integer",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "numCols",
          "type" : "integer",
          "nullable" : false,
          "metadata" : { }
        }, {
          "name" : "colPtrs",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "rowIndices",
          "type" : {
            "type" : "array",
            "elementType" : "integer",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "values",
          "type" : {
            "type" : "array",
            "elementType" : "double",
            "containsNull" : false
          },
          "nullable" : true,
          "metadata" : { }
        }, {
          "name" : "isTransposed",
          "type" : "boolean",
          "nullable" : false,
          "metadata" : { }
        } ]
      }
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isMultinomial",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

       
18/01/24 16:10:40 INFO CodecPool: Got brand-new compressor [.snappy]
18/01/24 16:10:41 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161040_0131_m_000000_0' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/data/_temporary/0/task_20180124161040_0131_m_000000
18/01/24 16:10:41 INFO SparkHadoopMapRedUtil: attempt_20180124161040_0131_m_000000_0: Committed
18/01/24 16:10:41 INFO Executor: Finished task 0.0 in stage 131.0 (TID 426). 1935 bytes result sent to driver
18/01/24 16:10:41 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 426) in 57 ms on localhost (executor driver) (1/1)
18/01/24 16:10:41 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
18/01/24 16:10:41 INFO DAGScheduler: ResultStage 131 (parquet at LogisticRegression.scala:965) finished in 0.057 s
18/01/24 16:10:41 INFO DAGScheduler: Job 66 finished: parquet at LogisticRegression.scala:965, took 0.074612 s
18/01/24 16:10:41 INFO FileFormatWriter: Job null committed.
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:44 INFO DAGScheduler: Got job 67 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:44 INFO DAGScheduler: Final stage: ResultStage 132 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:44 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:44 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[289] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 71.4 KB, free 364.0 MB)
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 25.6 KB, free 364.0 MB)
18/01/24 16:10:44 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.8 MB)
18/01/24 16:10:44 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[289] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks
18/01/24 16:10:44 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 427, localhost, executor driver, partition 0, PROCESS_LOCAL, 6316 bytes)
18/01/24 16:10:44 INFO Executor: Running task 0.0 in stage 132.0 (TID 427)
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161044_0132_m_000000_427' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_pipeline/metadata/_temporary/0/task_20180124161044_0132_m_000000
18/01/24 16:10:44 INFO SparkHadoopMapRedUtil: attempt_20180124161044_0132_m_000000_427: Committed
18/01/24 16:10:44 INFO Executor: Finished task 0.0 in stage 132.0 (TID 427). 1093 bytes result sent to driver
18/01/24 16:10:44 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 427) in 9 ms on localhost (executor driver) (1/1)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
18/01/24 16:10:44 INFO DAGScheduler: ResultStage 132 (saveAsTextFile at ReadWrite.scala:275) finished in 0.009 s
18/01/24 16:10:44 INFO DAGScheduler: Job 67 finished: saveAsTextFile at ReadWrite.scala:275, took 0.017522 s
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:44 INFO DAGScheduler: Got job 68 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:44 INFO DAGScheduler: Final stage: ResultStage 133 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:44 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:44 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[291] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 71.5 KB, free 363.9 MB)
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 25.6 KB, free 363.9 MB)
18/01/24 16:10:44 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.8 MB)
18/01/24 16:10:44 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[291] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
18/01/24 16:10:44 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 428, localhost, executor driver, partition 0, PROCESS_LOCAL, 7294 bytes)
18/01/24 16:10:44 INFO Executor: Running task 0.0 in stage 133.0 (TID 428)
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161044_0133_m_000000_428' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_pipeline/stages/0_dplyr_transformer_610463a1360/metadata/_temporary/0/task_20180124161044_0133_m_000000
18/01/24 16:10:44 INFO SparkHadoopMapRedUtil: attempt_20180124161044_0133_m_000000_428: Committed
18/01/24 16:10:44 INFO Executor: Finished task 0.0 in stage 133.0 (TID 428). 1093 bytes result sent to driver
18/01/24 16:10:44 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 428) in 10 ms on localhost (executor driver) (1/1)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
18/01/24 16:10:44 INFO DAGScheduler: ResultStage 133 (saveAsTextFile at ReadWrite.scala:275) finished in 0.010 s
18/01/24 16:10:44 INFO DAGScheduler: Job 68 finished: saveAsTextFile at ReadWrite.scala:275, took 0.021365 s
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:44 INFO DAGScheduler: Got job 69 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:44 INFO DAGScheduler: Final stage: ResultStage 134 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:44 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:44 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[293] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 71.5 KB, free 363.8 MB)
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 25.6 KB, free 363.8 MB)
18/01/24 16:10:44 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:44 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[293] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
18/01/24 16:10:44 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 429, localhost, executor driver, partition 0, PROCESS_LOCAL, 6231 bytes)
18/01/24 16:10:44 INFO Executor: Running task 0.0 in stage 134.0 (TID 429)
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161044_0134_m_000000_429' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_pipeline/stages/1_binarizer_61041cbbcaf0/metadata/_temporary/0/task_20180124161044_0134_m_000000
18/01/24 16:10:44 INFO SparkHadoopMapRedUtil: attempt_20180124161044_0134_m_000000_429: Committed
18/01/24 16:10:44 INFO Executor: Finished task 0.0 in stage 134.0 (TID 429). 1093 bytes result sent to driver
18/01/24 16:10:44 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 429) in 9 ms on localhost (executor driver) (1/1)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
18/01/24 16:10:44 INFO DAGScheduler: ResultStage 134 (saveAsTextFile at ReadWrite.scala:275) finished in 0.009 s
18/01/24 16:10:44 INFO DAGScheduler: Job 69 finished: saveAsTextFile at ReadWrite.scala:275, took 0.017457 s
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:44 INFO DAGScheduler: Got job 70 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:44 INFO DAGScheduler: Final stage: ResultStage 135 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:44 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:44 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[295] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 71.5 KB, free 363.7 MB)
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 25.6 KB, free 363.7 MB)
18/01/24 16:10:44 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:44 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[295] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks
18/01/24 16:10:44 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 430, localhost, executor driver, partition 0, PROCESS_LOCAL, 6296 bytes)
18/01/24 16:10:44 INFO Executor: Running task 0.0 in stage 135.0 (TID 430)
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161044_0135_m_000000_430' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_pipeline/stages/2_bucketizer_61049871837/metadata/_temporary/0/task_20180124161044_0135_m_000000
18/01/24 16:10:44 INFO SparkHadoopMapRedUtil: attempt_20180124161044_0135_m_000000_430: Committed
18/01/24 16:10:44 INFO Executor: Finished task 0.0 in stage 135.0 (TID 430). 1093 bytes result sent to driver
18/01/24 16:10:44 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 430) in 10 ms on localhost (executor driver) (1/1)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
18/01/24 16:10:44 INFO DAGScheduler: ResultStage 135 (saveAsTextFile at ReadWrite.scala:275) finished in 0.010 s
18/01/24 16:10:44 INFO DAGScheduler: Job 70 finished: saveAsTextFile at ReadWrite.scala:275, took 0.020807 s
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:44 INFO DAGScheduler: Got job 71 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:44 INFO DAGScheduler: Final stage: ResultStage 136 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:44 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:44 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[297] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 71.5 KB, free 363.6 MB)
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 25.6 KB, free 363.6 MB)
18/01/24 16:10:44 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:44 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[297] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
18/01/24 16:10:44 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 431, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
18/01/24 16:10:44 INFO Executor: Running task 0.0 in stage 136.0 (TID 431)
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161044_0136_m_000000_431' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_pipeline/stages/3_r_formula_61046ea225dc/metadata/_temporary/0/task_20180124161044_0136_m_000000
18/01/24 16:10:44 INFO SparkHadoopMapRedUtil: attempt_20180124161044_0136_m_000000_431: Committed
18/01/24 16:10:44 INFO Executor: Finished task 0.0 in stage 136.0 (TID 431). 1180 bytes result sent to driver
18/01/24 16:10:44 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 431) in 11 ms on localhost (executor driver) (1/1)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
18/01/24 16:10:44 INFO DAGScheduler: ResultStage 136 (saveAsTextFile at ReadWrite.scala:275) finished in 0.011 s
18/01/24 16:10:44 INFO DAGScheduler: Job 71 finished: saveAsTextFile at ReadWrite.scala:275, took 0.025165 s
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO SparkContext: Starting job: saveAsTextFile at ReadWrite.scala:275
18/01/24 16:10:44 INFO DAGScheduler: Got job 72 (saveAsTextFile at ReadWrite.scala:275) with 1 output partitions
18/01/24 16:10:44 INFO DAGScheduler: Final stage: ResultStage 137 (saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:44 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:44 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[299] at saveAsTextFile at ReadWrite.scala:275), which has no missing parents
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 71.5 KB, free 363.5 MB)
18/01/24 16:10:44 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 25.6 KB, free 363.5 MB)
18/01/24 16:10:44 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:33521 (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:44 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[299] at saveAsTextFile at ReadWrite.scala:275)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks
18/01/24 16:10:44 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 432, localhost, executor driver, partition 0, PROCESS_LOCAL, 6495 bytes)
18/01/24 16:10:44 INFO Executor: Running task 0.0 in stage 137.0 (TID 432)
18/01/24 16:10:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
18/01/24 16:10:44 INFO FileOutputCommitter: Saved output of task 'attempt_20180124161044_0137_m_000000_432' to file:/home/rstudio-user/bigdataclass2018/workbook/saved_pipeline/stages/4_logistic_regression_610474782d95/metadata/_temporary/0/task_20180124161044_0137_m_000000
18/01/24 16:10:44 INFO SparkHadoopMapRedUtil: attempt_20180124161044_0137_m_000000_432: Committed
18/01/24 16:10:44 INFO Executor: Finished task 0.0 in stage 137.0 (TID 432). 1093 bytes result sent to driver
18/01/24 16:10:44 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 432) in 11 ms on localhost (executor driver) (1/1)
18/01/24 16:10:44 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
18/01/24 16:10:44 INFO DAGScheduler: ResultStage 137 (saveAsTextFile at ReadWrite.scala:275) finished in 0.011 s
18/01/24 16:10:44 INFO DAGScheduler: Job 72 finished: saveAsTextFile at ReadWrite.scala:275, took 0.023027 s
18/01/24 16:10:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:10:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:10:45 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:10:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:10:45 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:10:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:10:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:10:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:10:45 INFO SparkContext: Starting job: collect at utils.scala:58
18/01/24 16:10:45 INFO DAGScheduler: Got job 73 (collect at utils.scala:58) with 1 output partitions
18/01/24 16:10:45 INFO DAGScheduler: Final stage: ResultStage 138 (collect at utils.scala:58)
18/01/24 16:10:45 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:45 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:45 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[305] at map at utils.scala:55), which has no missing parents
18/01/24 16:10:45 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 8.7 KB, free 363.5 MB)
18/01/24 16:10:45 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 4.6 KB, free 363.5 MB)
18/01/24 16:10:45 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:33521 (size: 4.6 KB, free: 365.6 MB)
18/01/24 16:10:45 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[305] at map at utils.scala:55)
18/01/24 16:10:45 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks
18/01/24 16:10:45 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 433, localhost, executor driver, partition 0, PROCESS_LOCAL, 6717 bytes)
18/01/24 16:10:45 INFO Executor: Running task 0.0 in stage 138.0 (TID 433)
18/01/24 16:10:45 INFO Executor: Finished task 0.0 in stage 138.0 (TID 433). 1294 bytes result sent to driver
18/01/24 16:10:45 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 433) in 2 ms on localhost (executor driver) (1/1)
18/01/24 16:10:45 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
18/01/24 16:10:45 INFO DAGScheduler: ResultStage 138 (collect at utils.scala:58) finished in 0.002 s
18/01/24 16:10:45 INFO DAGScheduler: Job 73 finished: collect at utils.scala:58, took 0.004951 s
18/01/24 16:10:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:10:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:10:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:10:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:10:46 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:10:46 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:10:46 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:10:46 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:10:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:10:46 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:10:46 INFO SparkSqlParser: Parsing command: flights
18/01/24 16:10:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:10:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz8`
WHERE (0 = 1)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 237.2 KB, free 363.3 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.2 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 165 from textFile at ReadWrite.scala:379
18/01/24 16:10:46 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:46 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:46 INFO DAGScheduler: Got job 74 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:46 INFO DAGScheduler: Final stage: ResultStage 139 (first at ReadWrite.scala:379)
18/01/24 16:10:46 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:46 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:46 INFO DAGScheduler: Submitting ResultStage 139 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata MapPartitionsRDD[309] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 3.3 KB, free 363.2 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 1996.0 B, free 363.2 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:33521 (size: 1996.0 B, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata MapPartitionsRDD[309] at textFile at ReadWrite.scala:379)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
18/01/24 16:10:46 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 434, localhost, executor driver, partition 0, PROCESS_LOCAL, 6089 bytes)
18/01/24 16:10:46 INFO Executor: Running task 0.0 in stage 139.0 (TID 434)
18/01/24 16:10:46 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata/part-00000:0+294
18/01/24 16:10:46 INFO Executor: Finished task 0.0 in stage 139.0 (TID 434). 1384 bytes result sent to driver
18/01/24 16:10:46 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 434) in 7 ms on localhost (executor driver) (1/1)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
18/01/24 16:10:46 INFO DAGScheduler: ResultStage 139 (first at ReadWrite.scala:379) finished in 0.007 s
18/01/24 16:10:46 INFO DAGScheduler: Job 74 finished: first at ReadWrite.scala:379, took 0.011159 s
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 237.3 KB, free 363.0 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.0 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 167 from textFile at ReadWrite.scala:379
18/01/24 16:10:46 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:46 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:46 INFO DAGScheduler: Got job 75 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:46 INFO DAGScheduler: Final stage: ResultStage 140 (first at ReadWrite.scala:379)
18/01/24 16:10:46 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:46 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:46 INFO DAGScheduler: Submitting ResultStage 140 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[311] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 3.3 KB, free 363.0 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 2040.0 B, free 363.0 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:33521 (size: 2040.0 B, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[311] at textFile at ReadWrite.scala:379)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks
18/01/24 16:10:46 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 435, localhost, executor driver, partition 0, PROCESS_LOCAL, 6128 bytes)
18/01/24 16:10:46 INFO Executor: Running task 0.0 in stage 140.0 (TID 435)
18/01/24 16:10:46 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 16:10:46 INFO Executor: Finished task 0.0 in stage 140.0 (TID 435). 2362 bytes result sent to driver
18/01/24 16:10:46 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 435) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
18/01/24 16:10:46 INFO DAGScheduler: ResultStage 140 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 16:10:46 INFO DAGScheduler: Job 75 finished: first at ReadWrite.scala:379, took 0.006311 s
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 237.3 KB, free 362.7 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.7 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 169 from textFile at ReadWrite.scala:379
18/01/24 16:10:46 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:46 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:46 INFO DAGScheduler: Got job 76 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:46 INFO DAGScheduler: Final stage: ResultStage 141 (first at ReadWrite.scala:379)
18/01/24 16:10:46 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:46 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:46 INFO DAGScheduler: Submitting ResultStage 141 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[313] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 3.3 KB, free 362.7 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 2040.0 B, free 362.7 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:33521 (size: 2040.0 B, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[313] at textFile at ReadWrite.scala:379)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks
18/01/24 16:10:46 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 436, localhost, executor driver, partition 0, PROCESS_LOCAL, 6128 bytes)
18/01/24 16:10:46 INFO Executor: Running task 0.0 in stage 141.0 (TID 436)
18/01/24 16:10:46 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 16:10:46 INFO Executor: Finished task 0.0 in stage 141.0 (TID 436). 2275 bytes result sent to driver
18/01/24 16:10:46 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 436) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
18/01/24 16:10:46 INFO DAGScheduler: ResultStage 141 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:46 INFO DAGScheduler: Job 76 finished: first at ReadWrite.scala:379, took 0.005053 s
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 237.3 KB, free 362.5 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.5 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 171 from textFile at ReadWrite.scala:379
18/01/24 16:10:46 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:46 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:46 INFO DAGScheduler: Got job 77 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:46 INFO DAGScheduler: Final stage: ResultStage 142 (first at ReadWrite.scala:379)
18/01/24 16:10:46 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:46 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:46 INFO DAGScheduler: Submitting ResultStage 142 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[315] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 3.3 KB, free 362.4 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 2028.0 B, free 362.4 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:33521 (size: 2028.0 B, free: 365.6 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[315] at textFile at ReadWrite.scala:379)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks
18/01/24 16:10:46 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 437, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 16:10:46 INFO Executor: Running task 0.0 in stage 142.0 (TID 437)
18/01/24 16:10:46 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 16:10:46 INFO Executor: Finished task 0.0 in stage 142.0 (TID 437). 1294 bytes result sent to driver
18/01/24 16:10:46 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 437) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
18/01/24 16:10:46 INFO DAGScheduler: ResultStage 142 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:46 INFO DAGScheduler: Job 77 finished: first at ReadWrite.scala:379, took 0.004967 s
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 237.3 KB, free 362.2 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.2 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 173 from textFile at ReadWrite.scala:379
18/01/24 16:10:46 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:46 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:46 INFO DAGScheduler: Got job 78 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:46 INFO DAGScheduler: Final stage: ResultStage 143 (first at ReadWrite.scala:379)
18/01/24 16:10:46 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:46 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:46 INFO DAGScheduler: Submitting ResultStage 143 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[317] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 3.3 KB, free 362.2 MB)
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 2028.0 B, free 362.2 MB)
18/01/24 16:10:46 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:33521 (size: 2028.0 B, free: 365.5 MB)
18/01/24 16:10:46 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[317] at textFile at ReadWrite.scala:379)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks
18/01/24 16:10:46 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 438, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 16:10:46 INFO Executor: Running task 0.0 in stage 143.0 (TID 438)
18/01/24 16:10:46 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 16:10:46 INFO Executor: Finished task 0.0 in stage 143.0 (TID 438). 1215 bytes result sent to driver
18/01/24 16:10:46 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 438) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:46 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
18/01/24 16:10:46 INFO DAGScheduler: ResultStage 143 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:46 INFO DAGScheduler: Job 78 finished: first at ReadWrite.scala:379, took 0.005037 s
18/01/24 16:10:46 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 237.3 KB, free 362.0 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.9 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 175 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 79 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 144 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 144 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[319] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 3.3 KB, free 361.9 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 2029.0 B, free 361.9 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:33521 (size: 2029.0 B, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[319] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 439, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 144.0 (TID 439)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 144.0 (TID 439). 1359 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 439) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 144 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 16:10:47 INFO DAGScheduler: Job 79 finished: first at ReadWrite.scala:379, took 0.008027 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 237.3 KB, free 361.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:33521 in memory (size: 2028.0 B, free: 365.5 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:33521 in memory (size: 2028.0 B, free: 365.5 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:33521 in memory (size: 2040.0 B, free: 365.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 12801
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 12802
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 12803
18/01/24 16:10:47 INFO ContextCleaner: Cleaned shuffle 45
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:33521 in memory (size: 2.9 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:33521 in memory (size: 28.3 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 12948
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 12949
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 12950
18/01/24 16:10:47 INFO ContextCleaner: Cleaned shuffle 46
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:33521 in memory (size: 3.0 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:33521 in memory (size: 28.7 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 177 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 13335
18/01/24 16:10:47 INFO ContextCleaner: Cleaned accumulator 13336
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:33521 in memory (size: 4.6 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:33521 in memory (size: 1996.0 B, free: 365.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:33521 in memory (size: 2040.0 B, free: 365.8 MB)
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 80 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 145 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 145 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[321] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 3.3 KB, free 363.9 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 2029.0 B, free 363.9 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:33521 (size: 2029.0 B, free: 365.8 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[321] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 440, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 145.0 (TID 440)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 145.0 (TID 440). 1280 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 440) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 145 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:47 INFO DAGScheduler: Job 80 finished: first at ReadWrite.scala:379, took 0.005724 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 237.3 KB, free 363.6 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 179 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 81 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 146 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 146 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[323] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 3.3 KB, free 363.6 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 2028.0 B, free 363.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:33521 (size: 2028.0 B, free: 365.8 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[323] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 441, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 146.0 (TID 441)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 146.0 (TID 441). 1278 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 441) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 146 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:47 INFO DAGScheduler: Job 81 finished: first at ReadWrite.scala:379, took 0.005818 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 237.3 KB, free 363.4 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.4 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 181 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 82 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 147 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 147 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[325] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 3.3 KB, free 363.3 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 2028.0 B, free 363.3 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:33521 (size: 2028.0 B, free: 365.8 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[325] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 442, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 147.0 (TID 442)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 147.0 (TID 442). 1278 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 442) in 2 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 147 (first at ReadWrite.scala:379) finished in 0.002 s
18/01/24 16:10:47 INFO DAGScheduler: Job 82 finished: first at ReadWrite.scala:379, took 0.005647 s
18/01/24 16:10:47 INFO SparkContext: Starting job: parquet at RFormula.scala:341
18/01/24 16:10:47 INFO DAGScheduler: Got job 83 (parquet at RFormula.scala:341) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 148 (parquet at RFormula.scala:341)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[327] at parquet at RFormula.scala:341), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 70.7 KB, free 363.3 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 25.3 KB, free 363.3 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:33521 (size: 25.3 KB, free: 365.8 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[327] at parquet at RFormula.scala:341)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 443, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 148.0 (TID 443)
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 148.0 (TID 443). 1990 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 443) in 20 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 148 (parquet at RFormula.scala:341) finished in 0.015 s
18/01/24 16:10:47 INFO DAGScheduler: Job 83 finished: parquet at RFormula.scala:341, took 0.030887 s
18/01/24 16:10:47 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:10:47 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:10:47 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
18/01/24 16:10:47 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 10.976781 ms
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 283.6 KB, free 363.0 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 24.5 KB, free 363.0 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:33521 (size: 24.5 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 184 from head at RFormula.scala:341
18/01/24 16:10:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:10:47 INFO SparkContext: Starting job: head at RFormula.scala:341
18/01/24 16:10:47 INFO DAGScheduler: Got job 84 (head at RFormula.scala:341) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 149 (head at RFormula.scala:341)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[330] at head at RFormula.scala:341), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 9.8 KB, free 362.9 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 4.7 KB, free 362.9 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:33521 (size: 4.7 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[330] at head at RFormula.scala:341)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 444, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 149.0 (TID 444)
18/01/24 16:10:47 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/data/part-00000-4c76e860-8b4c-4e35-8244-61bdf47c8710.snappy.parquet, range: 0-946, partition values: [empty row]
18/01/24 16:10:47 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 11.502783 ms
18/01/24 16:10:47 INFO CodecPool: Got brand-new decompressor [.snappy]
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 149.0 (TID 444). 1512 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 444) in 75 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 149 (head at RFormula.scala:341) finished in 0.075 s
18/01/24 16:10:47 INFO DAGScheduler: Job 84 finished: head at RFormula.scala:341, took 0.087403 s
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 15.278495 ms
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 237.3 KB, free 362.7 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 186 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 85 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 150 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 150 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[332] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 3.3 KB, free 362.7 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 2040.0 B, free 362.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:33521 (size: 2040.0 B, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[332] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 445, localhost, executor driver, partition 0, PROCESS_LOCAL, 6135 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 150.0 (TID 445)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata/part-00000:0+240
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 150.0 (TID 445). 1330 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 445) in 4 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 150 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 16:10:47 INFO DAGScheduler: Job 85 finished: first at ReadWrite.scala:379, took 0.006927 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 237.3 KB, free 362.4 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.4 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 188 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 86 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 151 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 151 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[334] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 3.4 KB, free 362.4 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 2045.0 B, free 362.4 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:33521 (size: 2045.0 B, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[334] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 446, localhost, executor driver, partition 0, PROCESS_LOCAL, 6168 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 151.0 (TID 446)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 151.0 (TID 446). 1297 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 446) in 2 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 151 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:47 INFO DAGScheduler: Job 86 finished: first at ReadWrite.scala:379, took 0.005736 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 237.3 KB, free 362.2 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.2 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 190 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 87 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 152 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 152 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[336] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 3.4 KB, free 362.2 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 2045.0 B, free 362.2 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:33521 (size: 2045.0 B, free: 365.7 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[336] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 447, localhost, executor driver, partition 0, PROCESS_LOCAL, 6168 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 152.0 (TID 447)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 152.0 (TID 447). 1297 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 447) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 152 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 16:10:47 INFO DAGScheduler: Job 87 finished: first at ReadWrite.scala:379, took 0.007675 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 237.3 KB, free 361.9 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.9 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 192 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 88 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 153 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 153 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[338] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 3.4 KB, free 361.9 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 2.0 KB, free 361.9 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[338] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 153.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 448, localhost, executor driver, partition 0, PROCESS_LOCAL, 6180 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 153.0 (TID 448)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 153.0 (TID 448). 1254 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 448) in 4 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 153 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 16:10:47 INFO DAGScheduler: Job 88 finished: first at ReadWrite.scala:379, took 0.006438 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 237.3 KB, free 361.7 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 194 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 89 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 154 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 154 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[340] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 3.4 KB, free 361.6 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 2.0 KB, free 361.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[340] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 449, localhost, executor driver, partition 0, PROCESS_LOCAL, 6180 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 154.0 (TID 449)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 154.0 (TID 449). 1254 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 449) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 154 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 16:10:47 INFO DAGScheduler: Job 89 finished: first at ReadWrite.scala:379, took 0.008634 s
18/01/24 16:10:47 INFO SparkContext: Starting job: parquet at RFormula.scala:503
18/01/24 16:10:47 INFO DAGScheduler: Got job 90 (parquet at RFormula.scala:503) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 155 (parquet at RFormula.scala:503)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[342] at parquet at RFormula.scala:503), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 70.7 KB, free 361.6 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 25.3 KB, free 361.5 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:33521 (size: 25.3 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[342] at parquet at RFormula.scala:503)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 450, localhost, executor driver, partition 0, PROCESS_LOCAL, 6333 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 155.0 (TID 450)
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 155.0 (TID 450). 1837 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 450) in 9 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 155 (parquet at RFormula.scala:503) finished in 0.003 s
18/01/24 16:10:47 INFO DAGScheduler: Job 90 finished: parquet at RFormula.scala:503, took 0.021546 s
18/01/24 16:10:47 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:10:47 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:10:47 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
18/01/24 16:10:47 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 16.744361 ms
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 283.3 KB, free 361.3 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 24.4 KB, free 361.2 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:33521 (size: 24.4 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 197 from head at RFormula.scala:503
18/01/24 16:10:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:10:47 INFO SparkContext: Starting job: head at RFormula.scala:503
18/01/24 16:10:47 INFO DAGScheduler: Got job 91 (head at RFormula.scala:503) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 156 (head at RFormula.scala:503)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[345] at head at RFormula.scala:503), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 10.3 KB, free 361.2 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 4.8 KB, free 361.2 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:33521 (size: 4.8 KB, free: 365.6 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[345] at head at RFormula.scala:503)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 451, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 156.0 (TID 451)
18/01/24 16:10:47 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/data/part-00000-46d12c43-4d60-4984-8900-332c8821b472.snappy.parquet, range: 0-812, partition values: [empty row]
18/01/24 16:10:47 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 156.0 (TID 451). 1457 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 451) in 22 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 156 (head at RFormula.scala:503) finished in 0.022 s
18/01/24 16:10:47 INFO DAGScheduler: Job 91 finished: head at RFormula.scala:503, took 0.030103 s
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 27.902009 ms
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 237.3 KB, free 361.0 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.0 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 199 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 92 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 157 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 157 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[347] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 3.4 KB, free 361.0 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 2.0 KB, free 361.0 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[347] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 452, localhost, executor driver, partition 0, PROCESS_LOCAL, 6171 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 157.0 (TID 452)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 157.0 (TID 452). 1237 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 452) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 157 (first at ReadWrite.scala:379) finished in 0.000 s
18/01/24 16:10:47 INFO DAGScheduler: Job 92 finished: first at ReadWrite.scala:379, took 0.007723 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 237.3 KB, free 360.7 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 23.1 KB, free 360.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 201 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 93 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 158 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 158 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[349] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 3.4 KB, free 360.7 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 2.0 KB, free 360.7 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:33521 (size: 2.0 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[349] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 453, localhost, executor driver, partition 0, PROCESS_LOCAL, 6171 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 158.0 (TID 453)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 158.0 (TID 453). 1237 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 453) in 2 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 158 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:47 INFO DAGScheduler: Job 93 finished: first at ReadWrite.scala:379, took 0.006718 s
18/01/24 16:10:47 INFO SparkContext: Starting job: parquet at RFormula.scala:412
18/01/24 16:10:47 INFO DAGScheduler: Got job 94 (parquet at RFormula.scala:412) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 159 (parquet at RFormula.scala:412)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[351] at parquet at RFormula.scala:412), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 70.7 KB, free 360.6 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 25.3 KB, free 360.6 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:33521 (size: 25.3 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[351] at parquet at RFormula.scala:412)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 159.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 454, localhost, executor driver, partition 0, PROCESS_LOCAL, 6327 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 159.0 (TID 454)
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 159.0 (TID 454). 1773 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 454) in 9 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 159 (parquet at RFormula.scala:412) finished in 0.009 s
18/01/24 16:10:47 INFO DAGScheduler: Job 94 finished: parquet at RFormula.scala:412, took 0.020962 s
18/01/24 16:10:47 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:10:47 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:10:47 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
18/01/24 16:10:47 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 7.097814 ms
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 282.9 KB, free 360.3 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 24.4 KB, free 360.3 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:33521 (size: 24.4 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 204 from head at RFormula.scala:412
18/01/24 16:10:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:10:47 INFO SparkContext: Starting job: head at RFormula.scala:412
18/01/24 16:10:47 INFO DAGScheduler: Got job 95 (head at RFormula.scala:412) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 160 (head at RFormula.scala:412)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[354] at head at RFormula.scala:412), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 8.2 KB, free 360.3 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 4.3 KB, free 360.3 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:33521 (size: 4.3 KB, free: 365.5 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[354] at head at RFormula.scala:412)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 455, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 160.0 (TID 455)
18/01/24 16:10:47 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/data/part-00000-593de674-2fd9-48f5-b311-77492e49101f.snappy.parquet, range: 0-461, partition values: [empty row]
18/01/24 16:10:47 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 160.0 (TID 455). 1441 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 455) in 6 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 160 (head at RFormula.scala:412) finished in 0.007 s
18/01/24 16:10:47 INFO DAGScheduler: Job 95 finished: head at RFormula.scala:412, took 0.010666 s
18/01/24 16:10:47 INFO CodeGenerator: Code generated in 13.350422 ms
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 237.3 KB, free 360.1 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 23.1 KB, free 360.1 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.4 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 206 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 96 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 161 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 161 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[356] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 3.3 KB, free 360.0 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 2038.0 B, free 360.0 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:33521 (size: 2038.0 B, free: 365.4 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[356] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 456, localhost, executor driver, partition 0, PROCESS_LOCAL, 6131 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 161.0 (TID 456)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 161.0 (TID 456). 1563 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 456) in 4 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 161 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 16:10:47 INFO DAGScheduler: Job 96 finished: first at ReadWrite.scala:379, took 0.008488 s
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 237.3 KB, free 359.8 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 23.1 KB, free 359.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:33521 (size: 23.1 KB, free: 365.4 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 208 from textFile at ReadWrite.scala:379
18/01/24 16:10:47 INFO FileInputFormat: Total input paths to process : 1
18/01/24 16:10:47 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 16:10:47 INFO DAGScheduler: Got job 97 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 16:10:47 INFO DAGScheduler: Final stage: ResultStage 162 (first at ReadWrite.scala:379)
18/01/24 16:10:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:47 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:47 INFO DAGScheduler: Submitting ResultStage 162 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[358] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 3.3 KB, free 359.8 MB)
18/01/24 16:10:47 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 2038.0 B, free 359.8 MB)
18/01/24 16:10:47 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:33521 (size: 2038.0 B, free: 365.4 MB)
18/01/24 16:10:47 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[358] at textFile at ReadWrite.scala:379)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks
18/01/24 16:10:47 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 457, localhost, executor driver, partition 0, PROCESS_LOCAL, 6131 bytes)
18/01/24 16:10:47 INFO Executor: Running task 0.0 in stage 162.0 (TID 457)
18/01/24 16:10:47 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 16:10:47 INFO Executor: Finished task 0.0 in stage 162.0 (TID 457). 1563 bytes result sent to driver
18/01/24 16:10:47 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 457) in 3 ms on localhost (executor driver) (1/1)
18/01/24 16:10:47 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
18/01/24 16:10:47 INFO DAGScheduler: ResultStage 162 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 16:10:47 INFO DAGScheduler: Job 97 finished: first at ReadWrite.scala:379, took 0.005926 s
18/01/24 16:10:48 INFO SparkContext: Starting job: load at LogisticRegression.scala:979
18/01/24 16:10:48 INFO DAGScheduler: Got job 98 (load at LogisticRegression.scala:979) with 1 output partitions
18/01/24 16:10:48 INFO DAGScheduler: Final stage: ResultStage 163 (load at LogisticRegression.scala:979)
18/01/24 16:10:48 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:48 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:48 INFO DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[360] at load at LogisticRegression.scala:979), which has no missing parents
18/01/24 16:10:48 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 70.7 KB, free 359.7 MB)
18/01/24 16:10:48 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 25.3 KB, free 359.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:33521 (size: 25.3 KB, free: 365.4 MB)
18/01/24 16:10:48 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (MapPartitionsRDD[360] at load at LogisticRegression.scala:979)
18/01/24 16:10:48 INFO TaskSchedulerImpl: Adding task set 163.0 with 1 tasks
18/01/24 16:10:48 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 458, localhost, executor driver, partition 0, PROCESS_LOCAL, 6288 bytes)
18/01/24 16:10:48 INFO Executor: Running task 0.0 in stage 163.0 (TID 458)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.4 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:33521 in memory (size: 2029.0 B, free: 365.4 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.4 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:33521 in memory (size: 2029.0 B, free: 365.4 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:48 INFO Executor: Finished task 0.0 in stage 163.0 (TID 458). 2072 bytes result sent to driver
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:33521 in memory (size: 2028.0 B, free: 365.5 MB)
18/01/24 16:10:48 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 458) in 9 ms on localhost (executor driver) (1/1)
18/01/24 16:10:48 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
18/01/24 16:10:48 INFO DAGScheduler: ResultStage 163 (load at LogisticRegression.scala:979) finished in 0.010 s
18/01/24 16:10:48 INFO DAGScheduler: Job 98 finished: load at LogisticRegression.scala:979, took 0.037092 s
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.5 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:33521 in memory (size: 2028.0 B, free: 365.5 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:33521 in memory (size: 25.3 KB, free: 365.5 MB)
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 13865
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 13866
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 13867
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:33521 in memory (size: 24.5 KB, free: 365.5 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:33521 in memory (size: 4.7 KB, free: 365.5 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:33521 in memory (size: 2040.0 B, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:33521 in memory (size: 2045.0 B, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:33521 in memory (size: 2045.0 B, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 365.6 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:33521 in memory (size: 25.3 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 14204
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 14205
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 14206
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:33521 in memory (size: 24.4 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:33521 in memory (size: 4.8 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 365.7 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:33521 in memory (size: 2.0 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:33521 in memory (size: 25.3 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 14399
18/01/24 16:10:48 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 14400
18/01/24 16:10:48 INFO ContextCleaner: Cleaned accumulator 14401
18/01/24 16:10:48 INFO FileSourceStrategy: Output Data Schema: struct<numClasses: int, numFeatures: int, interceptVector: vector, coefficientMatrix: matrix, isMultinomial: boolean ... 3 more fields>
18/01/24 16:10:48 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:33521 in memory (size: 24.4 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:33521 in memory (size: 4.3 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:33521 in memory (size: 2038.0 B, free: 365.8 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:33521 in memory (size: 23.1 KB, free: 365.9 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:33521 in memory (size: 2038.0 B, free: 365.9 MB)
18/01/24 16:10:48 INFO CodeGenerator: Code generated in 12.2958 ms
18/01/24 16:10:48 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 288.7 KB, free 364.0 MB)
18/01/24 16:10:48 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 25.0 KB, free 364.0 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:33521 (size: 25.0 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO SparkContext: Created broadcast 211 from head at LogisticRegression.scala:997
18/01/24 16:10:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:10:48 INFO SparkContext: Starting job: head at LogisticRegression.scala:997
18/01/24 16:10:48 INFO DAGScheduler: Got job 99 (head at LogisticRegression.scala:997) with 1 output partitions
18/01/24 16:10:48 INFO DAGScheduler: Final stage: ResultStage 164 (head at LogisticRegression.scala:997)
18/01/24 16:10:48 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:10:48 INFO DAGScheduler: Missing parents: List()
18/01/24 16:10:48 INFO DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[363] at head at LogisticRegression.scala:997), which has no missing parents
18/01/24 16:10:48 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 17.3 KB, free 364.0 MB)
18/01/24 16:10:48 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 6.2 KB, free 364.0 MB)
18/01/24 16:10:48 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:33521 (size: 6.2 KB, free: 365.8 MB)
18/01/24 16:10:48 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:996
18/01/24 16:10:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[363] at head at LogisticRegression.scala:997)
18/01/24 16:10:48 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks
18/01/24 16:10:48 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 459, localhost, executor driver, partition 0, PROCESS_LOCAL, 6631 bytes)
18/01/24 16:10:48 INFO Executor: Running task 0.0 in stage 164.0 (TID 459)
18/01/24 16:10:48 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/data/part-00000-d0beedf9-5461-4cb8-8867-676902a6c5f5.snappy.parquet, range: 0-3705, partition values: [empty row]
18/01/24 16:10:48 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

Catalyst form:
StructType(StructField(numClasses,IntegerType,true), StructField(numFeatures,IntegerType,true), StructField(interceptVector,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(coefficientMatrix,org.apache.spark.ml.linalg.MatrixUDT@e59e0c69,true), StructField(isMultinomial,BooleanType,true))
       
18/01/24 16:10:48 INFO CodeGenerator: Code generated in 13.638214 ms
18/01/24 16:10:48 INFO CodeGenerator: Code generated in 5.995761 ms
18/01/24 16:10:48 INFO CodeGenerator: Code generated in 6.813392 ms
18/01/24 16:10:48 INFO Executor: Finished task 0.0 in stage 164.0 (TID 459). 1526 bytes result sent to driver
18/01/24 16:10:48 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 459) in 46 ms on localhost (executor driver) (1/1)
18/01/24 16:10:48 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
18/01/24 16:10:48 INFO DAGScheduler: ResultStage 164 (head at LogisticRegression.scala:997) finished in 0.046 s
18/01/24 16:10:48 INFO DAGScheduler: Job 99 finished: head at LogisticRegression.scala:997, took 0.050925 s
18/01/24 16:10:48 INFO CodeGenerator: Code generated in 6.090585 ms
18/01/24 16:10:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:10:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:10:51 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:10:51 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:10:51 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:10:51 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:10:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:10:51 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:12:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:12:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz9`
WHERE (0 = 1)
18/01/24 16:13:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:13:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = FORMAT(SYS.DATE(), "%d")))
LIMIT 6
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_function: default.DATE
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_function: default.DATE	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_function: default.DATE
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_function: default.DATE	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_function: default.DATE
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_function: default.DATE	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:13:05 INFO HiveMetaStore: 0: get_function: default.DATE
18/01/24 16:13:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_function: default.DATE	
18/01/24 16:13:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:13:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz10`
WHERE (0 = 1)
18/01/24 16:34:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:34:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:34:52 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:34:52 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:34:52 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:34:52 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:34:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:34:52 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 365.9 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:33521 in memory (size: 6.2 KB, free: 365.9 MB)
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 14595
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:33521 in memory (size: 25.0 KB, free: 365.9 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:33521 in memory (size: 25.3 KB, free: 365.9 MB)
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 14594
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 14596
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:33521 in memory (size: 28.4 KB, free: 365.9 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:33521 in memory (size: 2.9 KB, free: 365.9 MB)
18/01/24 16:38:06 INFO ContextCleaner: Cleaned shuffle 44
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 12656
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 12655
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 12654
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.0 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.0 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.0 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:33521 in memory (size: 28.3 KB, free: 366.0 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:33521 in memory (size: 3.0 KB, free: 366.1 MB)
18/01/24 16:38:06 INFO ContextCleaner: Cleaned shuffle 43
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 12413
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 12412
18/01/24 16:38:06 INFO ContextCleaner: Cleaned accumulator 12411
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.1 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.2 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:33521 in memory (size: 25.6 KB, free: 366.2 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.2 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:33521 in memory (size: 19.6 KB, free: 366.2 MB)
18/01/24 16:38:06 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:33521 in memory (size: 25.7 KB, free: 366.2 MB)
18/01/24 16:38:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:38:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz16`
WHERE (0 = 1)
18/01/24 16:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:38:31 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:38:31 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:38:31 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:38:31 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:38:31 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:38:31 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:38:31 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:38:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:38:31 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 16:38:31 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:38:31 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:38:31 INFO HiveMetaStore: 0: get_database: default
18/01/24 16:38:31 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 16:38:31 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 16:38:31 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 16:39:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:39:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = "24"))
LIMIT 6
18/01/24 16:39:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:39:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = "24"))
LIMIT 6
18/01/24 16:39:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:39:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = "24"))
LIMIT 6
18/01/24 16:39:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:39:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = "24"))
LIMIT 6
18/01/24 16:39:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:39:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = "24"))
LIMIT 6
18/01/24 16:39:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:39:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = "01") AND (`dayofmonth` = "24"))
LIMIT 6
18/01/24 16:39:14 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:39:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#1744),isnotnull(dayofmonth#1745),(month#1744 = 01),(dayofmonth#1745 = 24)
18/01/24 16:39:14 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, dayofmonth: string, dayofweek: string, deptime: string ... 27 more fields>
18/01/24 16:39:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth),EqualTo(month,01),EqualTo(dayofmonth,24)
18/01/24 16:39:15 INFO CodeGenerator: Code generated in 17.212275 ms
18/01/24 16:39:15 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 282.1 KB, free 365.4 MB)
18/01/24 16:39:15 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.4 MB)
18/01/24 16:39:15 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:33521 (size: 23.9 KB, free: 366.2 MB)
18/01/24 16:39:15 INFO SparkContext: Created broadcast 213 from collect at utils.scala:211
18/01/24 16:39:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:39:15 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:39:15 INFO DAGScheduler: Got job 100 (collect at utils.scala:211) with 1 output partitions
18/01/24 16:39:15 INFO DAGScheduler: Final stage: ResultStage 165 (collect at utils.scala:211)
18/01/24 16:39:15 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:39:15 INFO DAGScheduler: Missing parents: List()
18/01/24 16:39:15 INFO DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[370] at collect at utils.scala:211), which has no missing parents
18/01/24 16:39:15 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 19.9 KB, free 365.3 MB)
18/01/24 16:39:15 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 7.9 KB, free 365.3 MB)
18/01/24 16:39:15 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:33521 (size: 7.9 KB, free: 366.2 MB)
18/01/24 16:39:15 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:996
18/01/24 16:39:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[370] at collect at utils.scala:211)
18/01/24 16:39:15 INFO TaskSchedulerImpl: Adding task set 165.0 with 1 tasks
18/01/24 16:39:15 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 460, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:39:15 INFO Executor: Running task 0.0 in stage 165.0 (TID 460)
18/01/24 16:39:15 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 16:39:21 INFO Executor: Finished task 0.0 in stage 165.0 (TID 460). 1555 bytes result sent to driver
18/01/24 16:39:21 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 460) in 6392 ms on localhost (executor driver) (1/1)
18/01/24 16:39:21 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
18/01/24 16:39:21 INFO DAGScheduler: ResultStage 165 (collect at utils.scala:211) finished in 6.392 s
18/01/24 16:39:21 INFO DAGScheduler: Job 100 finished: collect at utils.scala:211, took 6.424068 s
18/01/24 16:39:21 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:39:21 INFO DAGScheduler: Got job 101 (collect at utils.scala:211) with 4 output partitions
18/01/24 16:39:21 INFO DAGScheduler: Final stage: ResultStage 166 (collect at utils.scala:211)
18/01/24 16:39:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:39:21 INFO DAGScheduler: Missing parents: List()
18/01/24 16:39:21 INFO DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[370] at collect at utils.scala:211), which has no missing parents
18/01/24 16:39:21 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 19.9 KB, free 365.3 MB)
18/01/24 16:39:21 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 7.8 KB, free 365.3 MB)
18/01/24 16:39:21 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:33521 (size: 7.8 KB, free: 366.2 MB)
18/01/24 16:39:21 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:996
18/01/24 16:39:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 166 (MapPartitionsRDD[370] at collect at utils.scala:211)
18/01/24 16:39:21 INFO TaskSchedulerImpl: Adding task set 166.0 with 4 tasks
18/01/24 16:39:21 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 461, localhost, executor driver, partition 1, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:39:21 INFO TaskSetManager: Starting task 1.0 in stage 166.0 (TID 462, localhost, executor driver, partition 2, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:39:21 INFO TaskSetManager: Starting task 2.0 in stage 166.0 (TID 463, localhost, executor driver, partition 3, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:39:21 INFO TaskSetManager: Starting task 3.0 in stage 166.0 (TID 464, localhost, executor driver, partition 4, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:39:21 INFO Executor: Running task 0.0 in stage 166.0 (TID 461)
18/01/24 16:39:21 INFO Executor: Running task 1.0 in stage 166.0 (TID 462)
18/01/24 16:39:21 INFO Executor: Running task 2.0 in stage 166.0 (TID 463)
18/01/24 16:39:21 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 16:39:21 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 16:39:21 INFO Executor: Running task 3.0 in stage 166.0 (TID 464)
18/01/24 16:39:21 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 16:39:21 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 16:39:33 INFO Executor: Finished task 2.0 in stage 166.0 (TID 463). 1555 bytes result sent to driver
18/01/24 16:39:33 INFO TaskSetManager: Finished task 2.0 in stage 166.0 (TID 463) in 12173 ms on localhost (executor driver) (1/4)
18/01/24 16:39:33 INFO Executor: Finished task 3.0 in stage 166.0 (TID 464). 1555 bytes result sent to driver
18/01/24 16:39:33 INFO TaskSetManager: Finished task 3.0 in stage 166.0 (TID 464) in 12201 ms on localhost (executor driver) (2/4)
18/01/24 16:39:33 INFO Executor: Finished task 0.0 in stage 166.0 (TID 461). 1555 bytes result sent to driver
18/01/24 16:39:33 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 461) in 12233 ms on localhost (executor driver) (3/4)
18/01/24 16:39:33 INFO Executor: Finished task 1.0 in stage 166.0 (TID 462). 1555 bytes result sent to driver
18/01/24 16:39:33 INFO TaskSetManager: Finished task 1.0 in stage 166.0 (TID 462) in 12374 ms on localhost (executor driver) (4/4)
18/01/24 16:39:33 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
18/01/24 16:39:33 INFO DAGScheduler: ResultStage 166 (collect at utils.scala:211) finished in 12.374 s
18/01/24 16:39:33 INFO DAGScheduler: Job 101 finished: collect at utils.scala:211, took 12.376185 s
18/01/24 16:39:33 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:39:33 INFO DAGScheduler: Got job 102 (collect at utils.scala:211) with 1 output partitions
18/01/24 16:39:33 INFO DAGScheduler: Final stage: ResultStage 167 (collect at utils.scala:211)
18/01/24 16:39:33 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:39:33 INFO DAGScheduler: Missing parents: List()
18/01/24 16:39:33 INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[370] at collect at utils.scala:211), which has no missing parents
18/01/24 16:39:33 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 19.9 KB, free 365.3 MB)
18/01/24 16:39:33 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 7.8 KB, free 365.3 MB)
18/01/24 16:39:33 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:33521 (size: 7.8 KB, free: 366.2 MB)
18/01/24 16:39:33 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:996
18/01/24 16:39:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[370] at collect at utils.scala:211)
18/01/24 16:39:33 INFO TaskSchedulerImpl: Adding task set 167.0 with 1 tasks
18/01/24 16:39:33 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 465, localhost, executor driver, partition 5, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:39:33 INFO Executor: Running task 0.0 in stage 167.0 (TID 465)
18/01/24 16:39:33 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 16:39:34 INFO Executor: Finished task 0.0 in stage 167.0 (TID 465). 1555 bytes result sent to driver
18/01/24 16:39:34 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 465) in 839 ms on localhost (executor driver) (1/1)
18/01/24 16:39:34 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
18/01/24 16:39:34 INFO DAGScheduler: ResultStage 167 (collect at utils.scala:211) finished in 0.839 s
18/01/24 16:39:34 INFO DAGScheduler: Job 102 finished: collect at utils.scala:211, took 0.841781 s
18/01/24 16:47:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz17`
WHERE (0 = 1)
18/01/24 16:47:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
LIMIT 6
18/01/24 16:47:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
LIMIT 6
18/01/24 16:47:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
LIMIT 6
18/01/24 16:47:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
LIMIT 6
18/01/24 16:47:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
LIMIT 6
18/01/24 16:47:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 16:47:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
LIMIT 6
18/01/24 16:47:45 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 16:47:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#1744),isnotnull(dayofmonth#1745),(cast(month#1744 as double) = 1.0),(cast(dayofmonth#1745 as double) = 24.0)
18/01/24 16:47:45 INFO FileSourceStrategy: Output Data Schema: struct<year: string, month: string, dayofmonth: string, dayofweek: string, deptime: string ... 27 more fields>
18/01/24 16:47:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 16:47:45 INFO CodeGenerator: Code generated in 13.485048 ms
18/01/24 16:47:45 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 282.1 KB, free 365.0 MB)
18/01/24 16:47:45 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.0 MB)
18/01/24 16:47:45 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:33521 (size: 23.9 KB, free: 366.2 MB)
18/01/24 16:47:45 INFO SparkContext: Created broadcast 217 from collect at utils.scala:211
18/01/24 16:47:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 16:47:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 16:47:45 INFO DAGScheduler: Got job 103 (collect at utils.scala:211) with 1 output partitions
18/01/24 16:47:45 INFO DAGScheduler: Final stage: ResultStage 168 (collect at utils.scala:211)
18/01/24 16:47:45 INFO DAGScheduler: Parents of final stage: List()
18/01/24 16:47:45 INFO DAGScheduler: Missing parents: List()
18/01/24 16:47:45 INFO DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[373] at collect at utils.scala:211), which has no missing parents
18/01/24 16:47:45 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 20.3 KB, free 365.0 MB)
18/01/24 16:47:45 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 8.0 KB, free 365.0 MB)
18/01/24 16:47:45 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:33521 (size: 8.0 KB, free: 366.2 MB)
18/01/24 16:47:45 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:996
18/01/24 16:47:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[373] at collect at utils.scala:211)
18/01/24 16:47:45 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks
18/01/24 16:47:45 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 466, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/01/24 16:47:45 INFO Executor: Running task 0.0 in stage 168.0 (TID 466)
18/01/24 16:47:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 16:47:45 INFO Executor: Finished task 0.0 in stage 168.0 (TID 466). 2477 bytes result sent to driver
18/01/24 16:47:45 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 466) in 475 ms on localhost (executor driver) (1/1)
18/01/24 16:47:45 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
18/01/24 16:47:45 INFO DAGScheduler: ResultStage 168 (collect at utils.scala:211) finished in 0.475 s
18/01/24 16:47:45 INFO DAGScheduler: Job 103 finished: collect at utils.scala:211, took 0.479384 s
18/01/24 16:47:45 INFO CodeGenerator: Code generated in 17.329804 ms
18/01/24 17:08:06 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:33521 in memory (size: 8.0 KB, free: 366.2 MB)
18/01/24 17:08:06 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:33521 in memory (size: 7.8 KB, free: 366.2 MB)
18/01/24 17:08:06 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:33521 in memory (size: 7.8 KB, free: 366.2 MB)
18/01/24 17:08:06 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:33521 in memory (size: 7.9 KB, free: 366.2 MB)
18/01/24 17:10:55 INFO SparkContext: Invoking stop() from shutdown hook
18/01/24 17:10:55 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/01/24 17:10:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/01/24 17:10:56 INFO MemoryStore: MemoryStore cleared
18/01/24 17:10:56 INFO BlockManager: BlockManager stopped
18/01/24 17:10:56 INFO BlockManagerMaster: BlockManagerMaster stopped
18/01/24 17:10:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/01/24 17:10:56 INFO SparkContext: Successfully stopped SparkContext
18/01/24 17:10:56 INFO ShutdownHookManager: Shutdown hook called
18/01/24 17:10:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-e6ef4e5c-39a2-4d28-b9d3-e186585d373c
18/01/24 17:22:36 INFO SparkContext: Running Spark version 2.1.0
18/01/24 17:22:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/01/24 17:22:37 INFO SecurityManager: Changing view acls to: rstudio-user
18/01/24 17:22:37 INFO SecurityManager: Changing modify acls to: rstudio-user
18/01/24 17:22:37 INFO SecurityManager: Changing view acls groups to: 
18/01/24 17:22:37 INFO SecurityManager: Changing modify acls groups to: 
18/01/24 17:22:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rstudio-user); groups with view permissions: Set(); users  with modify permissions: Set(rstudio-user); groups with modify permissions: Set()
18/01/24 17:22:37 INFO Utils: Successfully started service 'sparkDriver' on port 34097.
18/01/24 17:22:37 INFO SparkEnv: Registering MapOutputTracker
18/01/24 17:22:37 INFO SparkEnv: Registering BlockManagerMaster
18/01/24 17:22:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/01/24 17:22:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/01/24 17:22:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7ef20127-bf7c-40c1-bd56-0df384bf3021
18/01/24 17:22:37 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/01/24 17:22:37 INFO SparkEnv: Registering OutputCommitCoordinator
18/01/24 17:22:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/01/24 17:22:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/01/24 17:22:37 INFO SparkContext: Added JAR file:/home/rstudio-user/R/x86_64-pc-linux-gnu-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:34097/jars/sparklyr-2.1-2.11.jar with timestamp 1516814557476
18/01/24 17:22:37 INFO Executor: Starting executor ID driver on host localhost
18/01/24 17:22:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35342.
18/01/24 17:22:37 INFO NettyBlockTransferService: Server created on 127.0.0.1:35342
18/01/24 17:22:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/01/24 17:22:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 35342, None)
18/01/24 17:22:37 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:35342 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 35342, None)
18/01/24 17:22:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 35342, None)
18/01/24 17:22:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 35342, None)
18/01/24 17:22:40 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/01/24 17:22:40 INFO SharedState: Warehouse path is 'file:/home/rstudio-user/bigdataclass2018/workbook/spark-warehouse'.
18/01/24 17:22:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/01/24 17:22:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/01/24 17:22:41 INFO ObjectStore: ObjectStore, initialize called
18/01/24 17:22:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/01/24 17:22:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/01/24 17:22:42 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/01/24 17:22:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 17:22:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 17:22:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 17:22:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 17:22:44 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/01/24 17:22:44 INFO ObjectStore: Initialized ObjectStore
18/01/24 17:22:44 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/01/24 17:22:44 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/01/24 17:22:45 INFO HiveMetaStore: Added admin role in metastore
18/01/24 17:22:45 INFO HiveMetaStore: Added public role in metastore
18/01/24 17:22:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/01/24 17:22:45 INFO HiveMetaStore: 0: get_all_databases
18/01/24 17:22:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_all_databases	
18/01/24 17:22:45 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/01/24 17:22:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/01/24 17:22:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 17:22:45 INFO SessionState: Created local directory: /tmp/ee16c38b-f08b-4ce0-801e-d160705dfb4e_resources
18/01/24 17:22:45 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio-user/ee16c38b-f08b-4ce0-801e-d160705dfb4e
18/01/24 17:22:45 INFO SessionState: Created local directory: /tmp/rstudio-user/ee16c38b-f08b-4ce0-801e-d160705dfb4e
18/01/24 17:22:45 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio-user/ee16c38b-f08b-4ce0-801e-d160705dfb4e/_tmp_space.db
18/01/24 17:22:45 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/rstudio-user/bigdataclass2018/workbook/spark-warehouse
18/01/24 17:22:45 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:45 INFO HiveMetaStore: 0: get_database: global_temp
18/01/24 17:22:45 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/01/24 17:22:45 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/01/24 17:22:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 17:22:50 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:50 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 17:22:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 17:22:51 INFO CodeGenerator: Code generated in 286.947546 ms
18/01/24 17:22:51 INFO SparkContext: Starting job: collect at utils.scala:58
18/01/24 17:22:51 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/01/24 17:22:51 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/01/24 17:22:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:51 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
18/01/24 17:22:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/01/24 17:22:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/01/24 17:22:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:35342 (size: 4.6 KB, free: 366.3 MB)
18/01/24 17:22:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
18/01/24 17:22:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/01/24 17:22:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
18/01/24 17:22:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/01/24 17:22:51 INFO Executor: Fetching spark://127.0.0.1:34097/jars/sparklyr-2.1-2.11.jar with timestamp 1516814557476
18/01/24 17:22:51 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:34097 after 11 ms (0 ms spent in bootstraps)
18/01/24 17:22:51 INFO Utils: Fetching spark://127.0.0.1:34097/jars/sparklyr-2.1-2.11.jar to /tmp/spark-08719dfc-f250-4193-8d4e-25a19a913ad7/userFiles-982f08b8-a398-4712-a052-ef744921663b/fetchFileTemp5100346204212612366.tmp
18/01/24 17:22:51 INFO Executor: Adding file:/tmp/spark-08719dfc-f250-4193-8d4e-25a19a913ad7/userFiles-982f08b8-a398-4712-a052-ef744921663b/sparklyr-2.1-2.11.jar to class loader
18/01/24 17:22:51 INFO CodeGenerator: Code generated in 14.436248 ms
18/01/24 17:22:51 INFO CodeGenerator: Code generated in 15.589415 ms
18/01/24 17:22:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
18/01/24 17:22:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 239 ms on localhost (executor driver) (1/1)
18/01/24 17:22:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/01/24 17:22:52 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.259 s
18/01/24 17:22:52 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.394698 s
18/01/24 17:22:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:22:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:22:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 17:22:54 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:54 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:54 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:54 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 17:22:54 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 17:22:54 INFO SparkSqlParser: Parsing command: flights
18/01/24 17:22:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:22:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz18`
WHERE (0 = 1)
18/01/24 17:22:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:22:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 17:22:55 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:55 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:55 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:22:55 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:22:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 17:22:55 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 17:22:55 INFO CodeGenerator: Code generated in 12.168763 ms
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 237.2 KB, free 366.1 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.3 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 1 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 1 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 1 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 1 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata MapPartitionsRDD[10] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.3 KB, free 366.0 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1994.0 B, free 366.0 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:35342 (size: 1994.0 B, free: 366.3 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata MapPartitionsRDD[10] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6088 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata/part-00000:0+294
18/01/24 17:22:55 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/01/24 17:22:55 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/01/24 17:22:55 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/01/24 17:22:55 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/01/24 17:22:55 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1384 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 1 (first at ReadWrite.scala:379) finished in 0.037 s
18/01/24 17:22:55 INFO DAGScheduler: Job 1 finished: first at ReadWrite.scala:379, took 0.055794 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 237.3 KB, free 365.8 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.8 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 3 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO ContextCleaner: Cleaned accumulator 0
18/01/24 17:22:55 INFO ContextCleaner: Cleaned accumulator 1
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:35342 in memory (size: 4.6 KB, free: 366.3 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.3 MB)
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:35342 in memory (size: 1994.0 B, free: 366.3 MB)
18/01/24 17:22:55 INFO DAGScheduler: Got job 2 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 2 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 2 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[12] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 366.0 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2036.0 B, free 366.0 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:35342 (size: 2036.0 B, free: 366.3 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[12] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2362 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 13 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 2 (first at ReadWrite.scala:379) finished in 0.013 s
18/01/24 17:22:55 INFO DAGScheduler: Job 2 finished: first at ReadWrite.scala:379, took 0.019840 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 237.3 KB, free 365.8 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.8 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.3 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 5 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 3 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 3 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 3 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[14] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.3 KB, free 365.8 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 2036.0 B, free 365.8 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:35342 (size: 2036.0 B, free: 366.3 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[14] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2362 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 9 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 3 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 17:22:55 INFO DAGScheduler: Job 3 finished: first at ReadWrite.scala:379, took 0.022779 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 237.3 KB, free 365.5 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.5 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 7 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 4 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 4 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 4 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[16] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.3 KB, free 365.5 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2027.0 B, free 365.5 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:35342 (size: 2027.0 B, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[16] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6120 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1294 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 4 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 17:22:55 INFO DAGScheduler: Job 4 finished: first at ReadWrite.scala:379, took 0.014052 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 237.3 KB, free 365.3 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.3 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 9 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 5 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 5 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 5 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[18] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.3 KB, free 365.3 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2027.0 B, free 365.3 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:35342 (size: 2027.0 B, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[18] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6120 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1294 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 5 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 17:22:55 INFO DAGScheduler: Job 5 finished: first at ReadWrite.scala:379, took 0.014255 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 237.3 KB, free 365.0 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.0 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 11 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 6 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 6 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 6 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[20] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.3 KB, free 365.0 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2028.0 B, free 365.0 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:35342 (size: 2028.0 B, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[20] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6120 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1359 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 6 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 17:22:55 INFO DAGScheduler: Job 6 finished: first at ReadWrite.scala:379, took 0.017869 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 237.3 KB, free 364.8 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.7 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 13 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 7 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 7 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 7 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[22] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.3 KB, free 364.7 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2028.0 B, free 364.7 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:35342 (size: 2028.0 B, free: 366.2 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[22] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6120 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1359 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 7 (first at ReadWrite.scala:379) finished in 0.007 s
18/01/24 17:22:55 INFO DAGScheduler: Job 7 finished: first at ReadWrite.scala:379, took 0.012086 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 237.3 KB, free 364.5 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.5 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 15 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 8 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 8 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 8 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[24] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.3 KB, free 364.5 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 2030.0 B, free 364.5 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:35342 (size: 2030.0 B, free: 366.1 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[24] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6120 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1278 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 7 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 8 (first at ReadWrite.scala:379) finished in 0.007 s
18/01/24 17:22:55 INFO DAGScheduler: Job 8 finished: first at ReadWrite.scala:379, took 0.011836 s
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 237.3 KB, free 364.3 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.2 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 17 from textFile at ReadWrite.scala:379
18/01/24 17:22:55 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:55 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:55 INFO DAGScheduler: Got job 9 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 9 (first at ReadWrite.scala:379)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 9 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[26] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 3.3 KB, free 364.2 MB)
18/01/24 17:22:55 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2027.0 B, free 364.2 MB)
18/01/24 17:22:55 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:35342 (size: 2027.0 B, free: 366.1 MB)
18/01/24 17:22:55 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[26] at textFile at ReadWrite.scala:379)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/01/24 17:22:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6120 bytes)
18/01/24 17:22:55 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
18/01/24 17:22:55 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 17:22:55 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1365 bytes result sent to driver
18/01/24 17:22:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
18/01/24 17:22:55 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/01/24 17:22:55 INFO DAGScheduler: ResultStage 9 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 17:22:55 INFO DAGScheduler: Job 9 finished: first at ReadWrite.scala:379, took 0.013823 s
18/01/24 17:22:55 INFO SparkContext: Starting job: parquet at RFormula.scala:341
18/01/24 17:22:55 INFO DAGScheduler: Got job 10 (parquet at RFormula.scala:341) with 1 output partitions
18/01/24 17:22:55 INFO DAGScheduler: Final stage: ResultStage 10 (parquet at RFormula.scala:341)
18/01/24 17:22:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:55 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[28] at parquet at RFormula.scala:341), which has no missing parents
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 70.7 KB, free 364.2 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.3 KB, free 364.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[28] at parquet at RFormula.scala:341)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6277 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1990 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 102 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 10 (parquet at RFormula.scala:341) finished in 0.095 s
18/01/24 17:22:56 INFO DAGScheduler: Job 10 finished: parquet at RFormula.scala:341, took 0.120867 s
18/01/24 17:22:56 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:22:56 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 17:22:56 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
18/01/24 17:22:56 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 17:22:56 INFO CodeGenerator: Code generated in 15.516773 ms
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 283.6 KB, free 363.9 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.5 KB, free 363.8 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:35342 (size: 24.5 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 20 from head at RFormula.scala:341
18/01/24 17:22:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:22:56 INFO SparkContext: Starting job: head at RFormula.scala:341
18/01/24 17:22:56 INFO DAGScheduler: Got job 11 (head at RFormula.scala:341) with 1 output partitions
18/01/24 17:22:56 INFO DAGScheduler: Final stage: ResultStage 11 (head at RFormula.scala:341)
18/01/24 17:22:56 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:56 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:56 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[31] at head at RFormula.scala:341), which has no missing parents
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 9.8 KB, free 363.8 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.7 KB, free 363.8 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:35342 (size: 4.7 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[31] at head at RFormula.scala:341)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6620 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
18/01/24 17:22:56 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/data/part-00000-4c76e860-8b4c-4e35-8244-61bdf47c8710.snappy.parquet, range: 0-946, partition values: [empty row]
18/01/24 17:22:56 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
18/01/24 17:22:56 INFO CodeGenerator: Code generated in 16.873436 ms
18/01/24 17:22:56 INFO CodecPool: Got brand-new decompressor [.snappy]
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1512 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 204 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 11 (head at RFormula.scala:341) finished in 0.206 s
18/01/24 17:22:56 INFO DAGScheduler: Job 11 finished: head at RFormula.scala:341, took 0.228305 s
18/01/24 17:22:56 INFO CodeGenerator: Code generated in 30.19428 ms
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 237.3 KB, free 363.6 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.6 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 22 from textFile at ReadWrite.scala:379
18/01/24 17:22:56 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:56 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:56 INFO DAGScheduler: Got job 12 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:56 INFO DAGScheduler: Final stage: ResultStage 12 (first at ReadWrite.scala:379)
18/01/24 17:22:56 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:56 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:56 INFO DAGScheduler: Submitting ResultStage 12 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[33] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.3 KB, free 363.6 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2039.0 B, free 363.6 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:35342 (size: 2039.0 B, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[33] at textFile at ReadWrite.scala:379)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6134 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
18/01/24 17:22:56 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata/part-00000:0+240
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1330 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 12 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 17:22:56 INFO DAGScheduler: Job 12 finished: first at ReadWrite.scala:379, took 0.011320 s
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 237.3 KB, free 363.3 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.3 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 24 from textFile at ReadWrite.scala:379
18/01/24 17:22:56 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:56 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:56 INFO DAGScheduler: Got job 13 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:56 INFO DAGScheduler: Final stage: ResultStage 13 (first at ReadWrite.scala:379)
18/01/24 17:22:56 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:56 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:56 INFO DAGScheduler: Submitting ResultStage 13 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[35] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.4 KB, free 363.3 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 2044.0 B, free 363.3 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:35342 (size: 2044.0 B, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[35] at textFile at ReadWrite.scala:379)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6167 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
18/01/24 17:22:56 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1297 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 13 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 17:22:56 INFO DAGScheduler: Job 13 finished: first at ReadWrite.scala:379, took 0.012570 s
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 237.3 KB, free 363.1 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 26 from textFile at ReadWrite.scala:379
18/01/24 17:22:56 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:56 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:56 INFO DAGScheduler: Got job 14 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:56 INFO DAGScheduler: Final stage: ResultStage 14 (first at ReadWrite.scala:379)
18/01/24 17:22:56 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:56 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:56 INFO DAGScheduler: Submitting ResultStage 14 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[37] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 3.4 KB, free 363.0 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 2044.0 B, free 363.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:35342 (size: 2044.0 B, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[37] at textFile at ReadWrite.scala:379)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6167 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
18/01/24 17:22:56 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1297 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 14 (first at ReadWrite.scala:379) finished in 0.007 s
18/01/24 17:22:56 INFO DAGScheduler: Job 14 finished: first at ReadWrite.scala:379, took 0.012471 s
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 237.3 KB, free 362.8 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.8 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 28 from textFile at ReadWrite.scala:379
18/01/24 17:22:56 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:56 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:56 INFO DAGScheduler: Got job 15 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:56 INFO DAGScheduler: Final stage: ResultStage 15 (first at ReadWrite.scala:379)
18/01/24 17:22:56 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:56 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:56 INFO DAGScheduler: Submitting ResultStage 15 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[39] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.4 KB, free 362.8 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.0 KB, free 362.8 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[39] at textFile at ReadWrite.scala:379)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6179 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
18/01/24 17:22:56 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1254 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 7 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 15 (first at ReadWrite.scala:379) finished in 0.007 s
18/01/24 17:22:56 INFO DAGScheduler: Job 15 finished: first at ReadWrite.scala:379, took 0.012112 s
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 237.3 KB, free 362.5 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.5 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.9 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 30 from textFile at ReadWrite.scala:379
18/01/24 17:22:56 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:35342 in memory (size: 2036.0 B, free: 366.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:35342 in memory (size: 2030.0 B, free: 366.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:35342 in memory (size: 2027.0 B, free: 366.0 MB)
18/01/24 17:22:56 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:56 INFO DAGScheduler: Got job 16 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:56 INFO DAGScheduler: Final stage: ResultStage 16 (first at ReadWrite.scala:379)
18/01/24 17:22:56 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:56 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:56 INFO DAGScheduler: Submitting ResultStage 16 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[41] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:35342 in memory (size: 25.3 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 3.4 KB, free 363.1 MB)
18/01/24 17:22:56 INFO ContextCleaner: Cleaned accumulator 530
18/01/24 17:22:56 INFO ContextCleaner: Cleaned accumulator 531
18/01/24 17:22:56 INFO ContextCleaner: Cleaned accumulator 532
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:35342 in memory (size: 24.5 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 2.0 KB, free 363.4 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:35342 in memory (size: 4.7 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 366.0 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[41] at textFile at ReadWrite.scala:379)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/01/24 17:22:56 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6179 bytes)
18/01/24 17:22:56 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
18/01/24 17:22:56 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 17:22:56 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1254 bytes result sent to driver
18/01/24 17:22:56 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
18/01/24 17:22:56 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/01/24 17:22:56 INFO DAGScheduler: ResultStage 16 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 17:22:56 INFO DAGScheduler: Job 16 finished: first at ReadWrite.scala:379, took 0.019811 s
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:35342 in memory (size: 2039.0 B, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:35342 in memory (size: 2044.0 B, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:35342 in memory (size: 2044.0 B, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:35342 in memory (size: 2.0 KB, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:35342 in memory (size: 2027.0 B, free: 366.1 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:35342 in memory (size: 2028.0 B, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:35342 in memory (size: 2028.0 B, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:35342 in memory (size: 2036.0 B, free: 366.2 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.3 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:35342 in memory (size: 2027.0 B, free: 366.3 MB)
18/01/24 17:22:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.3 MB)
18/01/24 17:22:57 INFO SparkContext: Starting job: parquet at RFormula.scala:503
18/01/24 17:22:57 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:503) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:503)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[43] at parquet at RFormula.scala:503), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 70.7 KB, free 366.0 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 25.3 KB, free 365.9 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 366.3 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[43] at parquet at RFormula.scala:503)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6332 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1924 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 20 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:503) finished in 0.023 s
18/01/24 17:22:57 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:503, took 0.040562 s
18/01/24 17:22:57 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:22:57 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 17:22:57 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
18/01/24 17:22:57 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 23.209967 ms
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 283.3 KB, free 365.7 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.4 KB, free 365.6 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:35342 (size: 24.4 KB, free: 366.2 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 33 from head at RFormula.scala:503
18/01/24 17:22:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:22:57 INFO SparkContext: Starting job: head at RFormula.scala:503
18/01/24 17:22:57 INFO DAGScheduler: Got job 18 (head at RFormula.scala:503) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 18 (head at RFormula.scala:503)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[46] at head at RFormula.scala:503), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 10.3 KB, free 365.6 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.8 KB, free 365.6 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:35342 (size: 4.8 KB, free: 366.2 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[46] at head at RFormula.scala:503)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6675 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
18/01/24 17:22:57 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/data/part-00000-46d12c43-4d60-4984-8900-332c8821b472.snappy.parquet, range: 0-812, partition values: [empty row]
18/01/24 17:22:57 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 22.723931 ms
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1457 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 42 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 18 (head at RFormula.scala:503) finished in 0.044 s
18/01/24 17:22:57 INFO DAGScheduler: Job 18 finished: head at RFormula.scala:503, took 0.048749 s
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 47.994625 ms
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 237.3 KB, free 365.4 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.4 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 35 from textFile at ReadWrite.scala:379
18/01/24 17:22:57 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:57 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:57 INFO DAGScheduler: Got job 19 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 19 (first at ReadWrite.scala:379)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 19 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[48] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 3.4 KB, free 365.4 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.4 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 366.2 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[48] at textFile at ReadWrite.scala:379)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6170 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
18/01/24 17:22:57 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1237 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 19 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 17:22:57 INFO DAGScheduler: Job 19 finished: first at ReadWrite.scala:379, took 0.012411 s
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 237.3 KB, free 365.1 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.1 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.2 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 37 from textFile at ReadWrite.scala:379
18/01/24 17:22:57 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:57 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:57 INFO DAGScheduler: Got job 20 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 20 (first at ReadWrite.scala:379)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 20 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[50] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 3.4 KB, free 365.1 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.0 KB, free 365.1 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 366.2 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[50] at textFile at ReadWrite.scala:379)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6171 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
18/01/24 17:22:57 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1237 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 20 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 17:22:57 INFO DAGScheduler: Job 20 finished: first at ReadWrite.scala:379, took 0.011173 s
18/01/24 17:22:57 INFO SparkContext: Starting job: parquet at RFormula.scala:412
18/01/24 17:22:57 INFO DAGScheduler: Got job 21 (parquet at RFormula.scala:412) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 21 (parquet at RFormula.scala:412)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[52] at parquet at RFormula.scala:412), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 70.7 KB, free 365.0 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 25.3 KB, free 365.0 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[52] at parquet at RFormula.scala:412)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6327 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1773 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 13 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 21 (parquet at RFormula.scala:412) finished in 0.012 s
18/01/24 17:22:57 INFO DAGScheduler: Job 21 finished: parquet at RFormula.scala:412, took 0.033551 s
18/01/24 17:22:57 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:22:57 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 17:22:57 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
18/01/24 17:22:57 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 23.114404 ms
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 282.9 KB, free 364.7 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.4 KB, free 364.7 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:35342 (size: 24.4 KB, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 40 from head at RFormula.scala:412
18/01/24 17:22:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:22:57 INFO SparkContext: Starting job: head at RFormula.scala:412
18/01/24 17:22:57 INFO DAGScheduler: Got job 22 (head at RFormula.scala:412) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 22 (head at RFormula.scala:412)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[55] at head at RFormula.scala:412), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 8.2 KB, free 364.7 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.3 KB, free 364.7 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:35342 (size: 4.3 KB, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[55] at head at RFormula.scala:412)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
18/01/24 17:22:57 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/data/part-00000-593de674-2fd9-48f5-b311-77492e49101f.snappy.parquet, range: 0-461, partition values: [empty row]
18/01/24 17:22:57 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 14.697661 ms
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1441 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 36 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 22 (head at RFormula.scala:412) finished in 0.035 s
18/01/24 17:22:57 INFO DAGScheduler: Job 22 finished: head at RFormula.scala:412, took 0.040907 s
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 13.827151 ms
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 237.3 KB, free 364.5 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.5 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 42 from textFile at ReadWrite.scala:379
18/01/24 17:22:57 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:57 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:57 INFO DAGScheduler: Got job 23 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 23 (first at ReadWrite.scala:379)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 23 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[57] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 3.3 KB, free 364.4 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 2037.0 B, free 364.4 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:35342 (size: 2037.0 B, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[57] at textFile at ReadWrite.scala:379)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6131 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
18/01/24 17:22:57 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1563 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 5 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 23 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 17:22:57 INFO DAGScheduler: Job 23 finished: first at ReadWrite.scala:379, took 0.009555 s
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 237.3 KB, free 364.2 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.2 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 44 from textFile at ReadWrite.scala:379
18/01/24 17:22:57 INFO FileInputFormat: Total input paths to process : 1
18/01/24 17:22:57 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 17:22:57 INFO DAGScheduler: Got job 24 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 24 (first at ReadWrite.scala:379)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 24 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[59] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 3.3 KB, free 364.2 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 2037.0 B, free 364.2 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:35342 (size: 2037.0 B, free: 366.1 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[59] at textFile at ReadWrite.scala:379)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6131 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
18/01/24 17:22:57 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1563 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 24 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 17:22:57 INFO DAGScheduler: Job 24 finished: first at ReadWrite.scala:379, took 0.010166 s
18/01/24 17:22:57 INFO SparkContext: Starting job: load at LogisticRegression.scala:979
18/01/24 17:22:57 INFO DAGScheduler: Got job 25 (load at LogisticRegression.scala:979) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 25 (load at LogisticRegression.scala:979)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[61] at load at LogisticRegression.scala:979), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 70.7 KB, free 364.1 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 25.3 KB, free 364.1 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 366.0 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[61] at load at LogisticRegression.scala:979)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6288 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2159 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 26 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 25 (load at LogisticRegression.scala:979) finished in 0.027 s
18/01/24 17:22:57 INFO DAGScheduler: Job 25 finished: load at LogisticRegression.scala:979, took 0.040502 s
18/01/24 17:22:57 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:22:57 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 17:22:57 INFO FileSourceStrategy: Output Data Schema: struct<numClasses: int, numFeatures: int, interceptVector: vector, coefficientMatrix: matrix, isMultinomial: boolean ... 3 more fields>
18/01/24 17:22:57 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 24.894942 ms
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 288.7 KB, free 363.8 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 25.0 KB, free 363.8 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:35342 (size: 25.0 KB, free: 366.0 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 47 from head at LogisticRegression.scala:997
18/01/24 17:22:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:22:57 INFO SparkContext: Starting job: head at LogisticRegression.scala:997
18/01/24 17:22:57 INFO DAGScheduler: Got job 26 (head at LogisticRegression.scala:997) with 1 output partitions
18/01/24 17:22:57 INFO DAGScheduler: Final stage: ResultStage 26 (head at LogisticRegression.scala:997)
18/01/24 17:22:57 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:22:57 INFO DAGScheduler: Missing parents: List()
18/01/24 17:22:57 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[64] at head at LogisticRegression.scala:997), which has no missing parents
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 17.3 KB, free 363.8 MB)
18/01/24 17:22:57 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 6.2 KB, free 363.8 MB)
18/01/24 17:22:57 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:35342 (size: 6.2 KB, free: 366.0 MB)
18/01/24 17:22:57 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
18/01/24 17:22:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[64] at head at LogisticRegression.scala:997)
18/01/24 17:22:57 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
18/01/24 17:22:57 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6630 bytes)
18/01/24 17:22:57 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
18/01/24 17:22:57 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/data/part-00000-d0beedf9-5461-4cb8-8867-676902a6c5f5.snappy.parquet, range: 0-3705, partition values: [empty row]
18/01/24 17:22:57 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

Catalyst form:
StructType(StructField(numClasses,IntegerType,true), StructField(numFeatures,IntegerType,true), StructField(interceptVector,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(coefficientMatrix,org.apache.spark.ml.linalg.MatrixUDT@e59e0c69,true), StructField(isMultinomial,BooleanType,true))
       
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 52.208507 ms
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 20.747534 ms
18/01/24 17:22:57 INFO CodeGenerator: Code generated in 24.986879 ms
18/01/24 17:22:57 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1526 bytes result sent to driver
18/01/24 17:22:57 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 135 ms on localhost (executor driver) (1/1)
18/01/24 17:22:57 INFO DAGScheduler: ResultStage 26 (head at LogisticRegression.scala:997) finished in 0.136 s
18/01/24 17:22:57 INFO DAGScheduler: Job 26 finished: head at LogisticRegression.scala:997, took 0.141694 s
18/01/24 17:22:57 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/01/24 17:22:58 INFO CodeGenerator: Code generated in 15.810295 ms
18/01/24 17:23:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 17:23:05 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:23:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:23:05 INFO HiveMetaStore: 0: get_database: default
18/01/24 17:23:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 17:23:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 17:23:05 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 17:23:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz19`
WHERE (0 = 1)
18/01/24 17:23:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
18/01/24 17:23:07 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_16d77319950f
18/01/24 17:23:07 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_16d77319950f`) `qibeoammfo`) `qkyoruvxll`
18/01/24 17:23:07 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_ae514c034e2a
18/01/24 17:23:07 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_ae514c034e2a`) `qibeoammfo`) `qkyoruvxll`
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 869
18/01/24 17:23:07 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_10d5e86b5211
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:35342 in memory (size: 24.4 KB, free: 366.0 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:35342 in memory (size: 4.8 KB, free: 366.0 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 1064
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 1066
18/01/24 17:23:07 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_10d5e86b5211`) `qibeoammfo`) `qkyoruvxll`
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:35342 in memory (size: 2037.0 B, free: 366.1 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 1259
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:35342 in memory (size: 25.0 KB, free: 366.1 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:35342 in memory (size: 25.3 KB, free: 366.2 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 870
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:35342 in memory (size: 25.3 KB, free: 366.2 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:35342 in memory (size: 24.4 KB, free: 366.2 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:35342 in memory (size: 25.3 KB, free: 366.2 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 1260
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:35342 in memory (size: 4.3 KB, free: 366.2 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:35342 in memory (size: 2037.0 B, free: 366.2 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 1261
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:35342 in memory (size: 6.2 KB, free: 366.2 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:35342 in memory (size: 2.0 KB, free: 366.3 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 871
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.3 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:35342 in memory (size: 2.0 KB, free: 366.3 MB)
18/01/24 17:23:07 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:35342 in memory (size: 2.0 KB, free: 366.3 MB)
18/01/24 17:23:07 INFO ContextCleaner: Cleaned accumulator 1065
18/01/24 17:23:09 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6104260f968e
18/01/24 17:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e` AS `zzz20`
WHERE (0 = 1)
18/01/24 17:23:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:23:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:23:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:23:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:23:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:23:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:23:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:23:26 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:23:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:23:26 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrtime: string, crsarrtime: string ... 6 more fields>
18/01/24 17:23:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:23:26 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/01/24 17:23:26 INFO CodeGenerator: Code generated in 149.620748 ms
18/01/24 17:23:26 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 282.1 KB, free 365.8 MB)
18/01/24 17:23:26 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.7 MB)
18/01/24 17:23:26 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.3 MB)
18/01/24 17:23:26 INFO SparkContext: Created broadcast 49 from collect at utils.scala:211
18/01/24 17:23:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:23:26 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:23:26 INFO DAGScheduler: Got job 27 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:23:26 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:211)
18/01/24 17:23:26 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:23:26 INFO DAGScheduler: Missing parents: List()
18/01/24 17:23:26 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[76] at collect at utils.scala:211), which has no missing parents
18/01/24 17:23:26 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 85.3 KB, free 365.7 MB)
18/01/24 17:23:26 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 26.3 KB, free 365.6 MB)
18/01/24 17:23:26 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:35342 (size: 26.3 KB, free: 366.2 MB)
18/01/24 17:23:26 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
18/01/24 17:23:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[76] at collect at utils.scala:211)
18/01/24 17:23:26 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
18/01/24 17:23:26 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6499 bytes)
18/01/24 17:23:26 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
18/01/24 17:23:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:23:26 INFO CodeGenerator: Code generated in 18.009622 ms
18/01/24 17:23:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/01/24 17:23:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/01/24 17:23:27 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 60037 bytes result sent to driver
18/01/24 17:23:27 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 778 ms on localhost (executor driver) (1/1)
18/01/24 17:23:27 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/01/24 17:23:27 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:211) finished in 0.752 s
18/01/24 17:23:27 INFO DAGScheduler: Job 27 finished: collect at utils.scala:211, took 0.807613 s
18/01/24 17:23:27 INFO CodeGenerator: Code generated in 13.587165 ms
18/01/24 17:26:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:26:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:26:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:26:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:26:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:26:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:26:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:26:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:26:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:26:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:26:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:26:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:26:18 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:26:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:26:18 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrtime: string, crsarrtime: string ... 6 more fields>
18/01/24 17:26:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:26:18 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 282.1 KB, free 365.4 MB)
18/01/24 17:26:18 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.3 MB)
18/01/24 17:26:18 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.2 MB)
18/01/24 17:26:18 INFO SparkContext: Created broadcast 51 from collect at utils.scala:211
18/01/24 17:26:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:26:18 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:26:18 INFO DAGScheduler: Got job 28 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:26:18 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:211)
18/01/24 17:26:18 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:26:18 INFO DAGScheduler: Missing parents: List()
18/01/24 17:26:18 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[79] at collect at utils.scala:211), which has no missing parents
18/01/24 17:26:18 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 85.3 KB, free 365.3 MB)
18/01/24 17:26:18 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 26.3 KB, free 365.2 MB)
18/01/24 17:26:18 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:35342 (size: 26.3 KB, free: 366.2 MB)
18/01/24 17:26:18 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
18/01/24 17:26:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[79] at collect at utils.scala:211)
18/01/24 17:26:18 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
18/01/24 17:26:18 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6499 bytes)
18/01/24 17:26:18 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
18/01/24 17:26:18 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:26:18 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 60124 bytes result sent to driver
18/01/24 17:26:18 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 327 ms on localhost (executor driver) (1/1)
18/01/24 17:26:18 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/01/24 17:26:18 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:211) finished in 0.326 s
18/01/24 17:26:18 INFO DAGScheduler: Job 28 finished: collect at utils.scala:211, took 0.333641 s
18/01/24 17:33:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:44 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:33:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:44 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:33:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:44 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:33:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:44 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:33:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:44 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 17:33:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:44 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:33:45 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:33:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:33:45 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:33:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:33:45 INFO CodeGenerator: Code generated in 20.882476 ms
18/01/24 17:33:45 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 282.1 KB, free 365.0 MB)
18/01/24 17:33:45 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.9 MB)
18/01/24 17:33:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.2 MB)
18/01/24 17:33:45 INFO SparkContext: Created broadcast 53 from collect at utils.scala:211
18/01/24 17:33:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:33:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:33:45 INFO DAGScheduler: Got job 29 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:33:45 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:211)
18/01/24 17:33:45 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:33:45 INFO DAGScheduler: Missing parents: List()
18/01/24 17:33:45 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[82] at collect at utils.scala:211), which has no missing parents
18/01/24 17:33:45 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 32.3 KB, free 364.9 MB)
18/01/24 17:33:45 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 13.8 KB, free 364.9 MB)
18/01/24 17:33:45 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:35342 (size: 13.8 KB, free: 366.1 MB)
18/01/24 17:33:45 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:996
18/01/24 17:33:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[82] at collect at utils.scala:211)
18/01/24 17:33:45 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
18/01/24 17:33:45 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 6499 bytes)
18/01/24 17:33:45 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:35342 in memory (size: 26.3 KB, free: 366.2 MB)
18/01/24 17:33:45 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
18/01/24 17:33:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:33:45 INFO CodeGenerator: Code generated in 5.750929 ms
18/01/24 17:33:45 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 6476 bytes result sent to driver
18/01/24 17:33:45 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 290 ms on localhost (executor driver) (1/1)
18/01/24 17:33:45 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
18/01/24 17:33:45 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:211) finished in 0.290 s
18/01/24 17:33:45 INFO DAGScheduler: Job 29 finished: collect at utils.scala:211, took 0.294289 s
18/01/24 17:33:45 INFO CodeGenerator: Code generated in 6.244719 ms
18/01/24 17:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:54 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
ORDER BY `crsdeptime`
18/01/24 17:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:54 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
ORDER BY `crsdeptime`
18/01/24 17:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:54 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
ORDER BY `crsdeptime`
18/01/24 17:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:54 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
ORDER BY `crsdeptime`
18/01/24 17:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:54 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
ORDER BY `crsdeptime`
18/01/24 17:33:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:33:54 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM `sparklyr_tmp_6104260f968e`
ORDER BY `crsdeptime`
LIMIT 1000
18/01/24 17:33:55 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:33:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:33:55 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:33:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:33:55 INFO CodeGenerator: Code generated in 13.00856 ms
18/01/24 17:33:55 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 282.1 KB, free 364.7 MB)
18/01/24 17:33:55 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.7 MB)
18/01/24 17:33:55 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.1 MB)
18/01/24 17:33:55 INFO SparkContext: Created broadcast 55 from collect at utils.scala:211
18/01/24 17:33:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:33:55 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:33:55 INFO DAGScheduler: Got job 30 (collect at utils.scala:211) with 6 output partitions
18/01/24 17:33:55 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:211)
18/01/24 17:33:55 INFO DAGScheduler: Parents of final stage: List()
18/01/24 17:33:55 INFO DAGScheduler: Missing parents: List()
18/01/24 17:33:55 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[86] at collect at utils.scala:211), which has no missing parents
18/01/24 17:33:55 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 33.2 KB, free 364.7 MB)
18/01/24 17:33:55 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 14.3 KB, free 364.7 MB)
18/01/24 17:33:55 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:35342 (size: 14.3 KB, free: 366.1 MB)
18/01/24 17:33:55 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
18/01/24 17:33:55 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 30 (MapPartitionsRDD[86] at collect at utils.scala:211)
18/01/24 17:33:55 INFO TaskSchedulerImpl: Adding task set 30.0 with 6 tasks
18/01/24 17:33:55 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6590 bytes)
18/01/24 17:33:55 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 6590 bytes)
18/01/24 17:33:55 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 6590 bytes)
18/01/24 17:33:55 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 6590 bytes)
18/01/24 17:33:55 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
18/01/24 17:33:55 INFO Executor: Running task 1.0 in stage 30.0 (TID 31)
18/01/24 17:33:55 INFO Executor: Running task 2.0 in stage 30.0 (TID 32)
18/01/24 17:33:55 INFO Executor: Running task 3.0 in stage 30.0 (TID 33)
18/01/24 17:33:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:33:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:33:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:33:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:33:55 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:35342 in memory (size: 13.8 KB, free: 366.1 MB)
18/01/24 17:34:01 INFO Executor: Finished task 2.0 in stage 30.0 (TID 32). 2865 bytes result sent to driver
18/01/24 17:34:01 INFO TaskSetManager: Starting task 4.0 in stage 30.0 (TID 34, localhost, executor driver, partition 4, PROCESS_LOCAL, 6590 bytes)
18/01/24 17:34:01 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 32) in 6115 ms on localhost (executor driver) (1/6)
18/01/24 17:34:01 INFO Executor: Running task 4.0 in stage 30.0 (TID 34)
18/01/24 17:34:01 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:34:01 INFO Executor: Finished task 1.0 in stage 30.0 (TID 31). 2778 bytes result sent to driver
18/01/24 17:34:01 INFO TaskSetManager: Starting task 5.0 in stage 30.0 (TID 35, localhost, executor driver, partition 5, PROCESS_LOCAL, 6590 bytes)
18/01/24 17:34:01 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 31) in 6220 ms on localhost (executor driver) (2/6)
18/01/24 17:34:01 INFO Executor: Running task 5.0 in stage 30.0 (TID 35)
18/01/24 17:34:01 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:34:01 INFO Executor: Finished task 3.0 in stage 30.0 (TID 33). 2778 bytes result sent to driver
18/01/24 17:34:01 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 33) in 6440 ms on localhost (executor driver) (3/6)
18/01/24 17:34:01 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 44183 bytes result sent to driver
18/01/24 17:34:01 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 6457 ms on localhost (executor driver) (4/6)
18/01/24 17:34:02 INFO Executor: Finished task 5.0 in stage 30.0 (TID 35). 2778 bytes result sent to driver
18/01/24 17:34:02 INFO TaskSetManager: Finished task 5.0 in stage 30.0 (TID 35) in 726 ms on localhost (executor driver) (5/6)
18/01/24 17:34:04 INFO Executor: Finished task 4.0 in stage 30.0 (TID 34). 2778 bytes result sent to driver
18/01/24 17:34:04 INFO TaskSetManager: Finished task 4.0 in stage 30.0 (TID 34) in 3122 ms on localhost (executor driver) (6/6)
18/01/24 17:34:04 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
18/01/24 17:34:04 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:211) finished in 9.237 s
18/01/24 17:34:04 INFO DAGScheduler: Job 30 finished: collect at utils.scala:211, took 9.243883 s
18/01/24 17:36:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:36:42 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 6) `athigzmomm`) `rnfhiitcse`
18/01/24 17:36:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:36:42 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 6) `opxefkqxko`) `redzkrasvn`
18/01/24 17:36:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:36:42 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 6) `kmbdgwuial`) `xyenqdmcyg`
18/01/24 17:36:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:36:42 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 6) `hyujfxakty`) `zmppvxfxii`
18/01/24 17:36:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:36:42 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 6) `gvdmuatfon`) `ybpiifmtiv`
18/01/24 17:36:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:36:42 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 6) `hderigynoy`) `fcvqsqonyu`
LIMIT 1000
18/01/24 17:36:43 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:36:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:36:43 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:36:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:36:43 INFO CodeGenerator: Code generated in 11.710529 ms
18/01/24 17:36:43 INFO CodeGenerator: Code generated in 18.216555 ms
18/01/24 17:36:43 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 282.1 KB, free 364.4 MB)
18/01/24 17:36:43 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.4 MB)
18/01/24 17:36:43 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.1 MB)
18/01/24 17:36:43 INFO SparkContext: Created broadcast 57 from collect at utils.scala:211
18/01/24 17:36:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:36:43 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:36:43 INFO DAGScheduler: Registering RDD 89 (collect at utils.scala:211)
18/01/24 17:36:43 INFO DAGScheduler: Got job 31 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:36:43 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:211)
18/01/24 17:36:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
18/01/24 17:36:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
18/01/24 17:36:43 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[89] at collect at utils.scala:211), which has no missing parents
18/01/24 17:36:43 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 34.5 KB, free 364.4 MB)
18/01/24 17:36:43 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 14.9 KB, free 364.3 MB)
18/01/24 17:36:43 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 366.1 MB)
18/01/24 17:36:43 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
18/01/24 17:36:43 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[89] at collect at utils.scala:211)
18/01/24 17:36:43 INFO TaskSchedulerImpl: Adding task set 31.0 with 6 tasks
18/01/24 17:36:43 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:36:43 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 37, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:36:43 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 38, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:36:43 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 39, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:36:43 INFO Executor: Running task 0.0 in stage 31.0 (TID 36)
18/01/24 17:36:43 INFO Executor: Running task 1.0 in stage 31.0 (TID 37)
18/01/24 17:36:43 INFO Executor: Running task 2.0 in stage 31.0 (TID 38)
18/01/24 17:36:43 INFO Executor: Running task 3.0 in stage 31.0 (TID 39)
18/01/24 17:36:43 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:36:43 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:36:43 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:36:43 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:36:44 INFO Executor: Finished task 0.0 in stage 31.0 (TID 36). 2030 bytes result sent to driver
18/01/24 17:36:44 INFO TaskSetManager: Starting task 4.0 in stage 31.0 (TID 40, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:36:44 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 36) in 584 ms on localhost (executor driver) (1/6)
18/01/24 17:36:44 INFO Executor: Running task 4.0 in stage 31.0 (TID 40)
18/01/24 17:36:44 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:36:49 INFO Executor: Finished task 3.0 in stage 31.0 (TID 39). 1674 bytes result sent to driver
18/01/24 17:36:49 INFO TaskSetManager: Starting task 5.0 in stage 31.0 (TID 41, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:36:49 INFO Executor: Running task 5.0 in stage 31.0 (TID 41)
18/01/24 17:36:49 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 39) in 6016 ms on localhost (executor driver) (2/6)
18/01/24 17:36:49 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:36:50 INFO Executor: Finished task 1.0 in stage 31.0 (TID 37). 1674 bytes result sent to driver
18/01/24 17:36:50 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 37) in 6241 ms on localhost (executor driver) (3/6)
18/01/24 17:36:50 INFO Executor: Finished task 2.0 in stage 31.0 (TID 38). 1674 bytes result sent to driver
18/01/24 17:36:50 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 38) in 6493 ms on localhost (executor driver) (4/6)
18/01/24 17:36:50 INFO Executor: Finished task 4.0 in stage 31.0 (TID 40). 1674 bytes result sent to driver
18/01/24 17:36:50 INFO TaskSetManager: Finished task 4.0 in stage 31.0 (TID 40) in 5978 ms on localhost (executor driver) (5/6)
18/01/24 17:36:50 INFO Executor: Finished task 5.0 in stage 31.0 (TID 41). 1674 bytes result sent to driver
18/01/24 17:36:50 INFO TaskSetManager: Finished task 5.0 in stage 31.0 (TID 41) in 628 ms on localhost (executor driver) (6/6)
18/01/24 17:36:50 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
18/01/24 17:36:50 INFO DAGScheduler: ShuffleMapStage 31 (collect at utils.scala:211) finished in 6.645 s
18/01/24 17:36:50 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:36:50 INFO DAGScheduler: running: Set()
18/01/24 17:36:50 INFO DAGScheduler: waiting: Set(ResultStage 32)
18/01/24 17:36:50 INFO DAGScheduler: failed: Set()
18/01/24 17:36:50 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[92] at collect at utils.scala:211), which has no missing parents
18/01/24 17:36:50 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 8.5 KB, free 364.3 MB)
18/01/24 17:36:50 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 4.1 KB, free 364.3 MB)
18/01/24 17:36:50 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:35342 (size: 4.1 KB, free: 366.1 MB)
18/01/24 17:36:50 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
18/01/24 17:36:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[92] at collect at utils.scala:211)
18/01/24 17:36:50 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
18/01/24 17:36:50 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 42, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:36:50 INFO Executor: Running task 0.0 in stage 32.0 (TID 42)
18/01/24 17:36:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:36:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/01/24 17:36:50 INFO Executor: Finished task 0.0 in stage 32.0 (TID 42). 1895 bytes result sent to driver
18/01/24 17:36:50 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 42) in 26 ms on localhost (executor driver) (1/1)
18/01/24 17:36:50 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
18/01/24 17:36:50 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:211) finished in 0.027 s
18/01/24 17:36:50 INFO DAGScheduler: Job 31 finished: collect at utils.scala:211, took 6.722182 s
18/01/24 17:36:50 INFO CodeGenerator: Code generated in 5.55753 ms
18/01/24 17:37:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:37:23 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `dewfkieyoa`) `vhiyrxuowa`
18/01/24 17:37:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:37:23 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `gxlkbmstes`) `vjdbtbrjjn`
18/01/24 17:37:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:37:23 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `bizlvbzrrr`) `xjueiflcdm`
18/01/24 17:37:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:37:23 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `ntucetldng`) `hqjpsaucty`
18/01/24 17:37:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:37:24 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `hvkydjraes`) `wyvwlblqds`
18/01/24 17:37:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:37:24 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `wmvqxloubp`) `uutodzlxrr`
LIMIT 1000
18/01/24 17:37:24 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:37:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:37:24 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:37:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:37:24 INFO CodeGenerator: Code generated in 5.78082 ms
18/01/24 17:37:24 INFO CodeGenerator: Code generated in 29.865637 ms
18/01/24 17:37:24 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 282.1 KB, free 364.1 MB)
18/01/24 17:37:24 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 23.9 KB, free 364.0 MB)
18/01/24 17:37:24 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.1 MB)
18/01/24 17:37:24 INFO SparkContext: Created broadcast 60 from collect at utils.scala:211
18/01/24 17:37:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:37:24 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:37:24 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:211)
18/01/24 17:37:24 INFO DAGScheduler: Got job 32 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:37:24 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:211)
18/01/24 17:37:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
18/01/24 17:37:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
18/01/24 17:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[95] at collect at utils.scala:211), which has no missing parents
18/01/24 17:37:24 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 34.5 KB, free 364.0 MB)
18/01/24 17:37:24 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 14.9 KB, free 364.0 MB)
18/01/24 17:37:24 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 366.1 MB)
18/01/24 17:37:24 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
18/01/24 17:37:24 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[95] at collect at utils.scala:211)
18/01/24 17:37:24 INFO TaskSchedulerImpl: Adding task set 33.0 with 6 tasks
18/01/24 17:37:24 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:37:24 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 44, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:37:24 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 45, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:37:24 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 46, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:37:24 INFO Executor: Running task 0.0 in stage 33.0 (TID 43)
18/01/24 17:37:24 INFO Executor: Running task 1.0 in stage 33.0 (TID 44)
18/01/24 17:37:24 INFO Executor: Running task 3.0 in stage 33.0 (TID 46)
18/01/24 17:37:24 INFO Executor: Running task 2.0 in stage 33.0 (TID 45)
18/01/24 17:37:24 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:37:24 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:37:24 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:37:24 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:37:25 INFO Executor: Finished task 0.0 in stage 33.0 (TID 43). 1943 bytes result sent to driver
18/01/24 17:37:25 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 47, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:37:25 INFO Executor: Running task 4.0 in stage 33.0 (TID 47)
18/01/24 17:37:25 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 43) in 789 ms on localhost (executor driver) (1/6)
18/01/24 17:37:25 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:37:30 INFO Executor: Finished task 2.0 in stage 33.0 (TID 45). 1761 bytes result sent to driver
18/01/24 17:37:30 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 48, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:37:30 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 45) in 6069 ms on localhost (executor driver) (2/6)
18/01/24 17:37:30 INFO Executor: Running task 5.0 in stage 33.0 (TID 48)
18/01/24 17:37:30 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:37:30 INFO Executor: Finished task 3.0 in stage 33.0 (TID 46). 1674 bytes result sent to driver
18/01/24 17:37:30 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 46) in 6444 ms on localhost (executor driver) (3/6)
18/01/24 17:37:30 INFO Executor: Finished task 1.0 in stage 33.0 (TID 44). 1674 bytes result sent to driver
18/01/24 17:37:30 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 44) in 6598 ms on localhost (executor driver) (4/6)
18/01/24 17:37:30 INFO Executor: Finished task 4.0 in stage 33.0 (TID 47). 1674 bytes result sent to driver
18/01/24 17:37:30 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 47) in 5918 ms on localhost (executor driver) (5/6)
18/01/24 17:37:31 INFO Executor: Finished task 5.0 in stage 33.0 (TID 48). 1674 bytes result sent to driver
18/01/24 17:37:31 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 48) in 673 ms on localhost (executor driver) (6/6)
18/01/24 17:37:31 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
18/01/24 17:37:31 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:211) finished in 6.739 s
18/01/24 17:37:31 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:37:31 INFO DAGScheduler: running: Set()
18/01/24 17:37:31 INFO DAGScheduler: waiting: Set(ResultStage 34)
18/01/24 17:37:31 INFO DAGScheduler: failed: Set()
18/01/24 17:37:31 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[98] at collect at utils.scala:211), which has no missing parents
18/01/24 17:37:31 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 8.5 KB, free 364.0 MB)
18/01/24 17:37:31 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 4.2 KB, free 364.0 MB)
18/01/24 17:37:31 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:35342 (size: 4.2 KB, free: 366.1 MB)
18/01/24 17:37:31 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
18/01/24 17:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[98] at collect at utils.scala:211)
18/01/24 17:37:31 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
18/01/24 17:37:31 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 49, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:37:31 INFO Executor: Running task 0.0 in stage 34.0 (TID 49)
18/01/24 17:37:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:37:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 17:37:31 INFO Executor: Finished task 0.0 in stage 34.0 (TID 49). 6367 bytes result sent to driver
18/01/24 17:37:31 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 49) in 11 ms on localhost (executor driver) (1/1)
18/01/24 17:37:31 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
18/01/24 17:37:31 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:211) finished in 0.011 s
18/01/24 17:37:31 INFO DAGScheduler: Job 32 finished: collect at utils.scala:211, took 6.759786 s
18/01/24 17:41:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:46 INFO SparkSqlParser: Parsing command: SELECT `crsdeptime`, `prediction`
FROM (SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000) `uriyntriis`
18/01/24 17:41:46 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61043899e911
18/01/24 17:41:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911` AS `zzz21`
WHERE (0 = 1)
18/01/24 17:41:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911`
18/01/24 17:41:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911`
18/01/24 17:41:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911`
18/01/24 17:41:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911`
18/01/24 17:41:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911`
18/01/24 17:41:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:41:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043899e911`
LIMIT 1000
18/01/24 17:41:47 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:41:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:41:47 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:41:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:41:47 INFO CodeGenerator: Code generated in 13.095114 ms
18/01/24 17:41:47 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 282.1 KB, free 363.7 MB)
18/01/24 17:41:47 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 23.9 KB, free 363.7 MB)
18/01/24 17:41:47 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.0 MB)
18/01/24 17:41:47 INFO SparkContext: Created broadcast 63 from collect at utils.scala:211
18/01/24 17:41:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:41:47 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:41:47 INFO DAGScheduler: Registering RDD 102 (collect at utils.scala:211)
18/01/24 17:41:47 INFO DAGScheduler: Got job 33 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:41:47 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:211)
18/01/24 17:41:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
18/01/24 17:41:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
18/01/24 17:41:47 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[102] at collect at utils.scala:211), which has no missing parents
18/01/24 17:41:47 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 34.5 KB, free 363.6 MB)
18/01/24 17:41:47 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 14.9 KB, free 363.6 MB)
18/01/24 17:41:47 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 366.0 MB)
18/01/24 17:41:47 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
18/01/24 17:41:47 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[102] at collect at utils.scala:211)
18/01/24 17:41:47 INFO TaskSchedulerImpl: Adding task set 35.0 with 6 tasks
18/01/24 17:41:47 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:41:47 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 51, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:41:47 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 52, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:41:47 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 53, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:41:47 INFO Executor: Running task 0.0 in stage 35.0 (TID 50)
18/01/24 17:41:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:41:47 INFO Executor: Running task 1.0 in stage 35.0 (TID 51)
18/01/24 17:41:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:41:47 INFO Executor: Running task 2.0 in stage 35.0 (TID 52)
18/01/24 17:41:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:41:47 INFO Executor: Running task 3.0 in stage 35.0 (TID 53)
18/01/24 17:41:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:41:47 INFO Executor: Finished task 0.0 in stage 35.0 (TID 50). 1943 bytes result sent to driver
18/01/24 17:41:47 INFO TaskSetManager: Starting task 4.0 in stage 35.0 (TID 54, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:41:47 INFO Executor: Running task 4.0 in stage 35.0 (TID 54)
18/01/24 17:41:47 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 50) in 564 ms on localhost (executor driver) (1/6)
18/01/24 17:41:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:41:53 INFO Executor: Finished task 1.0 in stage 35.0 (TID 51). 1674 bytes result sent to driver
18/01/24 17:41:53 INFO TaskSetManager: Starting task 5.0 in stage 35.0 (TID 55, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:41:53 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 51) in 6436 ms on localhost (executor driver) (2/6)
18/01/24 17:41:53 INFO Executor: Running task 5.0 in stage 35.0 (TID 55)
18/01/24 17:41:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:41:53 INFO Executor: Finished task 3.0 in stage 35.0 (TID 53). 1674 bytes result sent to driver
18/01/24 17:41:53 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 53) in 6468 ms on localhost (executor driver) (3/6)
18/01/24 17:41:53 INFO Executor: Finished task 4.0 in stage 35.0 (TID 54). 1674 bytes result sent to driver
18/01/24 17:41:53 INFO TaskSetManager: Finished task 4.0 in stage 35.0 (TID 54) in 5933 ms on localhost (executor driver) (4/6)
18/01/24 17:41:53 INFO Executor: Finished task 2.0 in stage 35.0 (TID 52). 1674 bytes result sent to driver
18/01/24 17:41:53 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 52) in 6523 ms on localhost (executor driver) (5/6)
18/01/24 17:41:53 INFO Executor: Finished task 5.0 in stage 35.0 (TID 55). 1674 bytes result sent to driver
18/01/24 17:41:53 INFO TaskSetManager: Finished task 5.0 in stage 35.0 (TID 55) in 415 ms on localhost (executor driver) (6/6)
18/01/24 17:41:53 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
18/01/24 17:41:53 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:211) finished in 6.853 s
18/01/24 17:41:53 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:41:53 INFO DAGScheduler: running: Set()
18/01/24 17:41:53 INFO DAGScheduler: waiting: Set(ResultStage 36)
18/01/24 17:41:53 INFO DAGScheduler: failed: Set()
18/01/24 17:41:53 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[105] at collect at utils.scala:211), which has no missing parents
18/01/24 17:41:53 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 12.3 KB, free 363.6 MB)
18/01/24 17:41:53 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 6.1 KB, free 363.6 MB)
18/01/24 17:41:53 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:35342 (size: 6.1 KB, free: 366.0 MB)
18/01/24 17:41:53 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
18/01/24 17:41:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[105] at collect at utils.scala:211)
18/01/24 17:41:53 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
18/01/24 17:41:53 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 56, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:41:53 INFO Executor: Running task 0.0 in stage 36.0 (TID 56)
18/01/24 17:41:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:41:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:41:53 INFO Executor: Finished task 0.0 in stage 36.0 (TID 56). 7744 bytes result sent to driver
18/01/24 17:41:53 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 56) in 7 ms on localhost (executor driver) (1/1)
18/01/24 17:41:53 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
18/01/24 17:41:53 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:211) finished in 0.009 s
18/01/24 17:41:53 INFO DAGScheduler: Job 33 finished: collect at utils.scala:211, took 6.870478 s
18/01/24 17:41:53 INFO CodeGenerator: Code generated in 7.480703 ms
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610419b2b000
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610419b2b000` AS `zzz22`
WHERE (0 = 1)
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610419b2b000`
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610419b2b000`
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610419b2b000`
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610419b2b000`
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610419b2b000`
18/01/24 17:42:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:42:34 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610419b2b000`
LIMIT 1000
18/01/24 17:42:34 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:42:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:42:34 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:42:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:42:34 INFO CodeGenerator: Code generated in 11.820171 ms
18/01/24 17:42:34 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 282.1 KB, free 363.3 MB)
18/01/24 17:42:34 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 23.9 KB, free 363.3 MB)
18/01/24 17:42:34 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.0 MB)
18/01/24 17:42:34 INFO SparkContext: Created broadcast 66 from collect at utils.scala:211
18/01/24 17:42:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:42:34 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:42:34 INFO DAGScheduler: Registering RDD 109 (collect at utils.scala:211)
18/01/24 17:42:34 INFO DAGScheduler: Got job 34 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:42:34 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:211)
18/01/24 17:42:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
18/01/24 17:42:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
18/01/24 17:42:34 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[109] at collect at utils.scala:211), which has no missing parents
18/01/24 17:42:34 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 34.5 KB, free 363.3 MB)
18/01/24 17:42:34 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 15.0 KB, free 363.3 MB)
18/01/24 17:42:34 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:35342 (size: 15.0 KB, free: 366.0 MB)
18/01/24 17:42:34 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
18/01/24 17:42:34 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[109] at collect at utils.scala:211)
18/01/24 17:42:34 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks
18/01/24 17:42:34 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:42:34 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:42:34 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 59, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:42:34 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 60, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:42:34 INFO Executor: Running task 0.0 in stage 37.0 (TID 57)
18/01/24 17:42:34 INFO Executor: Running task 1.0 in stage 37.0 (TID 58)
18/01/24 17:42:34 INFO Executor: Running task 2.0 in stage 37.0 (TID 59)
18/01/24 17:42:34 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:42:34 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:42:34 INFO Executor: Running task 3.0 in stage 37.0 (TID 60)
18/01/24 17:42:34 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:42:34 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:42:34 INFO Executor: Finished task 0.0 in stage 37.0 (TID 57). 1943 bytes result sent to driver
18/01/24 17:42:34 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 61, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:42:34 INFO Executor: Running task 4.0 in stage 37.0 (TID 61)
18/01/24 17:42:34 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 57) in 320 ms on localhost (executor driver) (1/6)
18/01/24 17:42:34 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:42:39 INFO Executor: Finished task 1.0 in stage 37.0 (TID 58). 1674 bytes result sent to driver
18/01/24 17:42:39 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 62, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:42:39 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 58) in 5570 ms on localhost (executor driver) (2/6)
18/01/24 17:42:39 INFO Executor: Running task 5.0 in stage 37.0 (TID 62)
18/01/24 17:42:39 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:42:40 INFO Executor: Finished task 3.0 in stage 37.0 (TID 60). 1674 bytes result sent to driver
18/01/24 17:42:40 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 60) in 5747 ms on localhost (executor driver) (3/6)
18/01/24 17:42:40 INFO Executor: Finished task 4.0 in stage 37.0 (TID 61). 1674 bytes result sent to driver
18/01/24 17:42:40 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 61) in 5532 ms on localhost (executor driver) (4/6)
18/01/24 17:42:40 INFO Executor: Finished task 2.0 in stage 37.0 (TID 59). 1674 bytes result sent to driver
18/01/24 17:42:40 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 59) in 5878 ms on localhost (executor driver) (5/6)
18/01/24 17:42:40 INFO Executor: Finished task 5.0 in stage 37.0 (TID 62). 1674 bytes result sent to driver
18/01/24 17:42:40 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 62) in 502 ms on localhost (executor driver) (6/6)
18/01/24 17:42:40 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
18/01/24 17:42:40 INFO DAGScheduler: ShuffleMapStage 37 (collect at utils.scala:211) finished in 6.071 s
18/01/24 17:42:40 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:42:40 INFO DAGScheduler: running: Set()
18/01/24 17:42:40 INFO DAGScheduler: waiting: Set(ResultStage 38)
18/01/24 17:42:40 INFO DAGScheduler: failed: Set()
18/01/24 17:42:40 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[112] at collect at utils.scala:211), which has no missing parents
18/01/24 17:42:40 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.2 KB, free 363.3 MB)
18/01/24 17:42:40 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 6.1 KB, free 363.2 MB)
18/01/24 17:42:40 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:35342 (size: 6.1 KB, free: 366.0 MB)
18/01/24 17:42:40 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
18/01/24 17:42:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[112] at collect at utils.scala:211)
18/01/24 17:42:40 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
18/01/24 17:42:40 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 63, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:42:40 INFO Executor: Running task 0.0 in stage 38.0 (TID 63)
18/01/24 17:42:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:42:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:42:40 INFO Executor: Finished task 0.0 in stage 38.0 (TID 63). 6443 bytes result sent to driver
18/01/24 17:42:40 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 63) in 7 ms on localhost (executor driver) (1/1)
18/01/24 17:42:40 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
18/01/24 17:42:40 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:211) finished in 0.007 s
18/01/24 17:42:40 INFO DAGScheduler: Job 34 finished: collect at utils.scala:211, took 6.087807 s
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610478c196b4
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610478c196b4` AS `zzz23`
WHERE (0 = 1)
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610478c196b4`
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610478c196b4`
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610478c196b4`
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610478c196b4`
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610478c196b4`
18/01/24 17:43:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:43:53 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610478c196b4`
LIMIT 1000
18/01/24 17:43:53 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:43:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:43:53 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:43:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:43:53 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 282.1 KB, free 363.0 MB)
18/01/24 17:43:53 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.9 KB, free 362.9 MB)
18/01/24 17:43:53 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.9 MB)
18/01/24 17:43:53 INFO SparkContext: Created broadcast 69 from collect at utils.scala:211
18/01/24 17:43:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:43:53 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:43:53 INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:211)
18/01/24 17:43:53 INFO DAGScheduler: Got job 35 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:43:53 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:211)
18/01/24 17:43:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
18/01/24 17:43:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
18/01/24 17:43:53 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[116] at collect at utils.scala:211), which has no missing parents
18/01/24 17:43:53 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 34.5 KB, free 362.9 MB)
18/01/24 17:43:53 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 14.9 KB, free 362.9 MB)
18/01/24 17:43:53 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:43:53 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
18/01/24 17:43:53 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[116] at collect at utils.scala:211)
18/01/24 17:43:53 INFO TaskSchedulerImpl: Adding task set 39.0 with 6 tasks
18/01/24 17:43:53 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:43:53 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:43:53 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:43:53 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:43:53 INFO Executor: Running task 0.0 in stage 39.0 (TID 64)
18/01/24 17:43:53 INFO Executor: Running task 1.0 in stage 39.0 (TID 65)
18/01/24 17:43:53 INFO Executor: Running task 2.0 in stage 39.0 (TID 66)
18/01/24 17:43:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:43:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:43:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:43:53 INFO Executor: Running task 3.0 in stage 39.0 (TID 67)
18/01/24 17:43:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:43:53 INFO Executor: Finished task 0.0 in stage 39.0 (TID 64). 1943 bytes result sent to driver
18/01/24 17:43:53 INFO TaskSetManager: Starting task 4.0 in stage 39.0 (TID 68, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:43:53 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 64) in 301 ms on localhost (executor driver) (1/6)
18/01/24 17:43:53 INFO Executor: Running task 4.0 in stage 39.0 (TID 68)
18/01/24 17:43:53 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:43:59 INFO Executor: Finished task 1.0 in stage 39.0 (TID 65). 1674 bytes result sent to driver
18/01/24 17:43:59 INFO TaskSetManager: Starting task 5.0 in stage 39.0 (TID 69, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:43:59 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 65) in 5794 ms on localhost (executor driver) (2/6)
18/01/24 17:43:59 INFO Executor: Running task 5.0 in stage 39.0 (TID 69)
18/01/24 17:43:59 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:43:59 INFO Executor: Finished task 2.0 in stage 39.0 (TID 66). 1674 bytes result sent to driver
18/01/24 17:43:59 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 66) in 6030 ms on localhost (executor driver) (3/6)
18/01/24 17:43:59 INFO Executor: Finished task 3.0 in stage 39.0 (TID 67). 1674 bytes result sent to driver
18/01/24 17:43:59 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 67) in 6278 ms on localhost (executor driver) (4/6)
18/01/24 17:43:59 INFO Executor: Finished task 4.0 in stage 39.0 (TID 68). 1674 bytes result sent to driver
18/01/24 17:43:59 INFO TaskSetManager: Finished task 4.0 in stage 39.0 (TID 68) in 6090 ms on localhost (executor driver) (5/6)
18/01/24 17:43:59 INFO Executor: Finished task 5.0 in stage 39.0 (TID 69). 1674 bytes result sent to driver
18/01/24 17:43:59 INFO TaskSetManager: Finished task 5.0 in stage 39.0 (TID 69) in 644 ms on localhost (executor driver) (6/6)
18/01/24 17:43:59 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
18/01/24 17:43:59 INFO DAGScheduler: ShuffleMapStage 39 (collect at utils.scala:211) finished in 6.438 s
18/01/24 17:43:59 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:43:59 INFO DAGScheduler: running: Set()
18/01/24 17:43:59 INFO DAGScheduler: waiting: Set(ResultStage 40)
18/01/24 17:43:59 INFO DAGScheduler: failed: Set()
18/01/24 17:43:59 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[119] at collect at utils.scala:211), which has no missing parents
18/01/24 17:43:59 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 12.2 KB, free 362.9 MB)
18/01/24 17:43:59 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 6.1 KB, free 362.9 MB)
18/01/24 17:43:59 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:35342 (size: 6.1 KB, free: 365.9 MB)
18/01/24 17:43:59 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
18/01/24 17:43:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[119] at collect at utils.scala:211)
18/01/24 17:43:59 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
18/01/24 17:43:59 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 70, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:43:59 INFO Executor: Running task 0.0 in stage 40.0 (TID 70)
18/01/24 17:43:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:43:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:43:59 INFO Executor: Finished task 0.0 in stage 40.0 (TID 70). 6443 bytes result sent to driver
18/01/24 17:43:59 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 70) in 4 ms on localhost (executor driver) (1/1)
18/01/24 17:43:59 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
18/01/24 17:43:59 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:211) finished in 0.006 s
18/01/24 17:43:59 INFO DAGScheduler: Job 35 finished: collect at utils.scala:211, took 6.453195 s
18/01/24 17:44:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:44:51 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610448c65fa3
18/01/24 17:44:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610448c65fa3` AS `zzz24`
WHERE (0 = 1)
18/01/24 17:44:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:51 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610448c65fa3`) `bhgxtusntk`) `womlfgkozl`
GROUP BY `hour`, `prediction`
18/01/24 17:44:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:52 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610448c65fa3`) `pwlvekukkx`) `yncceywvuk`
GROUP BY `hour`, `prediction`
18/01/24 17:44:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:52 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610448c65fa3`) `aicvmwkmhj`) `rxvdxegvik`
GROUP BY `hour`, `prediction`
18/01/24 17:44:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610448c65fa3`) `tvvnvxiamp`) `qnkbrpuhsq`
GROUP BY `hour`, `prediction`
18/01/24 17:44:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610448c65fa3`) `fvutqurbjf`) `mgrwnsippj`
GROUP BY `hour`, `prediction`
18/01/24 17:44:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:44:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610448c65fa3`) `odjhpyphvf`) `durbkskwhw`
GROUP BY `hour`, `prediction`
LIMIT 1000
18/01/24 17:44:55 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:44:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:44:55 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:44:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:44:55 INFO CodeGenerator: Code generated in 43.601725 ms
18/01/24 17:44:55 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 282.1 KB, free 362.6 MB)
18/01/24 17:44:55 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 23.9 KB, free 362.6 MB)
18/01/24 17:44:55 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.9 MB)
18/01/24 17:44:55 INFO SparkContext: Created broadcast 72 from collect at utils.scala:211
18/01/24 17:44:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:44:55 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:44:55 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:211)
18/01/24 17:44:55 INFO DAGScheduler: Got job 36 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:44:55 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:211)
18/01/24 17:44:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
18/01/24 17:44:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
18/01/24 17:44:55 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[123] at collect at utils.scala:211), which has no missing parents
18/01/24 17:44:55 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 34.5 KB, free 362.5 MB)
18/01/24 17:44:55 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 14.9 KB, free 362.5 MB)
18/01/24 17:44:55 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:44:55 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
18/01/24 17:44:55 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[123] at collect at utils.scala:211)
18/01/24 17:44:55 INFO TaskSchedulerImpl: Adding task set 41.0 with 6 tasks
18/01/24 17:44:55 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:44:55 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 72, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:44:55 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 73, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:44:55 INFO TaskSetManager: Starting task 3.0 in stage 41.0 (TID 74, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:44:55 INFO Executor: Running task 0.0 in stage 41.0 (TID 71)
18/01/24 17:44:55 INFO Executor: Running task 1.0 in stage 41.0 (TID 72)
18/01/24 17:44:55 INFO Executor: Running task 2.0 in stage 41.0 (TID 73)
18/01/24 17:44:55 INFO Executor: Running task 3.0 in stage 41.0 (TID 74)
18/01/24 17:44:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:44:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:44:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:44:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:44:55 INFO Executor: Finished task 0.0 in stage 41.0 (TID 71). 1943 bytes result sent to driver
18/01/24 17:44:55 INFO TaskSetManager: Starting task 4.0 in stage 41.0 (TID 75, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:44:55 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 71) in 511 ms on localhost (executor driver) (1/6)
18/01/24 17:44:55 INFO Executor: Running task 4.0 in stage 41.0 (TID 75)
18/01/24 17:44:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:45:01 INFO Executor: Finished task 2.0 in stage 41.0 (TID 73). 1674 bytes result sent to driver
18/01/24 17:45:01 INFO TaskSetManager: Starting task 5.0 in stage 41.0 (TID 76, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:45:01 INFO Executor: Running task 5.0 in stage 41.0 (TID 76)
18/01/24 17:45:01 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 73) in 5930 ms on localhost (executor driver) (2/6)
18/01/24 17:45:01 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:45:01 INFO Executor: Finished task 3.0 in stage 41.0 (TID 74). 1674 bytes result sent to driver
18/01/24 17:45:01 INFO TaskSetManager: Finished task 3.0 in stage 41.0 (TID 74) in 5982 ms on localhost (executor driver) (3/6)
18/01/24 17:45:01 INFO Executor: Finished task 1.0 in stage 41.0 (TID 72). 1674 bytes result sent to driver
18/01/24 17:45:01 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 72) in 6016 ms on localhost (executor driver) (4/6)
18/01/24 17:45:01 INFO Executor: Finished task 4.0 in stage 41.0 (TID 75). 1674 bytes result sent to driver
18/01/24 17:45:01 INFO TaskSetManager: Finished task 4.0 in stage 41.0 (TID 75) in 5601 ms on localhost (executor driver) (5/6)
18/01/24 17:45:01 INFO Executor: Finished task 5.0 in stage 41.0 (TID 76). 1674 bytes result sent to driver
18/01/24 17:45:01 INFO TaskSetManager: Finished task 5.0 in stage 41.0 (TID 76) in 420 ms on localhost (executor driver) (6/6)
18/01/24 17:45:01 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
18/01/24 17:45:01 INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:211) finished in 6.336 s
18/01/24 17:45:01 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:45:01 INFO DAGScheduler: running: Set()
18/01/24 17:45:01 INFO DAGScheduler: waiting: Set(ResultStage 42)
18/01/24 17:45:01 INFO DAGScheduler: failed: Set()
18/01/24 17:45:01 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[126] at collect at utils.scala:211), which has no missing parents
18/01/24 17:45:01 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 54.3 KB, free 362.5 MB)
18/01/24 17:45:01 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 23.3 KB, free 362.5 MB)
18/01/24 17:45:01 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:35342 (size: 23.3 KB, free: 365.9 MB)
18/01/24 17:45:01 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:996
18/01/24 17:45:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[126] at collect at utils.scala:211)
18/01/24 17:45:01 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
18/01/24 17:45:01 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 77, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:45:01 INFO Executor: Running task 0.0 in stage 42.0 (TID 77)
18/01/24 17:45:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:45:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:45:01 INFO CodeGenerator: Code generated in 5.349026 ms
18/01/24 17:45:01 INFO CodeGenerator: Code generated in 4.001923 ms
18/01/24 17:45:01 INFO CodeGenerator: Code generated in 4.569962 ms
18/01/24 17:45:01 INFO CodeGenerator: Code generated in 4.110428 ms
18/01/24 17:45:01 INFO Executor: Finished task 0.0 in stage 42.0 (TID 77). 3313 bytes result sent to driver
18/01/24 17:45:01 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 77) in 67 ms on localhost (executor driver) (1/1)
18/01/24 17:45:01 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
18/01/24 17:45:01 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:211) finished in 0.067 s
18/01/24 17:45:01 INFO DAGScheduler: Job 36 finished: collect at utils.scala:211, took 6.429844 s
18/01/24 17:45:01 INFO CodeGenerator: Code generated in 6.117284 ms
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61042078398b
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61042078398b` AS `zzz25`
WHERE (0 = 1)
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61042078398b`) `wefjeyrgys`) `ybnxjzebvv`
GROUP BY `hour`, `prediction`
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61042078398b`) `kvhmstfxnn`) `keodvmqmah`
GROUP BY `hour`, `prediction`
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61042078398b`) `rqmfmyeuxk`) `sjdpdggvjj`
GROUP BY `hour`, `prediction`
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61042078398b`) `lgqugbtzgp`) `bfzzfqgmsc`
GROUP BY `hour`, `prediction`
18/01/24 17:52:12 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:35342 in memory (size: 23.3 KB, free: 365.9 MB)
18/01/24 17:52:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:12 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61042078398b`) `qhlmjeykgv`) `vbjvdaheqn`
GROUP BY `hour`, `prediction`
18/01/24 17:52:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:52:14 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61042078398b`) `hfmjeloetb`) `umjvkirvgf`
GROUP BY `hour`, `prediction`
LIMIT 1000
18/01/24 17:52:14 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:52:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:52:14 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:52:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:52:14 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 282.1 KB, free 362.3 MB)
18/01/24 17:52:14 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 23.9 KB, free 362.2 MB)
18/01/24 17:52:14 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.9 MB)
18/01/24 17:52:14 INFO SparkContext: Created broadcast 75 from collect at utils.scala:211
18/01/24 17:52:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:52:14 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:52:14 INFO DAGScheduler: Registering RDD 130 (collect at utils.scala:211)
18/01/24 17:52:14 INFO DAGScheduler: Got job 37 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:52:14 INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:211)
18/01/24 17:52:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
18/01/24 17:52:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
18/01/24 17:52:14 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[130] at collect at utils.scala:211), which has no missing parents
18/01/24 17:52:14 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 34.5 KB, free 362.2 MB)
18/01/24 17:52:14 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 14.9 KB, free 362.2 MB)
18/01/24 17:52:14 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:52:14 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:996
18/01/24 17:52:14 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[130] at collect at utils.scala:211)
18/01/24 17:52:14 INFO TaskSchedulerImpl: Adding task set 43.0 with 6 tasks
18/01/24 17:52:14 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:52:14 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 79, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:52:14 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 80, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:52:14 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 81, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:52:14 INFO Executor: Running task 0.0 in stage 43.0 (TID 78)
18/01/24 17:52:14 INFO Executor: Running task 1.0 in stage 43.0 (TID 79)
18/01/24 17:52:14 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:52:14 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:52:14 INFO Executor: Running task 2.0 in stage 43.0 (TID 80)
18/01/24 17:52:14 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:52:14 INFO Executor: Running task 3.0 in stage 43.0 (TID 81)
18/01/24 17:52:14 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:52:15 INFO Executor: Finished task 0.0 in stage 43.0 (TID 78). 1943 bytes result sent to driver
18/01/24 17:52:15 INFO TaskSetManager: Starting task 4.0 in stage 43.0 (TID 82, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:52:15 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 78) in 352 ms on localhost (executor driver) (1/6)
18/01/24 17:52:15 INFO Executor: Running task 4.0 in stage 43.0 (TID 82)
18/01/24 17:52:15 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:52:20 INFO Executor: Finished task 3.0 in stage 43.0 (TID 81). 1674 bytes result sent to driver
18/01/24 17:52:20 INFO TaskSetManager: Starting task 5.0 in stage 43.0 (TID 83, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:52:20 INFO Executor: Running task 5.0 in stage 43.0 (TID 83)
18/01/24 17:52:20 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 81) in 5377 ms on localhost (executor driver) (2/6)
18/01/24 17:52:20 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:52:20 INFO Executor: Finished task 1.0 in stage 43.0 (TID 79). 1674 bytes result sent to driver
18/01/24 17:52:20 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 79) in 5580 ms on localhost (executor driver) (3/6)
18/01/24 17:52:20 INFO Executor: Finished task 2.0 in stage 43.0 (TID 80). 1674 bytes result sent to driver
18/01/24 17:52:20 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 80) in 5766 ms on localhost (executor driver) (4/6)
18/01/24 17:52:20 INFO Executor: Finished task 5.0 in stage 43.0 (TID 83). 1674 bytes result sent to driver
18/01/24 17:52:20 INFO TaskSetManager: Finished task 5.0 in stage 43.0 (TID 83) in 572 ms on localhost (executor driver) (5/6)
18/01/24 17:52:20 INFO Executor: Finished task 4.0 in stage 43.0 (TID 82). 1674 bytes result sent to driver
18/01/24 17:52:20 INFO TaskSetManager: Finished task 4.0 in stage 43.0 (TID 82) in 5690 ms on localhost (executor driver) (6/6)
18/01/24 17:52:20 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
18/01/24 17:52:20 INFO DAGScheduler: ShuffleMapStage 43 (collect at utils.scala:211) finished in 6.040 s
18/01/24 17:52:20 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:52:20 INFO DAGScheduler: running: Set()
18/01/24 17:52:20 INFO DAGScheduler: waiting: Set(ResultStage 44)
18/01/24 17:52:20 INFO DAGScheduler: failed: Set()
18/01/24 17:52:20 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[133] at collect at utils.scala:211), which has no missing parents
18/01/24 17:52:20 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 54.3 KB, free 362.1 MB)
18/01/24 17:52:20 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 23.3 KB, free 362.1 MB)
18/01/24 17:52:20 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:35342 (size: 23.3 KB, free: 365.8 MB)
18/01/24 17:52:20 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
18/01/24 17:52:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[133] at collect at utils.scala:211)
18/01/24 17:52:20 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
18/01/24 17:52:20 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 84, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:52:20 INFO Executor: Running task 0.0 in stage 44.0 (TID 84)
18/01/24 17:52:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:52:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:52:20 INFO Executor: Finished task 0.0 in stage 44.0 (TID 84). 3313 bytes result sent to driver
18/01/24 17:52:20 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 84) in 15 ms on localhost (executor driver) (1/1)
18/01/24 17:52:20 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
18/01/24 17:52:20 INFO DAGScheduler: ResultStage 44 (collect at utils.scala:211) finished in 0.016 s
18/01/24 17:52:20 INFO DAGScheduler: Job 37 finished: collect at utils.scala:211, took 6.066066 s
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.8 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:35342 in memory (size: 23.3 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 2984
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 2753
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:35342 in memory (size: 6.1 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 2530
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:35342 in memory (size: 6.1 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:35342 in memory (size: 15.0 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 2307
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:35342 in memory (size: 6.1 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 2084
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:35342 in memory (size: 4.2 KB, free: 365.9 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 366.0 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 1861
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:35342 in memory (size: 4.1 KB, free: 366.0 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 366.0 MB)
18/01/24 17:52:37 INFO ContextCleaner: Cleaned accumulator 1638
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:35342 in memory (size: 14.3 KB, free: 366.0 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:35342 in memory (size: 26.3 KB, free: 366.0 MB)
18/01/24 17:52:37 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 366.0 MB)
18/01/24 17:53:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:53:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:53:38 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61045bd43f94
18/01/24 17:53:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:53:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61045bd43f94` AS `zzz26`
WHERE (0 = 1)
18/01/24 17:53:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:53:38 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`, count(*) AS `n`
FROM (SELECT `hour`, CASE WHEN (`prediction` = 1.0) THEN ("Late") WHEN NOT(`prediction` = 1.0) THEN ("Not Late") END AS `prediction`
FROM (SELECT `hour`, `prediction`
FROM `sparklyr_tmp_61045bd43f94`) `xtpnlizmqi`) `uwfokvtmmh`
GROUP BY `hour`, `prediction`
18/01/24 17:53:38 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:53:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:53:38 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:53:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:53:38 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 282.1 KB, free 362.7 MB)
18/01/24 17:53:38 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 23.9 KB, free 362.7 MB)
18/01/24 17:53:38 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.0 MB)
18/01/24 17:53:38 INFO SparkContext: Created broadcast 78 from collect at utils.scala:211
18/01/24 17:53:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:53:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:53:38 INFO DAGScheduler: Registering RDD 137 (collect at utils.scala:211)
18/01/24 17:53:38 INFO DAGScheduler: Got job 38 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:53:38 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:211)
18/01/24 17:53:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
18/01/24 17:53:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)
18/01/24 17:53:38 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[137] at collect at utils.scala:211), which has no missing parents
18/01/24 17:53:38 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 34.5 KB, free 362.7 MB)
18/01/24 17:53:38 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 15.0 KB, free 362.7 MB)
18/01/24 17:53:38 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:35342 (size: 15.0 KB, free: 366.0 MB)
18/01/24 17:53:38 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
18/01/24 17:53:38 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[137] at collect at utils.scala:211)
18/01/24 17:53:38 INFO TaskSchedulerImpl: Adding task set 45.0 with 6 tasks
18/01/24 17:53:38 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/01/24 17:53:38 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/01/24 17:53:38 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 87, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/01/24 17:53:38 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 88, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/01/24 17:53:38 INFO Executor: Running task 0.0 in stage 45.0 (TID 85)
18/01/24 17:53:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:53:38 INFO Executor: Running task 1.0 in stage 45.0 (TID 86)
18/01/24 17:53:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:53:38 INFO Executor: Running task 2.0 in stage 45.0 (TID 87)
18/01/24 17:53:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:53:38 INFO Executor: Running task 3.0 in stage 45.0 (TID 88)
18/01/24 17:53:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:53:39 INFO Executor: Finished task 0.0 in stage 45.0 (TID 85). 1943 bytes result sent to driver
18/01/24 17:53:39 INFO TaskSetManager: Starting task 4.0 in stage 45.0 (TID 89, localhost, executor driver, partition 4, PROCESS_LOCAL, 6575 bytes)
18/01/24 17:53:39 INFO Executor: Running task 4.0 in stage 45.0 (TID 89)
18/01/24 17:53:39 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 85) in 385 ms on localhost (executor driver) (1/6)
18/01/24 17:53:39 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:53:44 INFO Executor: Finished task 3.0 in stage 45.0 (TID 88). 1674 bytes result sent to driver
18/01/24 17:53:44 INFO TaskSetManager: Starting task 5.0 in stage 45.0 (TID 90, localhost, executor driver, partition 5, PROCESS_LOCAL, 6575 bytes)
18/01/24 17:53:44 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 88) in 5999 ms on localhost (executor driver) (2/6)
18/01/24 17:53:44 INFO Executor: Running task 5.0 in stage 45.0 (TID 90)
18/01/24 17:53:44 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:53:44 INFO Executor: Finished task 1.0 in stage 45.0 (TID 86). 1674 bytes result sent to driver
18/01/24 17:53:44 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 86) in 6128 ms on localhost (executor driver) (3/6)
18/01/24 17:53:45 INFO Executor: Finished task 2.0 in stage 45.0 (TID 87). 1674 bytes result sent to driver
18/01/24 17:53:45 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 87) in 6229 ms on localhost (executor driver) (4/6)
18/01/24 17:53:45 INFO Executor: Finished task 4.0 in stage 45.0 (TID 89). 1674 bytes result sent to driver
18/01/24 17:53:45 INFO TaskSetManager: Finished task 4.0 in stage 45.0 (TID 89) in 6022 ms on localhost (executor driver) (5/6)
18/01/24 17:53:45 INFO Executor: Finished task 5.0 in stage 45.0 (TID 90). 1674 bytes result sent to driver
18/01/24 17:53:45 INFO TaskSetManager: Finished task 5.0 in stage 45.0 (TID 90) in 483 ms on localhost (executor driver) (6/6)
18/01/24 17:53:45 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
18/01/24 17:53:45 INFO DAGScheduler: ShuffleMapStage 45 (collect at utils.scala:211) finished in 6.483 s
18/01/24 17:53:45 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:53:45 INFO DAGScheduler: running: Set()
18/01/24 17:53:45 INFO DAGScheduler: waiting: Set(ResultStage 46)
18/01/24 17:53:45 INFO DAGScheduler: failed: Set()
18/01/24 17:53:45 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[140] at collect at utils.scala:211), which has no missing parents
18/01/24 17:53:45 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 54.5 KB, free 362.6 MB)
18/01/24 17:53:45 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 23.3 KB, free 362.6 MB)
18/01/24 17:53:45 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:35342 (size: 23.3 KB, free: 366.0 MB)
18/01/24 17:53:45 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:996
18/01/24 17:53:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[140] at collect at utils.scala:211)
18/01/24 17:53:45 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
18/01/24 17:53:45 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 91, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/01/24 17:53:45 INFO Executor: Running task 0.0 in stage 46.0 (TID 91)
18/01/24 17:53:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:53:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:53:45 INFO Executor: Finished task 0.0 in stage 46.0 (TID 91). 3337 bytes result sent to driver
18/01/24 17:53:45 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 91) in 14 ms on localhost (executor driver) (1/1)
18/01/24 17:53:45 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
18/01/24 17:53:45 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:211) finished in 0.014 s
18/01/24 17:53:45 INFO DAGScheduler: Job 38 finished: collect at utils.scala:211, took 6.507282 s
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610461a008a
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610461a008a` AS `zzz27`
WHERE (0 = 1)
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610461a008a`
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610461a008a`
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610461a008a`
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610461a008a`
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610461a008a`
18/01/24 17:54:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:54:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, `prediction`
FROM `sparklyr_tmp_610461a008a`
LIMIT 1000
18/01/24 17:54:41 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:54:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:54:41 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:54:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:54:41 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 282.1 KB, free 362.3 MB)
18/01/24 17:54:41 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 23.9 KB, free 362.3 MB)
18/01/24 17:54:41 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 366.0 MB)
18/01/24 17:54:41 INFO SparkContext: Created broadcast 81 from collect at utils.scala:211
18/01/24 17:54:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:54:41 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:54:41 INFO DAGScheduler: Registering RDD 144 (collect at utils.scala:211)
18/01/24 17:54:41 INFO DAGScheduler: Got job 39 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:54:41 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:211)
18/01/24 17:54:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
18/01/24 17:54:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
18/01/24 17:54:41 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[144] at collect at utils.scala:211), which has no missing parents
18/01/24 17:54:41 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 34.5 KB, free 362.3 MB)
18/01/24 17:54:41 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 14.9 KB, free 362.2 MB)
18/01/24 17:54:41 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:54:41 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:996
18/01/24 17:54:41 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[144] at collect at utils.scala:211)
18/01/24 17:54:41 INFO TaskSchedulerImpl: Adding task set 47.0 with 6 tasks
18/01/24 17:54:41 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:54:41 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 93, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:54:41 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 94, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:54:41 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 95, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:54:41 INFO Executor: Running task 1.0 in stage 47.0 (TID 93)
18/01/24 17:54:41 INFO Executor: Running task 0.0 in stage 47.0 (TID 92)
18/01/24 17:54:41 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:54:41 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:54:41 INFO Executor: Running task 2.0 in stage 47.0 (TID 94)
18/01/24 17:54:41 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:54:41 INFO Executor: Running task 3.0 in stage 47.0 (TID 95)
18/01/24 17:54:41 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:54:42 INFO Executor: Finished task 0.0 in stage 47.0 (TID 92). 1943 bytes result sent to driver
18/01/24 17:54:42 INFO TaskSetManager: Starting task 4.0 in stage 47.0 (TID 96, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:54:42 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 92) in 471 ms on localhost (executor driver) (1/6)
18/01/24 17:54:42 INFO Executor: Running task 4.0 in stage 47.0 (TID 96)
18/01/24 17:54:42 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:54:47 INFO Executor: Finished task 3.0 in stage 47.0 (TID 95). 1674 bytes result sent to driver
18/01/24 17:54:47 INFO TaskSetManager: Starting task 5.0 in stage 47.0 (TID 97, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:54:47 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 95) in 5704 ms on localhost (executor driver) (2/6)
18/01/24 17:54:47 INFO Executor: Running task 5.0 in stage 47.0 (TID 97)
18/01/24 17:54:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:54:47 INFO Executor: Finished task 1.0 in stage 47.0 (TID 93). 1674 bytes result sent to driver
18/01/24 17:54:47 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 93) in 5838 ms on localhost (executor driver) (3/6)
18/01/24 17:54:47 INFO Executor: Finished task 2.0 in stage 47.0 (TID 94). 1674 bytes result sent to driver
18/01/24 17:54:47 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 94) in 5938 ms on localhost (executor driver) (4/6)
18/01/24 17:54:48 INFO Executor: Finished task 4.0 in stage 47.0 (TID 96). 1674 bytes result sent to driver
18/01/24 17:54:48 INFO TaskSetManager: Finished task 4.0 in stage 47.0 (TID 96) in 5796 ms on localhost (executor driver) (5/6)
18/01/24 17:54:48 INFO Executor: Finished task 5.0 in stage 47.0 (TID 97). 1761 bytes result sent to driver
18/01/24 17:54:48 INFO TaskSetManager: Finished task 5.0 in stage 47.0 (TID 97) in 580 ms on localhost (executor driver) (6/6)
18/01/24 17:54:48 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
18/01/24 17:54:48 INFO DAGScheduler: ShuffleMapStage 47 (collect at utils.scala:211) finished in 6.284 s
18/01/24 17:54:48 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:54:48 INFO DAGScheduler: running: Set()
18/01/24 17:54:48 INFO DAGScheduler: waiting: Set(ResultStage 48)
18/01/24 17:54:48 INFO DAGScheduler: failed: Set()
18/01/24 17:54:48 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[147] at collect at utils.scala:211), which has no missing parents
18/01/24 17:54:48 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 12.2 KB, free 362.2 MB)
18/01/24 17:54:48 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 6.1 KB, free 362.2 MB)
18/01/24 17:54:48 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:35342 (size: 6.1 KB, free: 365.9 MB)
18/01/24 17:54:48 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:996
18/01/24 17:54:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[147] at collect at utils.scala:211)
18/01/24 17:54:48 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
18/01/24 17:54:48 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 98, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:54:48 INFO Executor: Running task 0.0 in stage 48.0 (TID 98)
18/01/24 17:54:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:54:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 17:54:48 INFO Executor: Finished task 0.0 in stage 48.0 (TID 98). 6443 bytes result sent to driver
18/01/24 17:54:48 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 98) in 4 ms on localhost (executor driver) (1/1)
18/01/24 17:54:48 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
18/01/24 17:54:48 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:211) finished in 0.004 s
18/01/24 17:54:48 INFO DAGScheduler: Job 39 finished: collect at utils.scala:211, took 6.295109 s
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610461407611
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610461407611` AS `zzz28`
WHERE (0 = 1)
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_610461407611`
GROUP BY `hour`
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_610461407611`
GROUP BY `hour`
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_610461407611`
GROUP BY `hour`
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_610461407611`
GROUP BY `hour`
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_610461407611`
GROUP BY `hour`
18/01/24 17:57:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:04 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_610461407611`
GROUP BY `hour`
LIMIT 1000
18/01/24 17:57:04 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:57:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:57:04 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:57:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:57:04 INFO CodeGenerator: Code generated in 58.220223 ms
18/01/24 17:57:04 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 282.1 KB, free 362.0 MB)
18/01/24 17:57:04 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 23.9 KB, free 361.9 MB)
18/01/24 17:57:04 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.9 MB)
18/01/24 17:57:04 INFO SparkContext: Created broadcast 84 from collect at utils.scala:211
18/01/24 17:57:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:57:04 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:57:04 INFO DAGScheduler: Registering RDD 151 (collect at utils.scala:211)
18/01/24 17:57:04 INFO DAGScheduler: Got job 40 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:57:04 INFO DAGScheduler: Final stage: ResultStage 50 (collect at utils.scala:211)
18/01/24 17:57:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
18/01/24 17:57:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
18/01/24 17:57:04 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[151] at collect at utils.scala:211), which has no missing parents
18/01/24 17:57:04 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 34.5 KB, free 361.9 MB)
18/01/24 17:57:04 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 14.9 KB, free 361.9 MB)
18/01/24 17:57:04 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.9 MB)
18/01/24 17:57:04 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
18/01/24 17:57:04 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[151] at collect at utils.scala:211)
18/01/24 17:57:04 INFO TaskSchedulerImpl: Adding task set 49.0 with 6 tasks
18/01/24 17:57:04 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:04 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 100, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:04 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 101, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:04 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 102, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:04 INFO Executor: Running task 0.0 in stage 49.0 (TID 99)
18/01/24 17:57:04 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:57:04 INFO Executor: Running task 1.0 in stage 49.0 (TID 100)
18/01/24 17:57:04 INFO Executor: Running task 2.0 in stage 49.0 (TID 101)
18/01/24 17:57:04 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:57:04 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:57:04 INFO Executor: Running task 3.0 in stage 49.0 (TID 102)
18/01/24 17:57:04 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:57:05 INFO Executor: Finished task 0.0 in stage 49.0 (TID 99). 1943 bytes result sent to driver
18/01/24 17:57:05 INFO TaskSetManager: Starting task 4.0 in stage 49.0 (TID 103, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:05 INFO Executor: Running task 4.0 in stage 49.0 (TID 103)
18/01/24 17:57:05 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 99) in 545 ms on localhost (executor driver) (1/6)
18/01/24 17:57:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:57:10 INFO Executor: Finished task 2.0 in stage 49.0 (TID 101). 1674 bytes result sent to driver
18/01/24 17:57:10 INFO TaskSetManager: Starting task 5.0 in stage 49.0 (TID 104, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:10 INFO Executor: Running task 5.0 in stage 49.0 (TID 104)
18/01/24 17:57:10 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 101) in 6050 ms on localhost (executor driver) (2/6)
18/01/24 17:57:10 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:57:11 INFO Executor: Finished task 1.0 in stage 49.0 (TID 100). 1674 bytes result sent to driver
18/01/24 17:57:11 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 100) in 6294 ms on localhost (executor driver) (3/6)
18/01/24 17:57:11 INFO Executor: Finished task 3.0 in stage 49.0 (TID 102). 1674 bytes result sent to driver
18/01/24 17:57:11 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 102) in 6358 ms on localhost (executor driver) (4/6)
18/01/24 17:57:11 INFO Executor: Finished task 4.0 in stage 49.0 (TID 103). 1674 bytes result sent to driver
18/01/24 17:57:11 INFO TaskSetManager: Finished task 4.0 in stage 49.0 (TID 103) in 5931 ms on localhost (executor driver) (5/6)
18/01/24 17:57:11 INFO Executor: Finished task 5.0 in stage 49.0 (TID 104). 1674 bytes result sent to driver
18/01/24 17:57:11 INFO TaskSetManager: Finished task 5.0 in stage 49.0 (TID 104) in 590 ms on localhost (executor driver) (6/6)
18/01/24 17:57:11 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
18/01/24 17:57:11 INFO DAGScheduler: ShuffleMapStage 49 (collect at utils.scala:211) finished in 6.639 s
18/01/24 17:57:11 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:57:11 INFO DAGScheduler: running: Set()
18/01/24 17:57:11 INFO DAGScheduler: waiting: Set(ResultStage 50)
18/01/24 17:57:11 INFO DAGScheduler: failed: Set()
18/01/24 17:57:11 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[154] at collect at utils.scala:211), which has no missing parents
18/01/24 17:57:11 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 54.5 KB, free 361.8 MB)
18/01/24 17:57:11 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.8 MB)
18/01/24 17:57:11 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.9 MB)
18/01/24 17:57:11 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:996
18/01/24 17:57:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[154] at collect at utils.scala:211)
18/01/24 17:57:11 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
18/01/24 17:57:11 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 105, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:57:11 INFO Executor: Running task 0.0 in stage 50.0 (TID 105)
18/01/24 17:57:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:57:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/01/24 17:57:11 INFO CodeGenerator: Code generated in 4.188689 ms
18/01/24 17:57:11 INFO CodeGenerator: Code generated in 3.866323 ms
18/01/24 17:57:11 INFO CodeGenerator: Code generated in 4.692745 ms
18/01/24 17:57:11 INFO Executor: Finished task 0.0 in stage 50.0 (TID 105). 3104 bytes result sent to driver
18/01/24 17:57:11 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 105) in 30 ms on localhost (executor driver) (1/1)
18/01/24 17:57:11 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
18/01/24 17:57:11 INFO DAGScheduler: ResultStage 50 (collect at utils.scala:211) finished in 0.031 s
18/01/24 17:57:11 INFO DAGScheduler: Job 40 finished: collect at utils.scala:211, took 6.679521 s
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61041dbaed52
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61041dbaed52` AS `zzz29`
WHERE (0 = 1)
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_61041dbaed52`
GROUP BY `hour`
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_61041dbaed52`
GROUP BY `hour`
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_61041dbaed52`
GROUP BY `hour`
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_61041dbaed52`
GROUP BY `hour`
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_61041dbaed52`
GROUP BY `hour`
18/01/24 17:57:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:57:27 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `total`
FROM `sparklyr_tmp_61041dbaed52`
GROUP BY `hour`
LIMIT 1000
18/01/24 17:57:27 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 17:57:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 17:57:27 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 17:57:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 17:57:27 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 282.1 KB, free 361.5 MB)
18/01/24 17:57:27 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 23.9 KB, free 361.5 MB)
18/01/24 17:57:27 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.9 MB)
18/01/24 17:57:27 INFO SparkContext: Created broadcast 87 from collect at utils.scala:211
18/01/24 17:57:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 17:57:27 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 17:57:27 INFO DAGScheduler: Registering RDD 158 (collect at utils.scala:211)
18/01/24 17:57:27 INFO DAGScheduler: Got job 41 (collect at utils.scala:211) with 1 output partitions
18/01/24 17:57:27 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:211)
18/01/24 17:57:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
18/01/24 17:57:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
18/01/24 17:57:27 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[158] at collect at utils.scala:211), which has no missing parents
18/01/24 17:57:27 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 34.5 KB, free 361.5 MB)
18/01/24 17:57:27 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 14.9 KB, free 361.5 MB)
18/01/24 17:57:27 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.8 MB)
18/01/24 17:57:27 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
18/01/24 17:57:27 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[158] at collect at utils.scala:211)
18/01/24 17:57:27 INFO TaskSchedulerImpl: Adding task set 51.0 with 6 tasks
18/01/24 17:57:27 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:27 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 107, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:27 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 108, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:27 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 109, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:27 INFO Executor: Running task 0.0 in stage 51.0 (TID 106)
18/01/24 17:57:27 INFO Executor: Running task 2.0 in stage 51.0 (TID 108)
18/01/24 17:57:27 INFO Executor: Running task 1.0 in stage 51.0 (TID 107)
18/01/24 17:57:27 INFO Executor: Running task 3.0 in stage 51.0 (TID 109)
18/01/24 17:57:27 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 17:57:27 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 17:57:27 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 17:57:27 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 17:57:28 INFO Executor: Finished task 0.0 in stage 51.0 (TID 106). 1943 bytes result sent to driver
18/01/24 17:57:28 INFO TaskSetManager: Starting task 4.0 in stage 51.0 (TID 110, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:28 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 106) in 322 ms on localhost (executor driver) (1/6)
18/01/24 17:57:28 INFO Executor: Running task 4.0 in stage 51.0 (TID 110)
18/01/24 17:57:28 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 17:57:33 INFO Executor: Finished task 3.0 in stage 51.0 (TID 109). 1674 bytes result sent to driver
18/01/24 17:57:33 INFO TaskSetManager: Starting task 5.0 in stage 51.0 (TID 111, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 17:57:33 INFO Executor: Running task 5.0 in stage 51.0 (TID 111)
18/01/24 17:57:33 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 109) in 5708 ms on localhost (executor driver) (2/6)
18/01/24 17:57:33 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 17:57:33 INFO Executor: Finished task 2.0 in stage 51.0 (TID 108). 1674 bytes result sent to driver
18/01/24 17:57:33 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 108) in 5948 ms on localhost (executor driver) (3/6)
18/01/24 17:57:34 INFO Executor: Finished task 4.0 in stage 51.0 (TID 110). 1674 bytes result sent to driver
18/01/24 17:57:34 INFO TaskSetManager: Finished task 4.0 in stage 51.0 (TID 110) in 5693 ms on localhost (executor driver) (4/6)
18/01/24 17:57:34 INFO Executor: Finished task 1.0 in stage 51.0 (TID 107). 1674 bytes result sent to driver
18/01/24 17:57:34 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 107) in 6117 ms on localhost (executor driver) (5/6)
18/01/24 17:57:34 INFO Executor: Finished task 5.0 in stage 51.0 (TID 111). 1674 bytes result sent to driver
18/01/24 17:57:34 INFO TaskSetManager: Finished task 5.0 in stage 51.0 (TID 111) in 536 ms on localhost (executor driver) (6/6)
18/01/24 17:57:34 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
18/01/24 17:57:34 INFO DAGScheduler: ShuffleMapStage 51 (collect at utils.scala:211) finished in 6.244 s
18/01/24 17:57:34 INFO DAGScheduler: looking for newly runnable stages
18/01/24 17:57:34 INFO DAGScheduler: running: Set()
18/01/24 17:57:34 INFO DAGScheduler: waiting: Set(ResultStage 52)
18/01/24 17:57:34 INFO DAGScheduler: failed: Set()
18/01/24 17:57:34 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[161] at collect at utils.scala:211), which has no missing parents
18/01/24 17:57:34 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 54.5 KB, free 361.4 MB)
18/01/24 17:57:34 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.4 MB)
18/01/24 17:57:34 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.8 MB)
18/01/24 17:57:34 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
18/01/24 17:57:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[161] at collect at utils.scala:211)
18/01/24 17:57:34 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
18/01/24 17:57:34 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 112, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 17:57:34 INFO Executor: Running task 0.0 in stage 52.0 (TID 112)
18/01/24 17:57:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 17:57:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 17:57:34 INFO Executor: Finished task 0.0 in stage 52.0 (TID 112). 3104 bytes result sent to driver
18/01/24 17:57:34 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 112) in 6 ms on localhost (executor driver) (1/1)
18/01/24 17:57:34 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
18/01/24 17:57:34 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:211) finished in 0.007 s
18/01/24 17:57:34 INFO DAGScheduler: Job 41 finished: collect at utils.scala:211, took 6.258363 s
18/01/24 17:58:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:58:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:58:11 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61044dbae64f
18/01/24 17:58:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:58:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044dbae64f` AS `zzz30`
WHERE (0 = 1)
18/01/24 17:58:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:58:11 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `sum(prediction, na`.`rm = TRUE)`
FROM `sparklyr_tmp_61044dbae64f`
GROUP BY `hour`
18/01/24 17:58:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:58:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 17:58:41 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61045a034ac4
18/01/24 17:58:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:58:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61045a034ac4` AS `zzz31`
WHERE (0 = 1)
18/01/24 17:58:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 17:58:41 INFO SparkSqlParser: Parsing command: SELECT `hour`, SUM(`prediction`) AS `sum(prediction, na`.`rm = TRUE)`
FROM `sparklyr_tmp_61045a034ac4`
GROUP BY `hour`
18/01/24 18:00:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:00:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 18:00:40 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610431ca83
18/01/24 18:00:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:00:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610431ca83` AS `zzz32`
WHERE (0 = 1)
18/01/24 18:00:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:00:40 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n()`
FROM `sparklyr_tmp_610431ca83`
GROUP BY `hour`
18/01/24 18:00:40 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:00:40 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:00:40 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string ... 1 more fields>
18/01/24 18:00:40 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:00:40 INFO CodeGenerator: Code generated in 24.351557 ms
18/01/24 18:00:40 INFO CodeGenerator: Code generated in 8.510279 ms
18/01/24 18:00:40 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 282.1 KB, free 361.1 MB)
18/01/24 18:00:40 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 23.9 KB, free 361.1 MB)
18/01/24 18:00:40 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.8 MB)
18/01/24 18:00:40 INFO SparkContext: Created broadcast 90 from collect at utils.scala:211
18/01/24 18:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:00:40 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:00:40 INFO DAGScheduler: Registering RDD 167 (collect at utils.scala:211)
18/01/24 18:00:40 INFO DAGScheduler: Got job 42 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:00:40 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:211)
18/01/24 18:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
18/01/24 18:00:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
18/01/24 18:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[167] at collect at utils.scala:211), which has no missing parents
18/01/24 18:00:40 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 14.6 KB, free 361.1 MB)
18/01/24 18:00:40 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 7.1 KB, free 361.1 MB)
18/01/24 18:00:40 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:35342 (size: 7.1 KB, free: 365.8 MB)
18/01/24 18:00:40 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
18/01/24 18:00:40 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[167] at collect at utils.scala:211)
18/01/24 18:00:40 INFO TaskSchedulerImpl: Adding task set 53.0 with 6 tasks
18/01/24 18:00:40 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:00:40 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:00:40 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 115, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:00:40 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 116, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:00:40 INFO Executor: Running task 0.0 in stage 53.0 (TID 113)
18/01/24 18:00:40 INFO Executor: Running task 1.0 in stage 53.0 (TID 114)
18/01/24 18:00:40 INFO Executor: Running task 2.0 in stage 53.0 (TID 115)
18/01/24 18:00:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:00:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:00:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:00:40 INFO Executor: Running task 3.0 in stage 53.0 (TID 116)
18/01/24 18:00:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:00:40 INFO CodeGenerator: Code generated in 6.514144 ms
18/01/24 18:00:41 INFO Executor: Finished task 0.0 in stage 53.0 (TID 113). 1943 bytes result sent to driver
18/01/24 18:00:41 INFO TaskSetManager: Starting task 4.0 in stage 53.0 (TID 117, localhost, executor driver, partition 4, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:00:41 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 113) in 394 ms on localhost (executor driver) (1/6)
18/01/24 18:00:41 INFO Executor: Running task 4.0 in stage 53.0 (TID 117)
18/01/24 18:00:41 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:00:46 INFO Executor: Finished task 3.0 in stage 53.0 (TID 116). 1674 bytes result sent to driver
18/01/24 18:00:46 INFO TaskSetManager: Starting task 5.0 in stage 53.0 (TID 118, localhost, executor driver, partition 5, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:00:46 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 116) in 5399 ms on localhost (executor driver) (2/6)
18/01/24 18:00:46 INFO Executor: Running task 5.0 in stage 53.0 (TID 118)
18/01/24 18:00:46 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 18:00:46 INFO Executor: Finished task 2.0 in stage 53.0 (TID 115). 1674 bytes result sent to driver
18/01/24 18:00:46 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 115) in 5431 ms on localhost (executor driver) (3/6)
18/01/24 18:00:46 INFO Executor: Finished task 1.0 in stage 53.0 (TID 114). 1674 bytes result sent to driver
18/01/24 18:00:46 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 114) in 5566 ms on localhost (executor driver) (4/6)
18/01/24 18:00:46 INFO Executor: Finished task 4.0 in stage 53.0 (TID 117). 1674 bytes result sent to driver
18/01/24 18:00:46 INFO TaskSetManager: Finished task 4.0 in stage 53.0 (TID 117) in 5420 ms on localhost (executor driver) (5/6)
18/01/24 18:00:46 INFO Executor: Finished task 5.0 in stage 53.0 (TID 118). 1674 bytes result sent to driver
18/01/24 18:00:46 INFO TaskSetManager: Finished task 5.0 in stage 53.0 (TID 118) in 555 ms on localhost (executor driver) (6/6)
18/01/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
18/01/24 18:00:46 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:211) finished in 5.955 s
18/01/24 18:00:46 INFO DAGScheduler: looking for newly runnable stages
18/01/24 18:00:46 INFO DAGScheduler: running: Set()
18/01/24 18:00:46 INFO DAGScheduler: waiting: Set(ResultStage 54)
18/01/24 18:00:46 INFO DAGScheduler: failed: Set()
18/01/24 18:00:46 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[170] at collect at utils.scala:211), which has no missing parents
18/01/24 18:00:46 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 41.9 KB, free 361.0 MB)
18/01/24 18:00:46 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 18.3 KB, free 361.0 MB)
18/01/24 18:00:46 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:35342 (size: 18.3 KB, free: 365.8 MB)
18/01/24 18:00:46 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:996
18/01/24 18:00:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[170] at collect at utils.scala:211)
18/01/24 18:00:46 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
18/01/24 18:00:46 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 119, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/01/24 18:00:46 INFO Executor: Running task 0.0 in stage 54.0 (TID 119)
18/01/24 18:00:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 18:00:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 18:00:46 INFO Executor: Finished task 0.0 in stage 54.0 (TID 119). 3068 bytes result sent to driver
18/01/24 18:00:46 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 119) in 16 ms on localhost (executor driver) (1/1)
18/01/24 18:00:46 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
18/01/24 18:00:46 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:211) finished in 0.017 s
18/01/24 18:00:46 INFO DAGScheduler: Job 42 finished: collect at utils.scala:211, took 5.978583 s
18/01/24 18:00:46 INFO CodeGenerator: Code generated in 4.294463 ms
18/01/24 18:01:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:01:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 18:01:13 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6104121cc7cd
18/01/24 18:01:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:01:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104121cc7cd` AS `zzz33`
WHERE (0 = 1)
18/01/24 18:01:13 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:01:13 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n()`
FROM `sparklyr_tmp_6104121cc7cd`
WHERE (`prediction` = 0.0)
GROUP BY `hour`
18/01/24 18:01:13 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:01:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:01:13 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:01:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:01:13 INFO CodeGenerator: Code generated in 40.193157 ms
18/01/24 18:01:13 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 282.1 KB, free 360.7 MB)
18/01/24 18:01:13 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 23.9 KB, free 360.7 MB)
18/01/24 18:01:13 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.7 MB)
18/01/24 18:01:13 INFO SparkContext: Created broadcast 93 from collect at utils.scala:211
18/01/24 18:01:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:01:13 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:01:13 INFO DAGScheduler: Registering RDD 174 (collect at utils.scala:211)
18/01/24 18:01:13 INFO DAGScheduler: Got job 43 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:01:13 INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:211)
18/01/24 18:01:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
18/01/24 18:01:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 55)
18/01/24 18:01:13 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[174] at collect at utils.scala:211), which has no missing parents
18/01/24 18:01:13 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 34.5 KB, free 360.7 MB)
18/01/24 18:01:13 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 14.9 KB, free 360.7 MB)
18/01/24 18:01:13 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.7 MB)
18/01/24 18:01:13 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:996
18/01/24 18:01:13 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[174] at collect at utils.scala:211)
18/01/24 18:01:13 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks
18/01/24 18:01:13 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:13 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 121, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:13 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 122, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:13 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 123, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:13 INFO Executor: Running task 1.0 in stage 55.0 (TID 121)
18/01/24 18:01:13 INFO Executor: Running task 3.0 in stage 55.0 (TID 123)
18/01/24 18:01:13 INFO Executor: Running task 0.0 in stage 55.0 (TID 120)
18/01/24 18:01:13 INFO Executor: Running task 2.0 in stage 55.0 (TID 122)
18/01/24 18:01:13 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:01:13 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:01:13 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:01:13 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:01:13 INFO Executor: Finished task 0.0 in stage 55.0 (TID 120). 1943 bytes result sent to driver
18/01/24 18:01:13 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 124, localhost, executor driver, partition 4, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:13 INFO Executor: Running task 4.0 in stage 55.0 (TID 124)
18/01/24 18:01:13 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 120) in 303 ms on localhost (executor driver) (1/6)
18/01/24 18:01:13 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:01:18 INFO Executor: Finished task 3.0 in stage 55.0 (TID 123). 1674 bytes result sent to driver
18/01/24 18:01:18 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 125, localhost, executor driver, partition 5, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:18 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 123) in 5793 ms on localhost (executor driver) (2/6)
18/01/24 18:01:18 INFO Executor: Running task 5.0 in stage 55.0 (TID 125)
18/01/24 18:01:19 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 18:01:19 INFO Executor: Finished task 2.0 in stage 55.0 (TID 122). 1674 bytes result sent to driver
18/01/24 18:01:19 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 122) in 5972 ms on localhost (executor driver) (3/6)
18/01/24 18:01:19 INFO Executor: Finished task 4.0 in stage 55.0 (TID 124). 1761 bytes result sent to driver
18/01/24 18:01:19 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 124) in 5746 ms on localhost (executor driver) (4/6)
18/01/24 18:01:19 INFO Executor: Finished task 1.0 in stage 55.0 (TID 121). 1674 bytes result sent to driver
18/01/24 18:01:19 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 121) in 6146 ms on localhost (executor driver) (5/6)
18/01/24 18:01:19 INFO Executor: Finished task 5.0 in stage 55.0 (TID 125). 1674 bytes result sent to driver
18/01/24 18:01:19 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 125) in 530 ms on localhost (executor driver) (6/6)
18/01/24 18:01:19 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
18/01/24 18:01:19 INFO DAGScheduler: ShuffleMapStage 55 (collect at utils.scala:211) finished in 6.324 s
18/01/24 18:01:19 INFO DAGScheduler: looking for newly runnable stages
18/01/24 18:01:19 INFO DAGScheduler: running: Set()
18/01/24 18:01:19 INFO DAGScheduler: waiting: Set(ResultStage 56)
18/01/24 18:01:19 INFO DAGScheduler: failed: Set()
18/01/24 18:01:19 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[177] at collect at utils.scala:211), which has no missing parents
18/01/24 18:01:19 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 51.8 KB, free 360.6 MB)
18/01/24 18:01:19 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 22.3 KB, free 360.6 MB)
18/01/24 18:01:19 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:35342 (size: 22.3 KB, free: 365.7 MB)
18/01/24 18:01:19 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
18/01/24 18:01:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[177] at collect at utils.scala:211)
18/01/24 18:01:19 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
18/01/24 18:01:19 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 126, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/01/24 18:01:19 INFO Executor: Running task 0.0 in stage 56.0 (TID 126)
18/01/24 18:01:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 18:01:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 18:01:19 INFO Executor: Finished task 0.0 in stage 56.0 (TID 126). 3132 bytes result sent to driver
18/01/24 18:01:19 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 126) in 16 ms on localhost (executor driver) (1/1)
18/01/24 18:01:19 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
18/01/24 18:01:19 INFO DAGScheduler: ResultStage 56 (collect at utils.scala:211) finished in 0.015 s
18/01/24 18:01:19 INFO DAGScheduler: Job 43 finished: collect at utils.scala:211, took 6.351176 s
18/01/24 18:01:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:01:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 18:01:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610430e93760
18/01/24 18:01:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:01:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610430e93760` AS `zzz34`
WHERE (0 = 1)
18/01/24 18:01:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:01:36 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n()`
FROM `sparklyr_tmp_610430e93760`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:01:36 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:01:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:01:36 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:01:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:01:36 INFO CodeGenerator: Code generated in 20.581591 ms
18/01/24 18:01:36 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 282.1 KB, free 360.3 MB)
18/01/24 18:01:36 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 23.9 KB, free 360.3 MB)
18/01/24 18:01:36 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.7 MB)
18/01/24 18:01:36 INFO SparkContext: Created broadcast 96 from collect at utils.scala:211
18/01/24 18:01:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:01:36 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:01:36 INFO DAGScheduler: Registering RDD 181 (collect at utils.scala:211)
18/01/24 18:01:36 INFO DAGScheduler: Got job 44 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:01:36 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:211)
18/01/24 18:01:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
18/01/24 18:01:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)
18/01/24 18:01:36 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[181] at collect at utils.scala:211), which has no missing parents
18/01/24 18:01:36 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 34.5 KB, free 360.2 MB)
18/01/24 18:01:36 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 14.9 KB, free 360.2 MB)
18/01/24 18:01:36 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:35342 (size: 14.9 KB, free: 365.7 MB)
18/01/24 18:01:36 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
18/01/24 18:01:36 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[181] at collect at utils.scala:211)
18/01/24 18:01:36 INFO TaskSchedulerImpl: Adding task set 57.0 with 6 tasks
18/01/24 18:01:36 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:36 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 128, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:36 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 129, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:36 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 130, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:36 INFO Executor: Running task 1.0 in stage 57.0 (TID 128)
18/01/24 18:01:36 INFO Executor: Running task 0.0 in stage 57.0 (TID 127)
18/01/24 18:01:36 INFO Executor: Running task 3.0 in stage 57.0 (TID 130)
18/01/24 18:01:36 INFO Executor: Running task 2.0 in stage 57.0 (TID 129)
18/01/24 18:01:36 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:01:36 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:01:36 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:01:36 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:01:36 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:35342 in memory (size: 22.3 KB, free: 365.7 MB)
18/01/24 18:01:36 INFO ContextCleaner: Cleaned accumulator 4594
18/01/24 18:01:37 INFO Executor: Finished task 0.0 in stage 57.0 (TID 127). 1943 bytes result sent to driver
18/01/24 18:01:37 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 131, localhost, executor driver, partition 4, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:37 INFO Executor: Running task 4.0 in stage 57.0 (TID 131)
18/01/24 18:01:37 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 127) in 337 ms on localhost (executor driver) (1/6)
18/01/24 18:01:37 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:01:42 INFO Executor: Finished task 3.0 in stage 57.0 (TID 130). 1674 bytes result sent to driver
18/01/24 18:01:42 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 132, localhost, executor driver, partition 5, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:01:42 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 130) in 5634 ms on localhost (executor driver) (2/6)
18/01/24 18:01:42 INFO Executor: Running task 5.0 in stage 57.0 (TID 132)
18/01/24 18:01:42 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 18:01:42 INFO Executor: Finished task 2.0 in stage 57.0 (TID 129). 1674 bytes result sent to driver
18/01/24 18:01:42 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 129) in 6066 ms on localhost (executor driver) (3/6)
18/01/24 18:01:42 INFO Executor: Finished task 1.0 in stage 57.0 (TID 128). 1674 bytes result sent to driver
18/01/24 18:01:42 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 128) in 6217 ms on localhost (executor driver) (4/6)
18/01/24 18:01:43 INFO Executor: Finished task 4.0 in stage 57.0 (TID 131). 1674 bytes result sent to driver
18/01/24 18:01:43 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 131) in 5941 ms on localhost (executor driver) (5/6)
18/01/24 18:01:43 INFO Executor: Finished task 5.0 in stage 57.0 (TID 132). 1674 bytes result sent to driver
18/01/24 18:01:43 INFO TaskSetManager: Finished task 5.0 in stage 57.0 (TID 132) in 649 ms on localhost (executor driver) (6/6)
18/01/24 18:01:43 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
18/01/24 18:01:43 INFO DAGScheduler: ShuffleMapStage 57 (collect at utils.scala:211) finished in 6.284 s
18/01/24 18:01:43 INFO DAGScheduler: looking for newly runnable stages
18/01/24 18:01:43 INFO DAGScheduler: running: Set()
18/01/24 18:01:43 INFO DAGScheduler: waiting: Set(ResultStage 58)
18/01/24 18:01:43 INFO DAGScheduler: failed: Set()
18/01/24 18:01:43 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[184] at collect at utils.scala:211), which has no missing parents
18/01/24 18:01:43 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 51.8 KB, free 360.3 MB)
18/01/24 18:01:43 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 22.3 KB, free 360.2 MB)
18/01/24 18:01:43 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:35342 (size: 22.3 KB, free: 365.7 MB)
18/01/24 18:01:43 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:996
18/01/24 18:01:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[184] at collect at utils.scala:211)
18/01/24 18:01:43 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
18/01/24 18:01:43 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 133, localhost, executor driver, partition 0, ANY, 5947 bytes)
18/01/24 18:01:43 INFO Executor: Running task 0.0 in stage 58.0 (TID 133)
18/01/24 18:01:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 6 blocks
18/01/24 18:01:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 18:01:43 INFO Executor: Finished task 0.0 in stage 58.0 (TID 133). 3114 bytes result sent to driver
18/01/24 18:01:43 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 133) in 12 ms on localhost (executor driver) (1/1)
18/01/24 18:01:43 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
18/01/24 18:01:43 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:211) finished in 0.013 s
18/01/24 18:01:43 INFO DAGScheduler: Job 44 finished: collect at utils.scala:211, took 6.304963 s
18/01/24 18:02:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:02:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:02:06 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61045279d95
18/01/24 18:02:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:02:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61045279d95` AS `zzz35`
WHERE (0 = 1)
18/01/24 18:02:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:02:06 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n()`
FROM `sparklyr_tmp_61045279d95`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:02:07 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:02:07 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0),(UDF(UDF(UDF(named_struct(arrdelay, cast(CASE WHEN (arrdelay#24 = NA) THEN 0.0 WHEN NOT (arrdelay#24 = NA) THEN arrdelay#24 END as double), dephour, if (isnull(cast(crsdeptime#15 as double))) null else UDF(cast(crsdeptime#15 as double)))))) = 1.0)
18/01/24 18:02:07 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:02:07 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:02:07 INFO CodeGenerator: Code generated in 11.704055 ms
18/01/24 18:02:07 INFO CodeGenerator: Code generated in 24.768263 ms
18/01/24 18:02:07 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 282.1 KB, free 360.0 MB)
18/01/24 18:02:07 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 23.9 KB, free 359.9 MB)
18/01/24 18:02:07 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.6 MB)
18/01/24 18:02:07 INFO SparkContext: Created broadcast 99 from collect at utils.scala:211
18/01/24 18:02:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:02:07 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:02:07 INFO DAGScheduler: Registering RDD 188 (collect at utils.scala:211)
18/01/24 18:02:07 INFO DAGScheduler: Got job 45 (collect at utils.scala:211) with 4 output partitions
18/01/24 18:02:07 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:211)
18/01/24 18:02:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
18/01/24 18:02:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
18/01/24 18:02:07 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[188] at collect at utils.scala:211), which has no missing parents
18/01/24 18:02:07 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 52.3 KB, free 359.9 MB)
18/01/24 18:02:07 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 22.6 KB, free 359.9 MB)
18/01/24 18:02:07 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:35342 (size: 22.6 KB, free: 365.6 MB)
18/01/24 18:02:07 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:996
18/01/24 18:02:07 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[188] at collect at utils.scala:211)
18/01/24 18:02:07 INFO TaskSchedulerImpl: Adding task set 59.0 with 6 tasks
18/01/24 18:02:07 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:02:07 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:02:07 INFO TaskSetManager: Starting task 2.0 in stage 59.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:02:07 INFO TaskSetManager: Starting task 3.0 in stage 59.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:02:07 INFO Executor: Running task 0.0 in stage 59.0 (TID 134)
18/01/24 18:02:07 INFO Executor: Running task 2.0 in stage 59.0 (TID 136)
18/01/24 18:02:07 INFO Executor: Running task 1.0 in stage 59.0 (TID 135)
18/01/24 18:02:07 INFO Executor: Running task 3.0 in stage 59.0 (TID 137)
18/01/24 18:02:07 INFO CodeGenerator: Code generated in 11.863284 ms
18/01/24 18:02:07 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:02:07 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:02:07 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:02:07 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:02:10 ERROR Executor: Exception in task 0.0 in stage 59.0 (TID 134)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more
18/01/24 18:02:10 INFO TaskSetManager: Starting task 4.0 in stage 59.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:02:10 INFO Executor: Running task 4.0 in stage 59.0 (TID 138)
18/01/24 18:02:10 WARN TaskSetManager: Lost task 0.0 in stage 59.0 (TID 134, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

18/01/24 18:02:10 ERROR TaskSetManager: Task 0 in stage 59.0 failed 1 times; aborting job
18/01/24 18:02:10 INFO TaskSchedulerImpl: Cancelling stage 59
18/01/24 18:02:10 INFO TaskSchedulerImpl: Stage 59 was cancelled
18/01/24 18:02:10 INFO DAGScheduler: ShuffleMapStage 59 (collect at utils.scala:211) failed in 3.004 s due to Job aborted due to stage failure: Task 0 in stage 59.0 failed 1 times, most recent failure: Lost task 0.0 in stage 59.0 (TID 134, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

Driver stacktrace:
18/01/24 18:02:10 INFO Executor: Executor is trying to kill task 1.0 in stage 59.0 (TID 135)
18/01/24 18:02:10 INFO Executor: Executor is trying to kill task 2.0 in stage 59.0 (TID 136)
18/01/24 18:02:10 INFO Executor: Executor is trying to kill task 3.0 in stage 59.0 (TID 137)
18/01/24 18:02:10 INFO Executor: Executor is trying to kill task 4.0 in stage 59.0 (TID 138)
18/01/24 18:02:10 INFO DAGScheduler: Job 45 failed: collect at utils.scala:211, took 3.010256 s
18/01/24 18:02:10 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:02:13 INFO Executor: Executor killed task 3.0 in stage 59.0 (TID 137)
18/01/24 18:02:13 WARN TaskSetManager: Lost task 3.0 in stage 59.0 (TID 137, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:02:13 INFO Executor: Executor killed task 2.0 in stage 59.0 (TID 136)
18/01/24 18:02:13 WARN TaskSetManager: Lost task 2.0 in stage 59.0 (TID 136, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:02:13 INFO Executor: Executor killed task 1.0 in stage 59.0 (TID 135)
18/01/24 18:02:13 WARN TaskSetManager: Lost task 1.0 in stage 59.0 (TID 135, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:02:14 INFO Executor: Executor killed task 4.0 in stage 59.0 (TID 138)
18/01/24 18:02:14 WARN TaskSetManager: Lost task 4.0 in stage 59.0 (TID 138, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:02:14 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
18/01/24 18:03:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:03:16 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61043db4a6cb
18/01/24 18:03:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043db4a6cb` AS `zzz36`
WHERE (0 = 1)
18/01/24 18:03:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:16 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n()`
FROM `sparklyr_tmp_61043db4a6cb`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:03:16 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:03:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0),(UDF(UDF(UDF(named_struct(arrdelay, cast(CASE WHEN (arrdelay#24 = NA) THEN 0.0 WHEN NOT (arrdelay#24 = NA) THEN arrdelay#24 END as double), dephour, if (isnull(cast(crsdeptime#15 as double))) null else UDF(cast(crsdeptime#15 as double)))))) = 1.0)
18/01/24 18:03:16 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:03:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:03:16 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 282.1 KB, free 359.6 MB)
18/01/24 18:03:16 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 23.9 KB, free 359.6 MB)
18/01/24 18:03:16 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.6 MB)
18/01/24 18:03:16 INFO SparkContext: Created broadcast 101 from collect at utils.scala:211
18/01/24 18:03:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:03:16 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:03:16 INFO DAGScheduler: Registering RDD 195 (collect at utils.scala:211)
18/01/24 18:03:16 INFO DAGScheduler: Got job 46 (collect at utils.scala:211) with 4 output partitions
18/01/24 18:03:16 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:211)
18/01/24 18:03:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
18/01/24 18:03:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
18/01/24 18:03:16 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[195] at collect at utils.scala:211), which has no missing parents
18/01/24 18:03:16 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 52.3 KB, free 359.5 MB)
18/01/24 18:03:16 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 22.6 KB, free 359.5 MB)
18/01/24 18:03:16 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:35342 (size: 22.6 KB, free: 365.6 MB)
18/01/24 18:03:16 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:996
18/01/24 18:03:16 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[195] at collect at utils.scala:211)
18/01/24 18:03:16 INFO TaskSchedulerImpl: Adding task set 61.0 with 6 tasks
18/01/24 18:03:16 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:03:16 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 140, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:03:16 INFO TaskSetManager: Starting task 2.0 in stage 61.0 (TID 141, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:03:16 INFO TaskSetManager: Starting task 3.0 in stage 61.0 (TID 142, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:03:16 INFO Executor: Running task 0.0 in stage 61.0 (TID 139)
18/01/24 18:03:16 INFO Executor: Running task 1.0 in stage 61.0 (TID 140)
18/01/24 18:03:16 INFO Executor: Running task 2.0 in stage 61.0 (TID 141)
18/01/24 18:03:16 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:03:16 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:03:16 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:03:16 INFO Executor: Running task 3.0 in stage 61.0 (TID 142)
18/01/24 18:03:16 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:03:16 INFO ContextCleaner: Cleaned accumulator 4985
18/01/24 18:03:19 ERROR Executor: Exception in task 0.0 in stage 61.0 (TID 139)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more
18/01/24 18:03:19 INFO TaskSetManager: Starting task 4.0 in stage 61.0 (TID 143, localhost, executor driver, partition 4, PROCESS_LOCAL, 6575 bytes)
18/01/24 18:03:19 WARN TaskSetManager: Lost task 0.0 in stage 61.0 (TID 139, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

18/01/24 18:03:19 ERROR TaskSetManager: Task 0 in stage 61.0 failed 1 times; aborting job
18/01/24 18:03:19 INFO TaskSchedulerImpl: Cancelling stage 61
18/01/24 18:03:19 INFO Executor: Executor is trying to kill task 4.0 in stage 61.0 (TID 143)
18/01/24 18:03:19 INFO Executor: Running task 4.0 in stage 61.0 (TID 143)
18/01/24 18:03:19 INFO Executor: Executor is trying to kill task 1.0 in stage 61.0 (TID 140)
18/01/24 18:03:19 INFO Executor: Executor is trying to kill task 2.0 in stage 61.0 (TID 141)
18/01/24 18:03:19 INFO Executor: Executor is trying to kill task 3.0 in stage 61.0 (TID 142)
18/01/24 18:03:19 INFO TaskSchedulerImpl: Stage 61 was cancelled
18/01/24 18:03:19 INFO DAGScheduler: ShuffleMapStage 61 (collect at utils.scala:211) failed in 2.829 s due to Job aborted due to stage failure: Task 0 in stage 61.0 failed 1 times, most recent failure: Lost task 0.0 in stage 61.0 (TID 139, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

Driver stacktrace:
18/01/24 18:03:19 INFO DAGScheduler: Job 46 failed: collect at utils.scala:211, took 2.836331 s
18/01/24 18:03:19 INFO Executor: Executor killed task 4.0 in stage 61.0 (TID 143)
18/01/24 18:03:19 WARN TaskSetManager: Lost task 4.0 in stage 61.0 (TID 143, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:03:21 INFO Executor: Executor killed task 2.0 in stage 61.0 (TID 141)
18/01/24 18:03:21 WARN TaskSetManager: Lost task 2.0 in stage 61.0 (TID 141, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:03:21 INFO Executor: Executor killed task 3.0 in stage 61.0 (TID 142)
18/01/24 18:03:21 WARN TaskSetManager: Lost task 3.0 in stage 61.0 (TID 142, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:03:21 INFO Executor: Executor killed task 1.0 in stage 61.0 (TID 140)
18/01/24 18:03:21 WARN TaskSetManager: Lost task 1.0 in stage 61.0 (TID 140, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:03:21 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610470491ea
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea` AS `zzz37`
WHERE (0 = 1)
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea`
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea`
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea`
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea`
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea`
18/01/24 18:03:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610470491ea`
LIMIT 1000
18/01/24 18:03:30 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:03:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:03:30 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrtime: string, crsarrtime: string ... 6 more fields>
18/01/24 18:03:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:03:30 INFO CodeGenerator: Code generated in 69.286872 ms
18/01/24 18:03:30 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 282.1 KB, free 359.2 MB)
18/01/24 18:03:30 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 23.9 KB, free 359.2 MB)
18/01/24 18:03:30 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.6 MB)
18/01/24 18:03:30 INFO SparkContext: Created broadcast 103 from collect at utils.scala:211
18/01/24 18:03:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:03:30 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:03:30 INFO DAGScheduler: Got job 47 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:03:30 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:211)
18/01/24 18:03:30 INFO DAGScheduler: Parents of final stage: List()
18/01/24 18:03:30 INFO DAGScheduler: Missing parents: List()
18/01/24 18:03:30 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[202] at collect at utils.scala:211), which has no missing parents
18/01/24 18:03:30 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 88.3 KB, free 359.1 MB)
18/01/24 18:03:30 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 27.0 KB, free 359.1 MB)
18/01/24 18:03:30 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:35342 (size: 27.0 KB, free: 365.5 MB)
18/01/24 18:03:30 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
18/01/24 18:03:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[202] at collect at utils.scala:211)
18/01/24 18:03:30 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
18/01/24 18:03:30 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/01/24 18:03:30 INFO Executor: Running task 0.0 in stage 63.0 (TID 144)
18/01/24 18:03:30 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:03:30 INFO Executor: Finished task 0.0 in stage 63.0 (TID 144). 63335 bytes result sent to driver
18/01/24 18:03:30 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 144) in 270 ms on localhost (executor driver) (1/1)
18/01/24 18:03:30 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
18/01/24 18:03:30 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:211) finished in 0.270 s
18/01/24 18:03:30 INFO DAGScheduler: Job 47 finished: collect at utils.scala:211, took 0.278032 s
18/01/24 18:03:30 INFO CodeGenerator: Code generated in 25.987867 ms
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61044bf98388
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388` AS `zzz38`
WHERE (0 = 1)
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388`
WHERE (`prediction` = 1.0)
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388`
WHERE (`prediction` = 1.0)
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388`
WHERE (`prediction` = 1.0)
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388`
WHERE (`prediction` = 1.0)
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388`
WHERE (`prediction` = 1.0)
18/01/24 18:03:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:03:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61044bf98388`
WHERE (`prediction` = 1.0)
LIMIT 1000
18/01/24 18:03:41 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:03:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0),(UDF(UDF(UDF(named_struct(arrdelay, cast(CASE WHEN (arrdelay#24 = NA) THEN 0.0 WHEN NOT (arrdelay#24 = NA) THEN arrdelay#24 END as double), dephour, if (isnull(cast(crsdeptime#15 as double))) null else UDF(cast(crsdeptime#15 as double)))))) = 1.0)
18/01/24 18:03:41 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrtime: string, crsarrtime: string ... 6 more fields>
18/01/24 18:03:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:03:41 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:35342 in memory (size: 27.0 KB, free: 365.6 MB)
18/01/24 18:03:41 INFO CodeGenerator: Code generated in 48.770871 ms
18/01/24 18:03:41 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 282.1 KB, free 358.9 MB)
18/01/24 18:03:41 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 23.9 KB, free 358.9 MB)
18/01/24 18:03:41 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.5 MB)
18/01/24 18:03:41 INFO SparkContext: Created broadcast 105 from collect at utils.scala:211
18/01/24 18:03:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:03:41 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:03:41 INFO DAGScheduler: Got job 48 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:03:41 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:211)
18/01/24 18:03:41 INFO DAGScheduler: Parents of final stage: List()
18/01/24 18:03:41 INFO DAGScheduler: Missing parents: List()
18/01/24 18:03:41 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[206] at collect at utils.scala:211), which has no missing parents
18/01/24 18:03:41 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 97.1 KB, free 358.8 MB)
18/01/24 18:03:41 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 29.1 KB, free 358.8 MB)
18/01/24 18:03:41 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:35342 (size: 29.1 KB, free: 365.5 MB)
18/01/24 18:03:41 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
18/01/24 18:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[206] at collect at utils.scala:211)
18/01/24 18:03:41 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
18/01/24 18:03:41 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/01/24 18:03:41 INFO Executor: Running task 0.0 in stage 64.0 (TID 145)
18/01/24 18:03:41 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:03:42 INFO Executor: Finished task 0.0 in stage 64.0 (TID 145). 62888 bytes result sent to driver
18/01/24 18:03:42 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 145) in 550 ms on localhost (executor driver) (1/1)
18/01/24 18:03:42 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
18/01/24 18:03:42 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:211) finished in 0.549 s
18/01/24 18:03:42 INFO DAGScheduler: Job 48 finished: collect at utils.scala:211, took 0.555405 s
18/01/24 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:05:04 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610478c4357b
18/01/24 18:05:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610478c4357b` AS `zzz39`
WHERE (0 = 1)
18/01/24 18:05:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_610478c4357b`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_610478c4357b`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_610478c4357b`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_610478c4357b`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_610478c4357b`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_610478c4357b`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
LIMIT 1000
18/01/24 18:05:05 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:05:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0),(UDF(UDF(UDF(named_struct(arrdelay, cast(CASE WHEN (arrdelay#24 = NA) THEN 0.0 WHEN NOT (arrdelay#24 = NA) THEN arrdelay#24 END as double), dephour, if (isnull(cast(crsdeptime#15 as double))) null else UDF(cast(crsdeptime#15 as double)))))) = 1.0)
18/01/24 18:05:05 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:05:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:05:05 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 282.1 KB, free 358.5 MB)
18/01/24 18:05:05 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 23.9 KB, free 358.5 MB)
18/01/24 18:05:05 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.5 MB)
18/01/24 18:05:05 INFO SparkContext: Created broadcast 107 from collect at utils.scala:211
18/01/24 18:05:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:05:05 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:05:05 INFO DAGScheduler: Registering RDD 210 (collect at utils.scala:211)
18/01/24 18:05:05 INFO DAGScheduler: Got job 49 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:05:05 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:211)
18/01/24 18:05:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
18/01/24 18:05:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
18/01/24 18:05:05 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[210] at collect at utils.scala:211), which has no missing parents
18/01/24 18:05:05 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 52.3 KB, free 358.4 MB)
18/01/24 18:05:05 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 22.6 KB, free 358.4 MB)
18/01/24 18:05:05 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:35342 (size: 22.6 KB, free: 365.5 MB)
18/01/24 18:05:05 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:996
18/01/24 18:05:05 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[210] at collect at utils.scala:211)
18/01/24 18:05:05 INFO TaskSchedulerImpl: Adding task set 65.0 with 6 tasks
18/01/24 18:05:05 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:05 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 147, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:05 INFO TaskSetManager: Starting task 2.0 in stage 65.0 (TID 148, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:05 INFO TaskSetManager: Starting task 3.0 in stage 65.0 (TID 149, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:05 INFO Executor: Running task 0.0 in stage 65.0 (TID 146)
18/01/24 18:05:05 INFO Executor: Running task 1.0 in stage 65.0 (TID 147)
18/01/24 18:05:05 INFO Executor: Running task 2.0 in stage 65.0 (TID 148)
18/01/24 18:05:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:05:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:05:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:05:05 INFO Executor: Running task 3.0 in stage 65.0 (TID 149)
18/01/24 18:05:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:05:06 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:35342 in memory (size: 29.1 KB, free: 365.5 MB)
18/01/24 18:05:06 INFO ContextCleaner: Cleaned accumulator 5248
18/01/24 18:05:08 ERROR Executor: Exception in task 0.0 in stage 65.0 (TID 146)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more
18/01/24 18:05:08 INFO TaskSetManager: Starting task 4.0 in stage 65.0 (TID 150, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:08 WARN TaskSetManager: Lost task 0.0 in stage 65.0 (TID 146, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

18/01/24 18:05:08 ERROR TaskSetManager: Task 0 in stage 65.0 failed 1 times; aborting job
18/01/24 18:05:08 INFO TaskSchedulerImpl: Cancelling stage 65
18/01/24 18:05:08 INFO TaskSchedulerImpl: Stage 65 was cancelled
18/01/24 18:05:08 INFO DAGScheduler: ShuffleMapStage 65 (collect at utils.scala:211) failed in 2.808 s due to Job aborted due to stage failure: Task 0 in stage 65.0 failed 1 times, most recent failure: Lost task 0.0 in stage 65.0 (TID 146, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 45.0 out of Bucketizer bounds [100.0, 2400.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

Driver stacktrace:
18/01/24 18:05:08 INFO DAGScheduler: Job 49 failed: collect at utils.scala:211, took 2.813038 s
18/01/24 18:05:08 INFO Executor: Running task 4.0 in stage 65.0 (TID 150)
18/01/24 18:05:08 INFO Executor: Executor is trying to kill task 4.0 in stage 65.0 (TID 150)
18/01/24 18:05:08 INFO Executor: Executor is trying to kill task 1.0 in stage 65.0 (TID 147)
18/01/24 18:05:08 INFO Executor: Executor is trying to kill task 2.0 in stage 65.0 (TID 148)
18/01/24 18:05:08 INFO Executor: Executor is trying to kill task 3.0 in stage 65.0 (TID 149)
18/01/24 18:05:08 INFO Executor: Executor killed task 4.0 in stage 65.0 (TID 150)
18/01/24 18:05:08 WARN TaskSetManager: Lost task 4.0 in stage 65.0 (TID 150, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:11 INFO Executor: Executor killed task 3.0 in stage 65.0 (TID 149)
18/01/24 18:05:11 WARN TaskSetManager: Lost task 3.0 in stage 65.0 (TID 149, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:11 INFO Executor: Executor killed task 2.0 in stage 65.0 (TID 148)
18/01/24 18:05:11 WARN TaskSetManager: Lost task 2.0 in stage 65.0 (TID 148, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:11 INFO Executor: Executor killed task 1.0 in stage 65.0 (TID 147)
18/01/24 18:05:11 WARN TaskSetManager: Lost task 1.0 in stage 65.0 (TID 147, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:11 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6104573b0e99
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104573b0e99` AS `zzz40`
WHERE (0 = 1)
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_6104573b0e99`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_6104573b0e99`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_6104573b0e99`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_6104573b0e99`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_6104573b0e99`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
18/01/24 18:05:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:29 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_6104573b0e99`
WHERE (`prediction` = 1.0)
GROUP BY `hour`
LIMIT 1000
18/01/24 18:05:29 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:05:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0),(UDF(UDF(UDF(named_struct(arrdelay, cast(CASE WHEN (arrdelay#24 = NA) THEN 0.0 WHEN NOT (arrdelay#24 = NA) THEN arrdelay#24 END as double), dephour, if (isnull(cast(crsdeptime#15 as double))) null else UDF(cast(crsdeptime#15 as double)))))) = 1.0)
18/01/24 18:05:29 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:05:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:05:29 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 282.1 KB, free 358.2 MB)
18/01/24 18:05:29 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 23.9 KB, free 358.2 MB)
18/01/24 18:05:29 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.5 MB)
18/01/24 18:05:29 INFO SparkContext: Created broadcast 109 from collect at utils.scala:211
18/01/24 18:05:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:05:29 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:05:29 INFO DAGScheduler: Registering RDD 217 (collect at utils.scala:211)
18/01/24 18:05:29 INFO DAGScheduler: Got job 50 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:05:29 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:211)
18/01/24 18:05:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
18/01/24 18:05:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
18/01/24 18:05:29 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[217] at collect at utils.scala:211), which has no missing parents
18/01/24 18:05:29 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 52.3 KB, free 358.2 MB)
18/01/24 18:05:29 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 22.6 KB, free 358.1 MB)
18/01/24 18:05:29 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:35342 (size: 22.6 KB, free: 365.4 MB)
18/01/24 18:05:29 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
18/01/24 18:05:29 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[217] at collect at utils.scala:211)
18/01/24 18:05:29 INFO TaskSchedulerImpl: Adding task set 67.0 with 6 tasks
18/01/24 18:05:29 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:29 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 152, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:29 INFO TaskSetManager: Starting task 2.0 in stage 67.0 (TID 153, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:29 INFO TaskSetManager: Starting task 3.0 in stage 67.0 (TID 154, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:29 INFO Executor: Running task 0.0 in stage 67.0 (TID 151)
18/01/24 18:05:29 INFO Executor: Running task 2.0 in stage 67.0 (TID 153)
18/01/24 18:05:29 INFO Executor: Running task 1.0 in stage 67.0 (TID 152)
18/01/24 18:05:29 INFO Executor: Running task 3.0 in stage 67.0 (TID 154)
18/01/24 18:05:29 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:05:29 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:05:29 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:05:29 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:05:30 ERROR Executor: Exception in task 0.0 in stage 67.0 (TID 151)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2353.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more
18/01/24 18:05:30 INFO TaskSetManager: Starting task 4.0 in stage 67.0 (TID 155, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:05:30 WARN TaskSetManager: Lost task 0.0 in stage 67.0 (TID 151, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2353.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

18/01/24 18:05:30 ERROR TaskSetManager: Task 0 in stage 67.0 failed 1 times; aborting job
18/01/24 18:05:30 INFO Executor: Running task 4.0 in stage 67.0 (TID 155)
18/01/24 18:05:30 INFO TaskSchedulerImpl: Cancelling stage 67
18/01/24 18:05:30 INFO TaskSchedulerImpl: Stage 67 was cancelled
18/01/24 18:05:30 INFO DAGScheduler: ShuffleMapStage 67 (collect at utils.scala:211) failed in 0.709 s due to Job aborted due to stage failure: Task 0 in stage 67.0 failed 1 times, most recent failure: Lost task 0.0 in stage 67.0 (TID 151, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2353.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

Driver stacktrace:
18/01/24 18:05:30 INFO Executor: Executor is trying to kill task 2.0 in stage 67.0 (TID 153)
18/01/24 18:05:30 INFO Executor: Executor is trying to kill task 3.0 in stage 67.0 (TID 154)
18/01/24 18:05:30 INFO Executor: Executor is trying to kill task 4.0 in stage 67.0 (TID 155)
18/01/24 18:05:30 INFO Executor: Executor is trying to kill task 1.0 in stage 67.0 (TID 152)
18/01/24 18:05:30 INFO Executor: Executor killed task 4.0 in stage 67.0 (TID 155)
18/01/24 18:05:30 INFO DAGScheduler: Job 50 failed: collect at utils.scala:211, took 0.719906 s
18/01/24 18:05:30 WARN TaskSetManager: Lost task 4.0 in stage 67.0 (TID 155, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:33 INFO Executor: Executor killed task 1.0 in stage 67.0 (TID 152)
18/01/24 18:05:33 WARN TaskSetManager: Lost task 1.0 in stage 67.0 (TID 152, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:34 INFO Executor: Executor killed task 2.0 in stage 67.0 (TID 153)
18/01/24 18:05:34 WARN TaskSetManager: Lost task 2.0 in stage 67.0 (TID 153, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:34 INFO Executor: Executor killed task 3.0 in stage 67.0 (TID 154)
18/01/24 18:05:34 WARN TaskSetManager: Lost task 3.0 in stage 67.0 (TID 154, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:05:34 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61043dbdb3e6
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6` AS `zzz41`
WHERE (0 = 1)
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6`
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6`
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6`
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6`
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6`
18/01/24 18:05:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:05:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043dbdb3e6`
LIMIT 1000
18/01/24 18:05:47 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:05:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:05:47 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrtime: string, crsarrtime: string ... 6 more fields>
18/01/24 18:05:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:05:47 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 282.1 KB, free 357.9 MB)
18/01/24 18:05:47 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 23.9 KB, free 357.9 MB)
18/01/24 18:05:47 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.4 MB)
18/01/24 18:05:47 INFO SparkContext: Created broadcast 111 from collect at utils.scala:211
18/01/24 18:05:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:05:47 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:05:47 INFO DAGScheduler: Got job 51 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:05:47 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:211)
18/01/24 18:05:47 INFO DAGScheduler: Parents of final stage: List()
18/01/24 18:05:47 INFO DAGScheduler: Missing parents: List()
18/01/24 18:05:47 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[224] at collect at utils.scala:211), which has no missing parents
18/01/24 18:05:47 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 88.3 KB, free 357.8 MB)
18/01/24 18:05:47 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 27.0 KB, free 357.7 MB)
18/01/24 18:05:47 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:35342 (size: 27.0 KB, free: 365.4 MB)
18/01/24 18:05:47 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
18/01/24 18:05:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[224] at collect at utils.scala:211)
18/01/24 18:05:47 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
18/01/24 18:05:47 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 156, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/01/24 18:05:47 INFO Executor: Running task 0.0 in stage 69.0 (TID 156)
18/01/24 18:05:47 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:05:48 INFO Executor: Finished task 0.0 in stage 69.0 (TID 156). 63369 bytes result sent to driver
18/01/24 18:05:48 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 156) in 246 ms on localhost (executor driver) (1/1)
18/01/24 18:05:48 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
18/01/24 18:05:48 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:211) finished in 0.245 s
18/01/24 18:05:48 INFO DAGScheduler: Job 51 finished: collect at utils.scala:211, took 0.251077 s
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61042e5b0939
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61042e5b0939` AS `zzz42`
WHERE (0 = 1)
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61042e5b0939`
GROUP BY `hour`
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61042e5b0939`
GROUP BY `hour`
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61042e5b0939`
GROUP BY `hour`
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61042e5b0939`
GROUP BY `hour`
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61042e5b0939`
GROUP BY `hour`
18/01/24 18:06:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:06:05 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61042e5b0939`
GROUP BY `hour`
LIMIT 1000
18/01/24 18:06:05 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:06:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:06:05 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string ... 1 more fields>
18/01/24 18:06:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:06:05 INFO CodeGenerator: Code generated in 16.055266 ms
18/01/24 18:06:05 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 282.1 KB, free 357.5 MB)
18/01/24 18:06:05 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 23.9 KB, free 357.4 MB)
18/01/24 18:06:05 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.4 MB)
18/01/24 18:06:05 INFO SparkContext: Created broadcast 113 from collect at utils.scala:211
18/01/24 18:06:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:06:05 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:06:05 INFO DAGScheduler: Registering RDD 228 (collect at utils.scala:211)
18/01/24 18:06:05 INFO DAGScheduler: Got job 52 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:06:05 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:211)
18/01/24 18:06:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
18/01/24 18:06:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
18/01/24 18:06:05 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[228] at collect at utils.scala:211), which has no missing parents
18/01/24 18:06:05 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 34.9 KB, free 357.4 MB)
18/01/24 18:06:05 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 16.5 KB, free 357.4 MB)
18/01/24 18:06:05 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:35342 (size: 16.5 KB, free: 365.4 MB)
18/01/24 18:06:05 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:996
18/01/24 18:06:05 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[228] at collect at utils.scala:211)
18/01/24 18:06:05 INFO TaskSchedulerImpl: Adding task set 70.0 with 6 tasks
18/01/24 18:06:05 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:06:05 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 158, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:06:05 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 159, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:06:05 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 160, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:06:05 INFO Executor: Running task 0.0 in stage 70.0 (TID 157)
18/01/24 18:06:05 INFO Executor: Running task 1.0 in stage 70.0 (TID 158)
18/01/24 18:06:05 INFO Executor: Running task 3.0 in stage 70.0 (TID 160)
18/01/24 18:06:05 INFO Executor: Running task 2.0 in stage 70.0 (TID 159)
18/01/24 18:06:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:06:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:06:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:06:05 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:06:06 ERROR Executor: Exception in task 0.0 in stage 70.0 (TID 157)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more
18/01/24 18:06:06 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 161, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:06:06 INFO Executor: Running task 4.0 in stage 70.0 (TID 161)
18/01/24 18:06:06 WARN TaskSetManager: Lost task 0.0 in stage 70.0 (TID 157, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

18/01/24 18:06:06 ERROR TaskSetManager: Task 0 in stage 70.0 failed 1 times; aborting job
18/01/24 18:06:06 INFO TaskSchedulerImpl: Cancelling stage 70
18/01/24 18:06:06 INFO Executor: Executor is trying to kill task 4.0 in stage 70.0 (TID 161)
18/01/24 18:06:06 INFO Executor: Executor is trying to kill task 1.0 in stage 70.0 (TID 158)
18/01/24 18:06:06 INFO Executor: Executor is trying to kill task 2.0 in stage 70.0 (TID 159)
18/01/24 18:06:06 INFO TaskSchedulerImpl: Stage 70 was cancelled
18/01/24 18:06:06 INFO Executor: Executor is trying to kill task 3.0 in stage 70.0 (TID 160)
18/01/24 18:06:06 INFO DAGScheduler: ShuffleMapStage 70 (collect at utils.scala:211) failed in 0.880 s due to Job aborted due to stage failure: Task 0 in stage 70.0 failed 1 times, most recent failure: Lost task 0.0 in stage 70.0 (TID 157, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

Driver stacktrace:
18/01/24 18:06:06 INFO DAGScheduler: Job 52 failed: collect at utils.scala:211, took 0.891418 s
18/01/24 18:06:06 INFO Executor: Executor killed task 4.0 in stage 70.0 (TID 161)
18/01/24 18:06:06 WARN TaskSetManager: Lost task 4.0 in stage 70.0 (TID 161, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:06:10 INFO Executor: Executor killed task 1.0 in stage 70.0 (TID 158)
18/01/24 18:06:10 WARN TaskSetManager: Lost task 1.0 in stage 70.0 (TID 158, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:06:10 INFO Executor: Executor killed task 2.0 in stage 70.0 (TID 159)
18/01/24 18:06:10 WARN TaskSetManager: Lost task 2.0 in stage 70.0 (TID 159, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:06:10 INFO Executor: Executor killed task 3.0 in stage 70.0 (TID 160)
18/01/24 18:06:10 WARN TaskSetManager: Lost task 3.0 in stage 70.0 (TID 160, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:06:10 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61041364c174
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61041364c174` AS `zzz43`
WHERE (0 = 1)
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61041364c174`
WHERE (NOT(((`hour`) IS NULL)))
GROUP BY `hour`
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61041364c174`
WHERE (NOT(((`hour`) IS NULL)))
GROUP BY `hour`
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61041364c174`
WHERE (NOT(((`hour`) IS NULL)))
GROUP BY `hour`
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61041364c174`
WHERE (NOT(((`hour`) IS NULL)))
GROUP BY `hour`
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61041364c174`
WHERE (NOT(((`hour`) IS NULL)))
GROUP BY `hour`
18/01/24 18:07:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:07:54 INFO SparkSqlParser: Parsing command: SELECT `hour`, count(*) AS `n`
FROM `sparklyr_tmp_61041364c174`
WHERE (NOT(((`hour`) IS NULL)))
GROUP BY `hour`
LIMIT 1000
18/01/24 18:07:55 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:07:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0),NOT isnull(if (isnull(cast(crsdeptime#15 as double))) null else UDF(cast(crsdeptime#15 as double)))
18/01/24 18:07:55 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string ... 1 more fields>
18/01/24 18:07:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:07:55 INFO CodeGenerator: Code generated in 15.767283 ms
18/01/24 18:07:55 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 282.1 KB, free 357.1 MB)
18/01/24 18:07:55 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 23.9 KB, free 357.1 MB)
18/01/24 18:07:55 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.3 MB)
18/01/24 18:07:55 INFO SparkContext: Created broadcast 115 from collect at utils.scala:211
18/01/24 18:07:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:07:55 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:07:55 INFO DAGScheduler: Registering RDD 235 (collect at utils.scala:211)
18/01/24 18:07:55 INFO DAGScheduler: Got job 53 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:07:55 INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:211)
18/01/24 18:07:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
18/01/24 18:07:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 72)
18/01/24 18:07:55 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[235] at collect at utils.scala:211), which has no missing parents
18/01/24 18:07:55 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 37.4 KB, free 357.1 MB)
18/01/24 18:07:55 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 17.3 KB, free 357.0 MB)
18/01/24 18:07:55 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:35342 (size: 17.3 KB, free: 365.3 MB)
18/01/24 18:07:55 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:996
18/01/24 18:07:55 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[235] at collect at utils.scala:211)
18/01/24 18:07:55 INFO TaskSchedulerImpl: Adding task set 72.0 with 6 tasks
18/01/24 18:07:55 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 162, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:07:55 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 163, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:07:55 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 164, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:07:55 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 165, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:07:55 INFO Executor: Running task 0.0 in stage 72.0 (TID 162)
18/01/24 18:07:55 INFO Executor: Running task 1.0 in stage 72.0 (TID 163)
18/01/24 18:07:55 INFO Executor: Running task 2.0 in stage 72.0 (TID 164)
18/01/24 18:07:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:07:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:07:55 INFO Executor: Running task 3.0 in stage 72.0 (TID 165)
18/01/24 18:07:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:07:55 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:07:56 ERROR Executor: Exception in task 0.0 in stage 72.0 (TID 162)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more
18/01/24 18:07:56 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 166, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:07:56 WARN TaskSetManager: Lost task 0.0 in stage 72.0 (TID 162, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

18/01/24 18:07:56 ERROR TaskSetManager: Task 0 in stage 72.0 failed 1 times; aborting job
18/01/24 18:07:56 INFO TaskSchedulerImpl: Cancelling stage 72
18/01/24 18:07:56 INFO Executor: Executor is trying to kill task 3.0 in stage 72.0 (TID 165)
18/01/24 18:07:56 INFO TaskSchedulerImpl: Stage 72 was cancelled
18/01/24 18:07:56 INFO Executor: Executor is trying to kill task 4.0 in stage 72.0 (TID 166)
18/01/24 18:07:56 INFO Executor: Executor is trying to kill task 1.0 in stage 72.0 (TID 163)
18/01/24 18:07:56 INFO Executor: Executor is trying to kill task 2.0 in stage 72.0 (TID 164)
18/01/24 18:07:56 INFO DAGScheduler: ShuffleMapStage 72 (collect at utils.scala:211) failed in 1.007 s due to Job aborted due to stage failure: Task 0 in stage 72.0 failed 1 times, most recent failure: Lost task 0.0 in stage 72.0 (TID 162, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 13 more

Driver stacktrace:
18/01/24 18:07:56 INFO DAGScheduler: Job 53 failed: collect at utils.scala:211, took 1.010037 s
18/01/24 18:07:56 INFO Executor: Running task 4.0 in stage 72.0 (TID 166)
18/01/24 18:07:56 INFO Executor: Executor killed task 4.0 in stage 72.0 (TID 166)
18/01/24 18:07:56 WARN TaskSetManager: Lost task 4.0 in stage 72.0 (TID 166, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:07:59 INFO Executor: Executor killed task 3.0 in stage 72.0 (TID 165)
18/01/24 18:07:59 WARN TaskSetManager: Lost task 3.0 in stage 72.0 (TID 165, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:00 INFO Executor: Executor killed task 2.0 in stage 72.0 (TID 164)
18/01/24 18:08:00 WARN TaskSetManager: Lost task 2.0 in stage 72.0 (TID 164, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:00 INFO Executor: Executor killed task 1.0 in stage 72.0 (TID 163)
18/01/24 18:08:00 WARN TaskSetManager: Lost task 1.0 in stage 72.0 (TID 163, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:00 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
18/01/24 18:08:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:08:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:08:26 INFO SparkSqlParser: Parsing command: sparklyr_tmp_610467b95147
18/01/24 18:08:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:08:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_610467b95147` AS `zzz44`
WHERE (0 = 1)
18/01/24 18:08:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:08:26 INFO SparkSqlParser: Parsing command: SELECT `hour`
FROM `sparklyr_tmp_610467b95147`
18/01/24 18:08:26 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:08:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:08:26 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string ... 1 more fields>
18/01/24 18:08:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:08:26 INFO CodeGenerator: Code generated in 7.526209 ms
18/01/24 18:08:26 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 282.1 KB, free 356.8 MB)
18/01/24 18:08:26 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 23.9 KB, free 356.7 MB)
18/01/24 18:08:26 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.3 MB)
18/01/24 18:08:26 INFO SparkContext: Created broadcast 117 from collect at utils.scala:211
18/01/24 18:08:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:08:26 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:08:26 INFO DAGScheduler: Got job 54 (collect at utils.scala:211) with 6 output partitions
18/01/24 18:08:26 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:211)
18/01/24 18:08:26 INFO DAGScheduler: Parents of final stage: List()
18/01/24 18:08:26 INFO DAGScheduler: Missing parents: List()
18/01/24 18:08:26 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[242] at collect at utils.scala:211), which has no missing parents
18/01/24 18:08:26 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 18.2 KB, free 356.7 MB)
18/01/24 18:08:26 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 8.8 KB, free 356.7 MB)
18/01/24 18:08:26 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:35342 (size: 8.8 KB, free: 365.3 MB)
18/01/24 18:08:26 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:996
18/01/24 18:08:26 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 74 (MapPartitionsRDD[242] at collect at utils.scala:211)
18/01/24 18:08:26 INFO TaskSchedulerImpl: Adding task set 74.0 with 6 tasks
18/01/24 18:08:26 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:26 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 168, localhost, executor driver, partition 1, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:26 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 169, localhost, executor driver, partition 2, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:26 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 170, localhost, executor driver, partition 3, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:26 INFO Executor: Running task 3.0 in stage 74.0 (TID 170)
18/01/24 18:08:26 INFO Executor: Running task 1.0 in stage 74.0 (TID 168)
18/01/24 18:08:26 INFO Executor: Running task 2.0 in stage 74.0 (TID 169)
18/01/24 18:08:26 INFO Executor: Running task 0.0 in stage 74.0 (TID 167)
18/01/24 18:08:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:08:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:08:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:08:26 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:08:26 ERROR Executor: Exception in task 0.0 in stage 74.0 (TID 167)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 16 more
18/01/24 18:08:26 INFO TaskSetManager: Starting task 4.0 in stage 74.0 (TID 171, localhost, executor driver, partition 4, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:26 WARN TaskSetManager: Lost task 0.0 in stage 74.0 (TID 167, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 16 more

18/01/24 18:08:26 ERROR TaskSetManager: Task 0 in stage 74.0 failed 1 times; aborting job
18/01/24 18:08:26 INFO TaskSchedulerImpl: Cancelling stage 74
18/01/24 18:08:26 INFO Executor: Executor is trying to kill task 4.0 in stage 74.0 (TID 171)
18/01/24 18:08:26 INFO Executor: Executor is trying to kill task 1.0 in stage 74.0 (TID 168)
18/01/24 18:08:26 INFO Executor: Running task 4.0 in stage 74.0 (TID 171)
18/01/24 18:08:26 INFO Executor: Executor is trying to kill task 2.0 in stage 74.0 (TID 169)
18/01/24 18:08:26 INFO Executor: Executor is trying to kill task 3.0 in stage 74.0 (TID 170)
18/01/24 18:08:26 INFO TaskSchedulerImpl: Stage 74 was cancelled
18/01/24 18:08:26 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:211) failed in 0.717 s due to Job aborted due to stage failure: Task 0 in stage 74.0 failed 1 times, most recent failure: Lost task 0.0 in stage 74.0 (TID 167, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 16 more

Driver stacktrace:
18/01/24 18:08:26 INFO DAGScheduler: Job 54 failed: collect at utils.scala:211, took 0.720357 s
18/01/24 18:08:26 INFO Executor: Executor killed task 4.0 in stage 74.0 (TID 171)
18/01/24 18:08:26 WARN TaskSetManager: Lost task 4.0 in stage 74.0 (TID 171, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:30 INFO Executor: Executor killed task 1.0 in stage 74.0 (TID 168)
18/01/24 18:08:30 WARN TaskSetManager: Lost task 1.0 in stage 74.0 (TID 168, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:30 INFO Executor: Executor killed task 3.0 in stage 74.0 (TID 170)
18/01/24 18:08:30 WARN TaskSetManager: Lost task 3.0 in stage 74.0 (TID 170, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:30 INFO Executor: Executor killed task 2.0 in stage 74.0 (TID 169)
18/01/24 18:08:30 WARN TaskSetManager: Lost task 2.0 in stage 74.0 (TID 169, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:30 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
18/01/24 18:08:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:08:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:08:45 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61045d333279
18/01/24 18:08:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:08:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61045d333279` AS `zzz45`
WHERE (0 = 1)
18/01/24 18:08:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:08:45 INFO SparkSqlParser: Parsing command: SELECT `hour`
FROM `sparklyr_tmp_61045d333279`
18/01/24 18:08:45 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:08:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:08:45 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string ... 1 more fields>
18/01/24 18:08:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:08:45 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 282.1 KB, free 356.4 MB)
18/01/24 18:08:45 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 23.9 KB, free 356.4 MB)
18/01/24 18:08:45 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.3 MB)
18/01/24 18:08:45 INFO SparkContext: Created broadcast 119 from collect at utils.scala:211
18/01/24 18:08:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:08:45 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:08:45 INFO DAGScheduler: Got job 55 (collect at utils.scala:211) with 6 output partitions
18/01/24 18:08:45 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:211)
18/01/24 18:08:45 INFO DAGScheduler: Parents of final stage: List()
18/01/24 18:08:45 INFO DAGScheduler: Missing parents: List()
18/01/24 18:08:45 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[246] at collect at utils.scala:211), which has no missing parents
18/01/24 18:08:45 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 18.2 KB, free 356.4 MB)
18/01/24 18:08:45 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 8.8 KB, free 356.4 MB)
18/01/24 18:08:45 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:35342 (size: 8.8 KB, free: 365.3 MB)
18/01/24 18:08:45 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:996
18/01/24 18:08:45 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 75 (MapPartitionsRDD[246] at collect at utils.scala:211)
18/01/24 18:08:45 INFO TaskSchedulerImpl: Adding task set 75.0 with 6 tasks
18/01/24 18:08:45 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:45 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 173, localhost, executor driver, partition 1, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:45 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 174, localhost, executor driver, partition 2, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:45 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 175, localhost, executor driver, partition 3, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:45 INFO Executor: Running task 1.0 in stage 75.0 (TID 173)
18/01/24 18:08:45 INFO Executor: Running task 0.0 in stage 75.0 (TID 172)
18/01/24 18:08:45 INFO Executor: Running task 3.0 in stage 75.0 (TID 175)
18/01/24 18:08:45 INFO Executor: Running task 2.0 in stage 75.0 (TID 174)
18/01/24 18:08:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:08:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:08:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:08:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:08:45 ERROR Executor: Exception in task 0.0 in stage 75.0 (TID 172)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 16 more
18/01/24 18:08:45 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 176, localhost, executor driver, partition 4, PROCESS_LOCAL, 6586 bytes)
18/01/24 18:08:45 INFO Executor: Running task 4.0 in stage 75.0 (TID 176)
18/01/24 18:08:45 WARN TaskSetManager: Lost task 0.0 in stage 75.0 (TID 172, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 16 more

18/01/24 18:08:45 ERROR TaskSetManager: Task 0 in stage 75.0 failed 1 times; aborting job
18/01/24 18:08:45 INFO TaskSchedulerImpl: Cancelling stage 75
18/01/24 18:08:45 INFO TaskSchedulerImpl: Stage 75 was cancelled
18/01/24 18:08:45 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:211) failed in 0.662 s due to Job aborted due to stage failure: Task 0 in stage 75.0 failed 1 times, most recent failure: Lost task 0.0 in stage 75.0 (TID 172, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$1: (double) => double)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:826)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Feature value 2346.0 out of Bucketizer bounds [0.0, 2300.0].  Check your features, or loosen the lower/upper bound constraints.
	at org.apache.spark.ml.feature.Bucketizer$.binarySearchForBuckets(Bucketizer.scala:201)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply$mcDD$sp(Bucketizer.scala:116)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	at org.apache.spark.ml.feature.Bucketizer$$anonfun$1.apply(Bucketizer.scala:115)
	... 16 more

Driver stacktrace:
18/01/24 18:08:45 INFO Executor: Executor is trying to kill task 4.0 in stage 75.0 (TID 176)
18/01/24 18:08:45 INFO Executor: Executor is trying to kill task 1.0 in stage 75.0 (TID 173)
18/01/24 18:08:45 INFO Executor: Executor is trying to kill task 2.0 in stage 75.0 (TID 174)
18/01/24 18:08:45 INFO Executor: Executor is trying to kill task 3.0 in stage 75.0 (TID 175)
18/01/24 18:08:45 INFO DAGScheduler: Job 55 failed: collect at utils.scala:211, took 0.665024 s
18/01/24 18:08:45 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:08:50 INFO Executor: Executor killed task 3.0 in stage 75.0 (TID 175)
18/01/24 18:08:50 WARN TaskSetManager: Lost task 3.0 in stage 75.0 (TID 175, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:50 INFO Executor: Executor killed task 2.0 in stage 75.0 (TID 174)
18/01/24 18:08:50 WARN TaskSetManager: Lost task 2.0 in stage 75.0 (TID 174, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:50 INFO Executor: Executor killed task 1.0 in stage 75.0 (TID 173)
18/01/24 18:08:50 WARN TaskSetManager: Lost task 1.0 in stage 75.0 (TID 173, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:51 INFO Executor: Executor killed task 4.0 in stage 75.0 (TID 176)
18/01/24 18:08:51 WARN TaskSetManager: Lost task 4.0 in stage 75.0 (TID 176, localhost, executor driver): TaskKilled (killed intentionally)
18/01/24 18:08:51 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
18/01/24 18:16:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:08 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `sum(prediction)`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:08 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `sum(prediction)`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:08 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `sum(prediction)`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:08 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `sum(prediction)`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:08 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `sum(prediction)`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:08 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `sum(prediction)`
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 18:16:08 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:16:08 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:16:08 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:16:08 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:16:08 INFO CodeGenerator: Code generated in 3.967375 ms
18/01/24 18:16:08 INFO CodeGenerator: Code generated in 14.278475 ms
18/01/24 18:16:08 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 282.1 KB, free 356.1 MB)
18/01/24 18:16:08 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 23.9 KB, free 356.1 MB)
18/01/24 18:16:08 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.2 MB)
18/01/24 18:16:08 INFO SparkContext: Created broadcast 121 from collect at utils.scala:211
18/01/24 18:16:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:16:08 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:16:08 INFO DAGScheduler: Registering RDD 249 (collect at utils.scala:211)
18/01/24 18:16:08 INFO DAGScheduler: Got job 56 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:16:08 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:211)
18/01/24 18:16:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
18/01/24 18:16:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 76)
18/01/24 18:16:08 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[249] at collect at utils.scala:211), which has no missing parents
18/01/24 18:16:08 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 35.5 KB, free 356.1 MB)
18/01/24 18:16:08 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 15.6 KB, free 356.0 MB)
18/01/24 18:16:08 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:35342 (size: 15.6 KB, free: 365.2 MB)
18/01/24 18:16:08 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:996
18/01/24 18:16:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[249] at collect at utils.scala:211)
18/01/24 18:16:08 INFO TaskSchedulerImpl: Adding task set 76.0 with 6 tasks
18/01/24 18:16:08 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:08 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 178, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:08 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 179, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:08 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 180, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:08 INFO Executor: Running task 0.0 in stage 76.0 (TID 177)
18/01/24 18:16:08 INFO Executor: Running task 1.0 in stage 76.0 (TID 178)
18/01/24 18:16:08 INFO Executor: Running task 2.0 in stage 76.0 (TID 179)
18/01/24 18:16:08 INFO Executor: Running task 3.0 in stage 76.0 (TID 180)
18/01/24 18:16:08 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:16:08 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:16:08 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:16:08 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 6232
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:35342 in memory (size: 8.8 KB, free: 365.2 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:35342 in memory (size: 8.8 KB, free: 365.2 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:35342 in memory (size: 17.3 KB, free: 365.2 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 5777
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:35342 in memory (size: 16.5 KB, free: 365.3 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 5618
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:35342 in memory (size: 27.0 KB, free: 365.3 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:35342 in memory (size: 22.6 KB, free: 365.3 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 5407
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:35342 in memory (size: 22.6 KB, free: 365.3 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:35342 in memory (size: 22.6 KB, free: 365.4 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:35342 in memory (size: 22.6 KB, free: 365.4 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 4826
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:35342 in memory (size: 22.3 KB, free: 365.4 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.4 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.4 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 4362
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:35342 in memory (size: 18.3 KB, free: 365.4 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:35342 in memory (size: 7.1 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 4131
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 3900
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:35342 in memory (size: 23.1 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 3669
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:35342 in memory (size: 6.1 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:35342 in memory (size: 14.9 KB, free: 365.5 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 3446
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:35342 in memory (size: 23.3 KB, free: 365.6 MB)
18/01/24 18:16:09 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:35342 in memory (size: 15.0 KB, free: 365.6 MB)
18/01/24 18:16:09 INFO ContextCleaner: Cleaned accumulator 3215
18/01/24 18:16:15 INFO Executor: Finished task 3.0 in stage 76.0 (TID 180). 2101 bytes result sent to driver
18/01/24 18:16:15 INFO TaskSetManager: Starting task 4.0 in stage 76.0 (TID 181, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:15 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 180) in 6206 ms on localhost (executor driver) (1/6)
18/01/24 18:16:15 INFO Executor: Running task 4.0 in stage 76.0 (TID 181)
18/01/24 18:16:15 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:16:15 INFO Executor: Finished task 1.0 in stage 76.0 (TID 178). 2101 bytes result sent to driver
18/01/24 18:16:15 INFO TaskSetManager: Starting task 5.0 in stage 76.0 (TID 182, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:15 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 178) in 6230 ms on localhost (executor driver) (2/6)
18/01/24 18:16:15 INFO Executor: Running task 5.0 in stage 76.0 (TID 182)
18/01/24 18:16:15 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 18:16:15 INFO Executor: Finished task 0.0 in stage 76.0 (TID 177). 2101 bytes result sent to driver
18/01/24 18:16:15 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 177) in 6656 ms on localhost (executor driver) (3/6)
18/01/24 18:16:15 INFO Executor: Finished task 2.0 in stage 76.0 (TID 179). 2101 bytes result sent to driver
18/01/24 18:16:15 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 179) in 6756 ms on localhost (executor driver) (4/6)
18/01/24 18:16:15 INFO Executor: Finished task 5.0 in stage 76.0 (TID 182). 2101 bytes result sent to driver
18/01/24 18:16:15 INFO TaskSetManager: Finished task 5.0 in stage 76.0 (TID 182) in 697 ms on localhost (executor driver) (5/6)
18/01/24 18:16:18 INFO Executor: Finished task 4.0 in stage 76.0 (TID 181). 2101 bytes result sent to driver
18/01/24 18:16:18 INFO TaskSetManager: Finished task 4.0 in stage 76.0 (TID 181) in 3142 ms on localhost (executor driver) (6/6)
18/01/24 18:16:18 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
18/01/24 18:16:18 INFO DAGScheduler: ShuffleMapStage 76 (collect at utils.scala:211) finished in 9.344 s
18/01/24 18:16:18 INFO DAGScheduler: looking for newly runnable stages
18/01/24 18:16:18 INFO DAGScheduler: running: Set()
18/01/24 18:16:18 INFO DAGScheduler: waiting: Set(ResultStage 77)
18/01/24 18:16:18 INFO DAGScheduler: failed: Set()
18/01/24 18:16:18 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[252] at collect at utils.scala:211), which has no missing parents
18/01/24 18:16:18 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 7.5 KB, free 357.3 MB)
18/01/24 18:16:18 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 4.0 KB, free 357.3 MB)
18/01/24 18:16:18 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:35342 (size: 4.0 KB, free: 365.6 MB)
18/01/24 18:16:18 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:996
18/01/24 18:16:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[252] at collect at utils.scala:211)
18/01/24 18:16:18 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
18/01/24 18:16:18 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 183, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 18:16:18 INFO Executor: Running task 0.0 in stage 77.0 (TID 183)
18/01/24 18:16:18 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 18:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 18:16:18 INFO Executor: Finished task 0.0 in stage 77.0 (TID 183). 2013 bytes result sent to driver
18/01/24 18:16:18 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 183) in 5 ms on localhost (executor driver) (1/1)
18/01/24 18:16:18 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
18/01/24 18:16:18 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:211) finished in 0.005 s
18/01/24 18:16:18 INFO DAGScheduler: Job 56 finished: collect at utils.scala:211, took 9.355271 s
18/01/24 18:16:18 INFO CodeGenerator: Code generated in 5.387173 ms
18/01/24 18:16:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:38 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:38 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:38 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:38 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:38 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_6104260f968e`
18/01/24 18:16:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 18:16:38 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_6104260f968e`
LIMIT 1000
18/01/24 18:16:38 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 18:16:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 18:16:38 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 18:16:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 18:16:38 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 282.1 KB, free 357.0 MB)
18/01/24 18:16:38 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 23.9 KB, free 357.0 MB)
18/01/24 18:16:38 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 365.6 MB)
18/01/24 18:16:38 INFO SparkContext: Created broadcast 124 from collect at utils.scala:211
18/01/24 18:16:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 18:16:38 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 18:16:38 INFO DAGScheduler: Registering RDD 255 (collect at utils.scala:211)
18/01/24 18:16:38 INFO DAGScheduler: Got job 57 (collect at utils.scala:211) with 1 output partitions
18/01/24 18:16:38 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:211)
18/01/24 18:16:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
18/01/24 18:16:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
18/01/24 18:16:38 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[255] at collect at utils.scala:211), which has no missing parents
18/01/24 18:16:38 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 35.5 KB, free 356.9 MB)
18/01/24 18:16:38 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 15.6 KB, free 356.9 MB)
18/01/24 18:16:38 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:35342 (size: 15.6 KB, free: 365.5 MB)
18/01/24 18:16:38 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:996
18/01/24 18:16:38 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[255] at collect at utils.scala:211)
18/01/24 18:16:38 INFO TaskSchedulerImpl: Adding task set 78.0 with 6 tasks
18/01/24 18:16:38 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 184, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:38 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 185, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:38 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 186, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:38 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 187, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:38 INFO Executor: Running task 0.0 in stage 78.0 (TID 184)
18/01/24 18:16:38 INFO Executor: Running task 2.0 in stage 78.0 (TID 186)
18/01/24 18:16:38 INFO Executor: Running task 1.0 in stage 78.0 (TID 185)
18/01/24 18:16:38 INFO Executor: Running task 3.0 in stage 78.0 (TID 187)
18/01/24 18:16:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 18:16:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 18:16:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 18:16:38 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 18:16:38 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:35342 in memory (size: 4.0 KB, free: 365.5 MB)
18/01/24 18:16:44 INFO Executor: Finished task 3.0 in stage 78.0 (TID 187). 2101 bytes result sent to driver
18/01/24 18:16:44 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 188, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:44 INFO Executor: Running task 4.0 in stage 78.0 (TID 188)
18/01/24 18:16:44 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 187) in 5647 ms on localhost (executor driver) (1/6)
18/01/24 18:16:44 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 18:16:44 INFO Executor: Finished task 2.0 in stage 78.0 (TID 186). 2101 bytes result sent to driver
18/01/24 18:16:44 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 189, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 18:16:44 INFO Executor: Running task 5.0 in stage 78.0 (TID 189)
18/01/24 18:16:44 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 186) in 5676 ms on localhost (executor driver) (2/6)
18/01/24 18:16:44 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 18:16:44 INFO Executor: Finished task 0.0 in stage 78.0 (TID 184). 2101 bytes result sent to driver
18/01/24 18:16:44 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 184) in 5856 ms on localhost (executor driver) (3/6)
18/01/24 18:16:44 INFO Executor: Finished task 1.0 in stage 78.0 (TID 185). 2101 bytes result sent to driver
18/01/24 18:16:44 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 185) in 5883 ms on localhost (executor driver) (4/6)
18/01/24 18:16:44 INFO Executor: Finished task 5.0 in stage 78.0 (TID 189). 2101 bytes result sent to driver
18/01/24 18:16:44 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 189) in 508 ms on localhost (executor driver) (5/6)
18/01/24 18:16:47 INFO Executor: Finished task 4.0 in stage 78.0 (TID 188). 2101 bytes result sent to driver
18/01/24 18:16:47 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 188) in 2988 ms on localhost (executor driver) (6/6)
18/01/24 18:16:47 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
18/01/24 18:16:47 INFO DAGScheduler: ShuffleMapStage 78 (collect at utils.scala:211) finished in 8.636 s
18/01/24 18:16:47 INFO DAGScheduler: looking for newly runnable stages
18/01/24 18:16:47 INFO DAGScheduler: running: Set()
18/01/24 18:16:47 INFO DAGScheduler: waiting: Set(ResultStage 79)
18/01/24 18:16:47 INFO DAGScheduler: failed: Set()
18/01/24 18:16:47 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[258] at collect at utils.scala:211), which has no missing parents
18/01/24 18:16:47 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 7.5 KB, free 356.9 MB)
18/01/24 18:16:47 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 4.0 KB, free 356.9 MB)
18/01/24 18:16:47 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:35342 (size: 4.0 KB, free: 365.5 MB)
18/01/24 18:16:47 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:996
18/01/24 18:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[258] at collect at utils.scala:211)
18/01/24 18:16:47 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
18/01/24 18:16:47 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 190, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 18:16:47 INFO Executor: Running task 0.0 in stage 79.0 (TID 190)
18/01/24 18:16:47 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 18:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 18:16:47 INFO Executor: Finished task 0.0 in stage 79.0 (TID 190). 1926 bytes result sent to driver
18/01/24 18:16:47 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 190) in 2 ms on localhost (executor driver) (1/1)
18/01/24 18:16:47 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
18/01/24 18:16:47 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:211) finished in 0.003 s
18/01/24 18:16:47 INFO DAGScheduler: Job 57 finished: collect at utils.scala:211, took 8.646092 s
18/01/24 18:22:38 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:35342 in memory (size: 15.6 KB, free: 365.6 MB)
18/01/24 18:22:38 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:35342 in memory (size: 4.0 KB, free: 365.6 MB)
18/01/24 18:22:38 INFO ContextCleaner: Cleaned accumulator 6463
18/01/24 18:22:38 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:35342 in memory (size: 15.6 KB, free: 365.6 MB)
18/01/24 19:24:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 19:24:50 INFO HiveMetaStore: 0: get_database: default
18/01/24 19:24:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 19:24:50 INFO HiveMetaStore: 0: get_database: default
18/01/24 19:24:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 19:24:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 19:24:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 19:24:50 INFO SparkContext: Starting job: collect at utils.scala:58
18/01/24 19:24:50 INFO DAGScheduler: Got job 58 (collect at utils.scala:58) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:58)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[264] at map at utils.scala:55), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 8.7 KB, free 357.0 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 4.6 KB, free 357.0 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:35342 (size: 4.6 KB, free: 365.6 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[264] at map at utils.scala:55)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 191, localhost, executor driver, partition 0, PROCESS_LOCAL, 8224 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 80.0 (TID 191)
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 80.0 (TID 191). 1967 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 191) in 24 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:58) finished in 0.023 s
18/01/24 19:24:50 INFO DAGScheduler: Job 58 finished: collect at utils.scala:58, took 0.030893 s
18/01/24 19:24:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 19:24:50 INFO HiveMetaStore: 0: get_database: default
18/01/24 19:24:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 19:24:50 INFO HiveMetaStore: 0: get_database: default
18/01/24 19:24:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 19:24:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 19:24:50 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 19:24:50 INFO SparkSqlParser: Parsing command: flights
18/01/24 19:24:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz46`
WHERE (0 = 1)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 237.3 KB, free 356.8 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 23.1 KB, free 356.8 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.6 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 128 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 59 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 81 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 81 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata MapPartitionsRDD[268] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 3.3 KB, free 356.8 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 1996.0 B, free 356.8 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:35342 (size: 1996.0 B, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata MapPartitionsRDD[268] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 192, localhost, executor driver, partition 0, PROCESS_LOCAL, 6089 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 81.0 (TID 192)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/metadata/part-00000:0+294
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 81.0 (TID 192). 1384 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 192) in 14 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 81 (first at ReadWrite.scala:379) finished in 0.014 s
18/01/24 19:24:50 INFO DAGScheduler: Job 59 finished: first at ReadWrite.scala:379, took 0.016845 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 237.3 KB, free 356.5 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 23.1 KB, free 356.5 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 130 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 60 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 82 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 82 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[270] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 3.3 KB, free 356.5 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 2040.0 B, free 356.5 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:35342 (size: 2040.0 B, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[270] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 6128 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 82.0 (TID 193)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 82.0 (TID 193). 2362 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 193) in 4 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 82 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:50 INFO DAGScheduler: Job 60 finished: first at ReadWrite.scala:379, took 0.007527 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 237.3 KB, free 356.3 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 23.1 KB, free 356.3 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 132 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 61 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 83 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 83 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[272] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 3.3 KB, free 356.2 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 2031.0 B, free 356.2 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:35342 (size: 2031.0 B, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[272] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 6128 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 83.0 (TID 194)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 83.0 (TID 194). 2283 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 194) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 83 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 19:24:50 INFO DAGScheduler: Job 61 finished: first at ReadWrite.scala:379, took 0.006201 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 237.3 KB, free 356.0 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 23.1 KB, free 356.0 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 134 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 62 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 84 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 84 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[274] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 3.3 KB, free 356.0 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 2028.0 B, free 356.0 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:35342 (size: 2028.0 B, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[274] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 195, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 84.0 (TID 195)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 84.0 (TID 195). 1294 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 195) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 84 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:50 INFO DAGScheduler: Job 62 finished: first at ReadWrite.scala:379, took 0.005996 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 237.3 KB, free 355.8 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 23.1 KB, free 355.7 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 136 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 63 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 85 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 85 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[276] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 3.3 KB, free 355.7 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 2028.0 B, free 355.7 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:35342 (size: 2028.0 B, free: 365.5 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[276] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 85.0 (TID 196)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 85.0 (TID 196). 1294 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 196) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 85 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 19:24:50 INFO DAGScheduler: Job 63 finished: first at ReadWrite.scala:379, took 0.005557 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 237.3 KB, free 355.5 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 23.1 KB, free 355.5 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 138 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 64 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 86 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 86 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[278] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 3.3 KB, free 355.5 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 2029.0 B, free 355.5 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:35342 (size: 2029.0 B, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[278] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 197, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 86.0 (TID 197)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 86.0 (TID 197). 1359 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 197) in 2 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 86 (first at ReadWrite.scala:379) finished in 0.002 s
18/01/24 19:24:50 INFO DAGScheduler: Job 64 finished: first at ReadWrite.scala:379, took 0.004778 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 237.3 KB, free 355.2 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 23.1 KB, free 355.2 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 140 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 65 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 87 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 87 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[280] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 3.3 KB, free 355.2 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 2029.0 B, free 355.2 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:35342 (size: 2029.0 B, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[280] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 198, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 87.0 (TID 198)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 87.0 (TID 198). 1359 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 198) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 87 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:50 INFO DAGScheduler: Job 65 finished: first at ReadWrite.scala:379, took 0.005154 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 237.3 KB, free 355.0 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 23.1 KB, free 355.0 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 142 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 66 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 88 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 88 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[282] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 3.3 KB, free 355.0 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 2028.0 B, free 355.0 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:35342 (size: 2028.0 B, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[282] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 88.0 (TID 199)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 88.0 (TID 199). 1278 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 199) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 88 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:50 INFO DAGScheduler: Job 66 finished: first at ReadWrite.scala:379, took 0.006793 s
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 237.3 KB, free 354.7 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 23.1 KB, free 354.7 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 144 from textFile at ReadWrite.scala:379
18/01/24 19:24:50 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:50 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:50 INFO DAGScheduler: Got job 67 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 89 (first at ReadWrite.scala:379)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 89 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[284] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 3.3 KB, free 354.7 MB)
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 2028.0 B, free 354.7 MB)
18/01/24 19:24:50 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:35342 (size: 2028.0 B, free: 365.4 MB)
18/01/24 19:24:50 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[284] at textFile at ReadWrite.scala:379)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
18/01/24 19:24:50 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 6121 bytes)
18/01/24 19:24:50 INFO Executor: Running task 0.0 in stage 89.0 (TID 200)
18/01/24 19:24:50 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 19:24:50 INFO Executor: Finished task 0.0 in stage 89.0 (TID 200). 1191 bytes result sent to driver
18/01/24 19:24:50 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 200) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:50 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
18/01/24 19:24:50 INFO DAGScheduler: ResultStage 89 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 19:24:50 INFO DAGScheduler: Job 67 finished: first at ReadWrite.scala:379, took 0.004968 s
18/01/24 19:24:50 INFO SparkContext: Starting job: parquet at RFormula.scala:341
18/01/24 19:24:50 INFO DAGScheduler: Got job 68 (parquet at RFormula.scala:341) with 1 output partitions
18/01/24 19:24:50 INFO DAGScheduler: Final stage: ResultStage 90 (parquet at RFormula.scala:341)
18/01/24 19:24:50 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:50 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:50 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[286] at parquet at RFormula.scala:341), which has no missing parents
18/01/24 19:24:50 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 70.7 KB, free 354.6 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 25.3 KB, free 354.6 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[286] at parquet at RFormula.scala:341)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 6278 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 90.0 (TID 201)
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 90.0 (TID 201). 1990 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 201) in 16 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 90 (parquet at RFormula.scala:341) finished in 0.016 s
18/01/24 19:24:51 INFO DAGScheduler: Job 68 finished: parquet at RFormula.scala:341, took 0.026075 s
18/01/24 19:24:51 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 19:24:51 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 19:24:51 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
18/01/24 19:24:51 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 283.6 KB, free 354.3 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 24.5 KB, free 354.3 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:35342 (size: 24.5 KB, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 147 from head at RFormula.scala:341
18/01/24 19:24:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 19:24:51 INFO SparkContext: Starting job: head at RFormula.scala:341
18/01/24 19:24:51 INFO DAGScheduler: Got job 69 (head at RFormula.scala:341) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 91 (head at RFormula.scala:341)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[289] at head at RFormula.scala:341), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 9.8 KB, free 354.3 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 4.7 KB, free 354.3 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:35342 (size: 4.7 KB, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[289] at head at RFormula.scala:341)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 202, localhost, executor driver, partition 0, PROCESS_LOCAL, 6621 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 91.0 (TID 202)
18/01/24 19:24:51 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/data/part-00000-4c76e860-8b4c-4e35-8244-61bdf47c8710.snappy.parquet, range: 0-946, partition values: [empty row]
18/01/24 19:24:51 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 91.0 (TID 202). 1512 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 202) in 9 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 91 (head at RFormula.scala:341) finished in 0.010 s
18/01/24 19:24:51 INFO DAGScheduler: Job 69 finished: head at RFormula.scala:341, took 0.015736 s
18/01/24 19:24:51 INFO CodeGenerator: Code generated in 14.954016 ms
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 237.3 KB, free 354.1 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 23.1 KB, free 354.0 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 149 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 70 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 92 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 92 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[291] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 3.3 KB, free 354.0 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 2041.0 B, free 354.0 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:35342 (size: 2041.0 B, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[291] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 6135 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 92.0 (TID 203)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata/part-00000:0+240
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 92.0 (TID 203). 1243 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 203) in 2 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 92 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 19:24:51 INFO DAGScheduler: Job 70 finished: first at ReadWrite.scala:379, took 0.005311 s
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 237.3 KB, free 353.8 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 23.1 KB, free 353.8 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 151 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 71 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 93 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 93 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[293] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 3.4 KB, free 353.8 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 2045.0 B, free 353.8 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:35342 (size: 2045.0 B, free: 365.3 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[293] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 6168 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 93.0 (TID 204)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 93.0 (TID 204). 1297 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 204) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 93 (first at ReadWrite.scala:379) finished in 0.003 s
18/01/24 19:24:51 INFO DAGScheduler: Job 71 finished: first at ReadWrite.scala:379, took 0.004943 s
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 237.3 KB, free 353.5 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 23.1 KB, free 353.5 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 153 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 72 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 94 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 94 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[295] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 3.4 KB, free 353.5 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 2045.0 B, free 353.5 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:35342 (size: 2045.0 B, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[295] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 6168 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 94.0 (TID 205)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 94.0 (TID 205). 1297 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 205) in 4 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 94 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:51 INFO DAGScheduler: Job 72 finished: first at ReadWrite.scala:379, took 0.007036 s
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 237.3 KB, free 353.3 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 23.1 KB, free 353.3 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 155 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 73 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 95 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 95 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[297] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 3.4 KB, free 353.2 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 2.0 KB, free 353.2 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[297] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 6180 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 95.0 (TID 206)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 95.0 (TID 206). 1254 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 206) in 5 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 95 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 19:24:51 INFO DAGScheduler: Job 73 finished: first at ReadWrite.scala:379, took 0.009475 s
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 237.3 KB, free 353.0 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 23.1 KB, free 353.0 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 157 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 74 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 96 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 96 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[299] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 3.4 KB, free 353.0 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 2.0 KB, free 353.0 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[299] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 6180 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 96.0 (TID 207)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 96.0 (TID 207). 1254 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 207) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 96 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:51 INFO DAGScheduler: Job 74 finished: first at ReadWrite.scala:379, took 0.007274 s
18/01/24 19:24:51 INFO SparkContext: Starting job: parquet at RFormula.scala:503
18/01/24 19:24:51 INFO DAGScheduler: Got job 75 (parquet at RFormula.scala:503) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 97 (parquet at RFormula.scala:503)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[301] at parquet at RFormula.scala:503), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 70.7 KB, free 352.9 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 25.3 KB, free 352.9 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 365.2 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[301] at parquet at RFormula.scala:503)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 6333 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 97.0 (TID 208)
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 97.0 (TID 208). 1837 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 208) in 10 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 97 (parquet at RFormula.scala:503) finished in 0.010 s
18/01/24 19:24:51 INFO DAGScheduler: Job 75 finished: parquet at RFormula.scala:503, took 0.019129 s
18/01/24 19:24:51 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 19:24:51 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 19:24:51 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
18/01/24 19:24:51 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 283.3 KB, free 352.6 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 24.4 KB, free 352.6 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:35342 (size: 24.4 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 160 from head at RFormula.scala:503
18/01/24 19:24:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 19:24:51 INFO SparkContext: Starting job: head at RFormula.scala:503
18/01/24 19:24:51 INFO DAGScheduler: Got job 76 (head at RFormula.scala:503) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 98 (head at RFormula.scala:503)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[304] at head at RFormula.scala:503), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 10.3 KB, free 352.6 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 4.8 KB, free 352.6 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:35342 (size: 4.8 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[304] at head at RFormula.scala:503)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 98.0 (TID 209)
18/01/24 19:24:51 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/data/part-00000-46d12c43-4d60-4984-8900-332c8821b472.snappy.parquet, range: 0-812, partition values: [empty row]
18/01/24 19:24:51 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 98.0 (TID 209). 1457 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 209) in 7 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 98 (head at RFormula.scala:503) finished in 0.008 s
18/01/24 19:24:51 INFO DAGScheduler: Job 76 finished: head at RFormula.scala:503, took 0.010564 s
18/01/24 19:24:51 INFO CodeGenerator: Code generated in 12.19026 ms
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 237.3 KB, free 352.3 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 23.1 KB, free 352.3 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 162 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 77 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 99 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 99 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[306] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 3.4 KB, free 352.3 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 2.0 KB, free 352.3 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[306] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 6171 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 99.0 (TID 210)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 99.0 (TID 210). 1150 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 210) in 4 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 99 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 19:24:51 INFO DAGScheduler: Job 77 finished: first at ReadWrite.scala:379, took 0.006839 s
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 237.3 KB, free 352.1 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 23.1 KB, free 352.1 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 164 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 78 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 100 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 100 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[308] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 3.4 KB, free 352.1 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 2.0 KB, free 352.1 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:35342 (size: 2.0 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[308] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 6171 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 100.0 (TID 211)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 100.0 (TID 211). 1237 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 211) in 6 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 100 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 19:24:51 INFO DAGScheduler: Job 78 finished: first at ReadWrite.scala:379, took 0.010694 s
18/01/24 19:24:51 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:35342 in memory (size: 2.0 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Starting job: parquet at RFormula.scala:412
18/01/24 19:24:51 INFO DAGScheduler: Got job 79 (parquet at RFormula.scala:412) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 101 (parquet at RFormula.scala:412)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[310] at parquet at RFormula.scala:412), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 70.7 KB, free 352.0 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 25.3 KB, free 352.0 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 365.1 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[310] at parquet at RFormula.scala:412)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 6327 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 101.0 (TID 212)
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 101.0 (TID 212). 1773 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 212) in 8 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 101 (parquet at RFormula.scala:412) finished in 0.008 s
18/01/24 19:24:51 INFO DAGScheduler: Job 79 finished: parquet at RFormula.scala:412, took 0.023751 s
18/01/24 19:24:51 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 19:24:51 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 19:24:51 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
18/01/24 19:24:51 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 282.9 KB, free 351.7 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 24.4 KB, free 351.7 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:35342 (size: 24.4 KB, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 167 from head at RFormula.scala:412
18/01/24 19:24:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 19:24:51 INFO SparkContext: Starting job: head at RFormula.scala:412
18/01/24 19:24:51 INFO DAGScheduler: Got job 80 (head at RFormula.scala:412) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 102 (head at RFormula.scala:412)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[313] at head at RFormula.scala:412), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 8.2 KB, free 351.7 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 4.3 KB, free 351.7 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:35342 (size: 4.3 KB, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[313] at head at RFormula.scala:412)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 102.0 (TID 213)
18/01/24 19:24:51 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/data/part-00000-593de674-2fd9-48f5-b311-77492e49101f.snappy.parquet, range: 0-461, partition values: [empty row]
18/01/24 19:24:51 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 102.0 (TID 213). 1441 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 213) in 5 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 102 (head at RFormula.scala:412) finished in 0.006 s
18/01/24 19:24:51 INFO DAGScheduler: Job 80 finished: head at RFormula.scala:412, took 0.009353 s
18/01/24 19:24:51 INFO CodeGenerator: Code generated in 9.489248 ms
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 237.3 KB, free 351.4 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 23.1 KB, free 351.4 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 169 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 81 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 103 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 103 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[315] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 3.3 KB, free 351.4 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 2038.0 B, free 351.4 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:35342 (size: 2038.0 B, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[315] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 6131 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 103.0 (TID 214)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 103.0 (TID 214). 1563 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 214) in 4 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 103 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:51 INFO DAGScheduler: Job 81 finished: first at ReadWrite.scala:379, took 0.007097 s
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 237.3 KB, free 351.2 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 23.1 KB, free 351.1 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:35342 (size: 23.1 KB, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 171 from textFile at ReadWrite.scala:379
18/01/24 19:24:51 INFO FileInputFormat: Total input paths to process : 1
18/01/24 19:24:51 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 19:24:51 INFO DAGScheduler: Got job 82 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 104 (first at ReadWrite.scala:379)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 104 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[317] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 3.3 KB, free 351.1 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 2038.0 B, free 351.1 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:35342 (size: 2038.0 B, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[317] at textFile at ReadWrite.scala:379)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 215, localhost, executor driver, partition 0, PROCESS_LOCAL, 6131 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 104.0 (TID 215)
18/01/24 19:24:51 INFO HadoopRDD: Input split: file:/home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 104.0 (TID 215). 1484 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 215) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 104 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 19:24:51 INFO DAGScheduler: Job 82 finished: first at ReadWrite.scala:379, took 0.006550 s
18/01/24 19:24:51 INFO SparkContext: Starting job: load at LogisticRegression.scala:979
18/01/24 19:24:51 INFO DAGScheduler: Got job 83 (load at LogisticRegression.scala:979) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 105 (load at LogisticRegression.scala:979)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[319] at load at LogisticRegression.scala:979), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 70.7 KB, free 351.1 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 25.3 KB, free 351.0 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:35342 (size: 25.3 KB, free: 365.0 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[319] at load at LogisticRegression.scala:979)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 216, localhost, executor driver, partition 0, PROCESS_LOCAL, 6288 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 105.0 (TID 216)
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 105.0 (TID 216). 2159 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 216) in 12 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 105 (load at LogisticRegression.scala:979) finished in 0.006 s
18/01/24 19:24:51 INFO DAGScheduler: Job 83 finished: load at LogisticRegression.scala:979, took 0.022630 s
18/01/24 19:24:51 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 19:24:51 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 19:24:51 INFO FileSourceStrategy: Output Data Schema: struct<numClasses: int, numFeatures: int, interceptVector: vector, coefficientMatrix: matrix, isMultinomial: boolean ... 3 more fields>
18/01/24 19:24:51 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 288.7 KB, free 350.8 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 25.0 KB, free 350.7 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:35342 (size: 25.0 KB, free: 364.9 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 174 from head at LogisticRegression.scala:997
18/01/24 19:24:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 19:24:51 INFO SparkContext: Starting job: head at LogisticRegression.scala:997
18/01/24 19:24:51 INFO DAGScheduler: Got job 84 (head at LogisticRegression.scala:997) with 1 output partitions
18/01/24 19:24:51 INFO DAGScheduler: Final stage: ResultStage 106 (head at LogisticRegression.scala:997)
18/01/24 19:24:51 INFO DAGScheduler: Parents of final stage: List()
18/01/24 19:24:51 INFO DAGScheduler: Missing parents: List()
18/01/24 19:24:51 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[322] at head at LogisticRegression.scala:997), which has no missing parents
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 17.3 KB, free 350.7 MB)
18/01/24 19:24:51 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 6.2 KB, free 350.7 MB)
18/01/24 19:24:51 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:35342 (size: 6.2 KB, free: 364.9 MB)
18/01/24 19:24:51 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[322] at head at LogisticRegression.scala:997)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
18/01/24 19:24:51 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 6631 bytes)
18/01/24 19:24:51 INFO Executor: Running task 0.0 in stage 106.0 (TID 217)
18/01/24 19:24:51 INFO FileScanRDD: Reading File path: file:///home/rstudio-user/bigdataclass2018/workbook/saved_model/stages/4_logistic_regression_610474782d95/data/part-00000-d0beedf9-5461-4cb8-8867-676902a6c5f5.snappy.parquet, range: 0-3705, partition values: [empty row]
18/01/24 19:24:51 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

Catalyst form:
StructType(StructField(numClasses,IntegerType,true), StructField(numFeatures,IntegerType,true), StructField(interceptVector,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(coefficientMatrix,org.apache.spark.ml.linalg.MatrixUDT@e59e0c69,true), StructField(isMultinomial,BooleanType,true))
       
18/01/24 19:24:51 INFO Executor: Finished task 0.0 in stage 106.0 (TID 217). 1526 bytes result sent to driver
18/01/24 19:24:51 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 217) in 20 ms on localhost (executor driver) (1/1)
18/01/24 19:24:51 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
18/01/24 19:24:51 INFO DAGScheduler: ResultStage 106 (head at LogisticRegression.scala:997) finished in 0.021 s
18/01/24 19:24:51 INFO DAGScheduler: Job 84 finished: head at LogisticRegression.scala:997, took 0.026362 s
18/01/24 19:24:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 19:24:52 INFO HiveMetaStore: 0: get_database: default
18/01/24 19:24:52 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 19:24:52 INFO HiveMetaStore: 0: get_database: default
18/01/24 19:24:52 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 19:24:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 19:24:52 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 19:24:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz47`
WHERE (0 = 1)
18/01/24 19:24:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
18/01/24 19:24:55 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_0d22473ec81f
18/01/24 19:24:55 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_0d22473ec81f`) `qibeoammfo`) `qkyoruvxll`
18/01/24 19:24:55 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_79376584d7ca
18/01/24 19:24:55 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_79376584d7ca`) `qibeoammfo`) `qkyoruvxll`
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_4c9d87cd3f84
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_4c9d87cd3f84`) `qibeoammfo`) `qkyoruvxll`
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_61043bf483a2
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_61043bf483a2` AS `zzz48`
WHERE (0 = 1)
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_61043bf483a2`
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_61043bf483a2`
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_61043bf483a2`
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_61043bf483a2`
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_61043bf483a2`
18/01/24 19:24:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 19:24:56 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_61043bf483a2`
LIMIT 1000
18/01/24 19:24:56 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 19:24:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#3811),isnotnull(dayofmonth#3812),(cast(month#3811 as double) = 1.0),(cast(dayofmonth#3812 as double) = 24.0)
18/01/24 19:24:56 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 19:24:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 19:24:56 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 282.1 KB, free 350.4 MB)
18/01/24 19:24:56 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 23.9 KB, free 350.4 MB)
18/01/24 19:24:56 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:35342 (size: 23.9 KB, free: 364.9 MB)
18/01/24 19:24:56 INFO SparkContext: Created broadcast 176 from collect at utils.scala:211
18/01/24 19:24:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 19:24:56 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 19:24:56 INFO DAGScheduler: Registering RDD 334 (collect at utils.scala:211)
18/01/24 19:24:56 INFO DAGScheduler: Got job 85 (collect at utils.scala:211) with 1 output partitions
18/01/24 19:24:56 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:211)
18/01/24 19:24:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
18/01/24 19:24:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 107)
18/01/24 19:24:56 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[334] at collect at utils.scala:211), which has no missing parents
18/01/24 19:24:56 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 35.5 KB, free 350.4 MB)
18/01/24 19:24:56 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 15.6 KB, free 350.4 MB)
18/01/24 19:24:56 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:35342 (size: 15.6 KB, free: 364.9 MB)
18/01/24 19:24:56 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:996
18/01/24 19:24:56 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[334] at collect at utils.scala:211)
18/01/24 19:24:56 INFO TaskSchedulerImpl: Adding task set 107.0 with 6 tasks
18/01/24 19:24:56 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 6489 bytes)
18/01/24 19:24:56 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 219, localhost, executor driver, partition 1, PROCESS_LOCAL, 6489 bytes)
18/01/24 19:24:56 INFO TaskSetManager: Starting task 2.0 in stage 107.0 (TID 220, localhost, executor driver, partition 2, PROCESS_LOCAL, 6489 bytes)
18/01/24 19:24:56 INFO TaskSetManager: Starting task 3.0 in stage 107.0 (TID 221, localhost, executor driver, partition 3, PROCESS_LOCAL, 6489 bytes)
18/01/24 19:24:56 INFO Executor: Running task 0.0 in stage 107.0 (TID 218)
18/01/24 19:24:56 INFO Executor: Running task 1.0 in stage 107.0 (TID 219)
18/01/24 19:24:56 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 19:24:56 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 19:24:56 INFO Executor: Running task 2.0 in stage 107.0 (TID 220)
18/01/24 19:24:56 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 19:24:57 INFO Executor: Running task 3.0 in stage 107.0 (TID 221)
18/01/24 19:24:57 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 19:25:02 INFO Executor: Finished task 2.0 in stage 107.0 (TID 220). 2101 bytes result sent to driver
18/01/24 19:25:02 INFO TaskSetManager: Starting task 4.0 in stage 107.0 (TID 222, localhost, executor driver, partition 4, PROCESS_LOCAL, 6489 bytes)
18/01/24 19:25:02 INFO TaskSetManager: Finished task 2.0 in stage 107.0 (TID 220) in 5900 ms on localhost (executor driver) (1/6)
18/01/24 19:25:02 INFO Executor: Running task 4.0 in stage 107.0 (TID 222)
18/01/24 19:25:02 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 19:25:02 INFO Executor: Finished task 3.0 in stage 107.0 (TID 221). 2101 bytes result sent to driver
18/01/24 19:25:02 INFO TaskSetManager: Starting task 5.0 in stage 107.0 (TID 223, localhost, executor driver, partition 5, PROCESS_LOCAL, 6489 bytes)
18/01/24 19:25:02 INFO Executor: Running task 5.0 in stage 107.0 (TID 223)
18/01/24 19:25:02 INFO TaskSetManager: Finished task 3.0 in stage 107.0 (TID 221) in 6007 ms on localhost (executor driver) (2/6)
18/01/24 19:25:03 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 19:25:03 INFO Executor: Finished task 0.0 in stage 107.0 (TID 218). 2101 bytes result sent to driver
18/01/24 19:25:03 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 218) in 6099 ms on localhost (executor driver) (3/6)
18/01/24 19:25:03 INFO Executor: Finished task 1.0 in stage 107.0 (TID 219). 2101 bytes result sent to driver
18/01/24 19:25:03 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 219) in 6142 ms on localhost (executor driver) (4/6)
18/01/24 19:25:03 INFO Executor: Finished task 5.0 in stage 107.0 (TID 223). 2101 bytes result sent to driver
18/01/24 19:25:03 INFO TaskSetManager: Finished task 5.0 in stage 107.0 (TID 223) in 504 ms on localhost (executor driver) (5/6)
18/01/24 19:25:05 INFO Executor: Finished task 4.0 in stage 107.0 (TID 222). 2101 bytes result sent to driver
18/01/24 19:25:05 INFO TaskSetManager: Finished task 4.0 in stage 107.0 (TID 222) in 2979 ms on localhost (executor driver) (6/6)
18/01/24 19:25:05 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
18/01/24 19:25:05 INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:211) finished in 8.879 s
18/01/24 19:25:05 INFO DAGScheduler: looking for newly runnable stages
18/01/24 19:25:05 INFO DAGScheduler: running: Set()
18/01/24 19:25:05 INFO DAGScheduler: waiting: Set(ResultStage 108)
18/01/24 19:25:05 INFO DAGScheduler: failed: Set()
18/01/24 19:25:05 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[337] at collect at utils.scala:211), which has no missing parents
18/01/24 19:25:05 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 7.5 KB, free 350.4 MB)
18/01/24 19:25:05 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 4.0 KB, free 350.4 MB)
18/01/24 19:25:05 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:35342 (size: 4.0 KB, free: 364.9 MB)
18/01/24 19:25:05 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:996
18/01/24 19:25:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[337] at collect at utils.scala:211)
18/01/24 19:25:05 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
18/01/24 19:25:05 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 224, localhost, executor driver, partition 0, ANY, 5861 bytes)
18/01/24 19:25:05 INFO Executor: Running task 0.0 in stage 108.0 (TID 224)
18/01/24 19:25:05 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 19:25:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/01/24 19:25:05 INFO Executor: Finished task 0.0 in stage 108.0 (TID 224). 1934 bytes result sent to driver
18/01/24 19:25:05 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 224) in 3 ms on localhost (executor driver) (1/1)
18/01/24 19:25:05 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
18/01/24 19:25:05 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:211) finished in 0.003 s
18/01/24 19:25:05 INFO DAGScheduler: Job 85 finished: collect at utils.scala:211, took 8.893548 s
18/01/24 19:29:00 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:35342 in memory (size: 4.0 KB, free: 364.9 MB)
18/01/24 19:41:12 INFO SparkContext: Invoking stop() from shutdown hook
18/01/24 19:41:12 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/01/24 19:41:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/01/24 19:41:12 INFO MemoryStore: MemoryStore cleared
18/01/24 19:41:12 INFO BlockManager: BlockManager stopped
18/01/24 19:41:12 INFO BlockManagerMaster: BlockManagerMaster stopped
18/01/24 19:41:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/01/24 19:41:12 INFO SparkContext: Successfully stopped SparkContext
18/01/24 19:41:12 INFO ShutdownHookManager: Shutdown hook called
18/01/24 19:41:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-08719dfc-f250-4193-8d4e-25a19a913ad7
18/01/24 21:59:04 INFO SparkContext: Running Spark version 2.1.0
18/01/24 21:59:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/01/24 21:59:04 INFO SecurityManager: Changing view acls to: rstudio-user
18/01/24 21:59:04 INFO SecurityManager: Changing modify acls to: rstudio-user
18/01/24 21:59:04 INFO SecurityManager: Changing view acls groups to: 
18/01/24 21:59:04 INFO SecurityManager: Changing modify acls groups to: 
18/01/24 21:59:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rstudio-user); groups with view permissions: Set(); users  with modify permissions: Set(rstudio-user); groups with modify permissions: Set()
18/01/24 21:59:04 INFO Utils: Successfully started service 'sparkDriver' on port 45923.
18/01/24 21:59:04 INFO SparkEnv: Registering MapOutputTracker
18/01/24 21:59:04 INFO SparkEnv: Registering BlockManagerMaster
18/01/24 21:59:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/01/24 21:59:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/01/24 21:59:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-582019d9-66d9-4196-a3ba-14f2bf5adec4
18/01/24 21:59:04 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/01/24 21:59:04 INFO SparkEnv: Registering OutputCommitCoordinator
18/01/24 21:59:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/01/24 21:59:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/01/24 21:59:04 INFO SparkContext: Added JAR file:/home/rstudio-user/R/x86_64-pc-linux-gnu-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:45923/jars/sparklyr-2.1-2.11.jar with timestamp 1516831144967
18/01/24 21:59:05 INFO Executor: Starting executor ID driver on host localhost
18/01/24 21:59:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46104.
18/01/24 21:59:05 INFO NettyBlockTransferService: Server created on 127.0.0.1:46104
18/01/24 21:59:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/01/24 21:59:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 46104, None)
18/01/24 21:59:05 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:46104 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 46104, None)
18/01/24 21:59:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 46104, None)
18/01/24 21:59:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 46104, None)
18/01/24 21:59:07 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/01/24 21:59:07 INFO SharedState: Warehouse path is 'file:/home/rstudio-user/bigdataclass2018/workbook/spark-warehouse'.
18/01/24 21:59:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
18/01/24 21:59:08 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/01/24 21:59:08 INFO ObjectStore: ObjectStore, initialize called
18/01/24 21:59:08 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/01/24 21:59:08 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
18/01/24 21:59:09 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
18/01/24 21:59:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 21:59:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 21:59:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 21:59:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 21:59:11 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
18/01/24 21:59:11 INFO ObjectStore: Initialized ObjectStore
18/01/24 21:59:11 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
18/01/24 21:59:11 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
18/01/24 21:59:11 INFO HiveMetaStore: Added admin role in metastore
18/01/24 21:59:11 INFO HiveMetaStore: Added public role in metastore
18/01/24 21:59:12 INFO HiveMetaStore: No user is added in admin role, since config is empty
18/01/24 21:59:12 INFO HiveMetaStore: 0: get_all_databases
18/01/24 21:59:12 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_all_databases	
18/01/24 21:59:12 INFO HiveMetaStore: 0: get_functions: db=default pat=*
18/01/24 21:59:12 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
18/01/24 21:59:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
18/01/24 21:59:12 INFO SessionState: Created local directory: /tmp/9e7e419d-55f9-4353-ba1b-0f9c5047fc1b_resources
18/01/24 21:59:12 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio-user/9e7e419d-55f9-4353-ba1b-0f9c5047fc1b
18/01/24 21:59:12 INFO SessionState: Created local directory: /tmp/rstudio-user/9e7e419d-55f9-4353-ba1b-0f9c5047fc1b
18/01/24 21:59:12 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio-user/9e7e419d-55f9-4353-ba1b-0f9c5047fc1b/_tmp_space.db
18/01/24 21:59:12 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/rstudio-user/bigdataclass2018/workbook/spark-warehouse
18/01/24 21:59:12 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:12 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:12 INFO HiveMetaStore: 0: get_database: global_temp
18/01/24 21:59:12 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: global_temp	
18/01/24 21:59:12 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
18/01/24 21:59:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 21:59:15 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:15 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:15 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:15 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 21:59:15 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 21:59:16 INFO CodeGenerator: Code generated in 231.273274 ms
18/01/24 21:59:16 INFO SparkContext: Starting job: collect at utils.scala:58
18/01/24 21:59:16 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
18/01/24 21:59:16 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
18/01/24 21:59:16 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:16 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
18/01/24 21:59:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
18/01/24 21:59:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
18/01/24 21:59:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:46104 (size: 4.6 KB, free: 366.3 MB)
18/01/24 21:59:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
18/01/24 21:59:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
18/01/24 21:59:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
18/01/24 21:59:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/01/24 21:59:16 INFO Executor: Fetching spark://127.0.0.1:45923/jars/sparklyr-2.1-2.11.jar with timestamp 1516831144967
18/01/24 21:59:16 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:45923 after 9 ms (0 ms spent in bootstraps)
18/01/24 21:59:16 INFO Utils: Fetching spark://127.0.0.1:45923/jars/sparklyr-2.1-2.11.jar to /tmp/spark-76ba0636-7990-48a5-99a9-44bc3f230d50/userFiles-82a8dd19-26d2-4092-b6a0-98bc629ec7b9/fetchFileTemp7366502557739500403.tmp
18/01/24 21:59:16 INFO Executor: Adding file:/tmp/spark-76ba0636-7990-48a5-99a9-44bc3f230d50/userFiles-82a8dd19-26d2-4092-b6a0-98bc629ec7b9/sparklyr-2.1-2.11.jar to class loader
18/01/24 21:59:16 INFO CodeGenerator: Code generated in 18.425959 ms
18/01/24 21:59:16 INFO CodeGenerator: Code generated in 13.458516 ms
18/01/24 21:59:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
18/01/24 21:59:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 243 ms on localhost (executor driver) (1/1)
18/01/24 21:59:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/01/24 21:59:16 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.263 s
18/01/24 21:59:16 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.404756 s
18/01/24 21:59:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 21:59:19 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:19 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:19 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:19 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 21:59:19 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 21:59:19 INFO SparkSqlParser: Parsing command: flights
18/01/24 21:59:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz1`
WHERE (0 = 1)
18/01/24 21:59:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 21:59:19 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:19 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:19 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:19 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 21:59:19 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 21:59:20 INFO CodeGenerator: Code generated in 22.275612 ms
18/01/24 21:59:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
18/01/24 21:59:20 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:20 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:20 INFO HiveMetaStore: 0: get_database: default
18/01/24 21:59:20 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_database: default	
18/01/24 21:59:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
18/01/24 21:59:20 INFO audit: ugi=rstudio-user	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
18/01/24 21:59:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 237.2 KB, free 366.1 MB)
18/01/24 21:59:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB)
18/01/24 21:59:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.3 MB)
18/01/24 21:59:20 INFO SparkContext: Created broadcast 1 from textFile at ReadWrite.scala:379
18/01/24 21:59:20 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:46104 in memory (size: 4.6 KB, free: 366.3 MB)
18/01/24 21:59:20 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:20 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:20 INFO DAGScheduler: Got job 1 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:20 INFO DAGScheduler: Final stage: ResultStage 1 (first at ReadWrite.scala:379)
18/01/24 21:59:20 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:20 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:20 INFO DAGScheduler: Submitting ResultStage 1 (/tmp/saved_model/metadata MapPartitionsRDD[11] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.2 KB, free 366.0 MB)
18/01/24 21:59:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1958.0 B, free 366.0 MB)
18/01/24 21:59:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:46104 (size: 1958.0 B, free: 366.3 MB)
18/01/24 21:59:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (/tmp/saved_model/metadata MapPartitionsRDD[11] at textFile at ReadWrite.scala:379)
18/01/24 21:59:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
18/01/24 21:59:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6048 bytes)
18/01/24 21:59:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
18/01/24 21:59:20 INFO HadoopRDD: Input split: file:/tmp/saved_model/metadata/part-00000:0+294
18/01/24 21:59:20 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/01/24 21:59:20 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/01/24 21:59:20 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/01/24 21:59:20 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/01/24 21:59:20 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/01/24 21:59:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1384 bytes result sent to driver
18/01/24 21:59:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on localhost (executor driver) (1/1)
18/01/24 21:59:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/01/24 21:59:20 INFO DAGScheduler: ResultStage 1 (first at ReadWrite.scala:379) finished in 0.042 s
18/01/24 21:59:20 INFO DAGScheduler: Job 1 finished: first at ReadWrite.scala:379, took 0.053984 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 237.3 KB, free 365.8 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.8 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.3 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 3 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 2 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 2 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 2 (/tmp/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[13] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 365.8 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1998.0 B, free 365.8 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:46104 (size: 1998.0 B, free: 366.3 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (/tmp/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[13] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6087 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2362 bytes result sent to driver
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 2 (first at ReadWrite.scala:379) finished in 0.010 s
18/01/24 21:59:21 INFO DAGScheduler: Job 2 finished: first at ReadWrite.scala:379, took 0.018097 s
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 10 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 237.3 KB, free 365.5 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.5 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 5 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 3 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 3 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 3 (/tmp/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[15] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.3 KB, free 365.5 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1998.0 B, free 365.5 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:46104 (size: 1998.0 B, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (/tmp/saved_model/stages/0_dplyr_transformer_610463a1360/metadata MapPartitionsRDD[15] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6087 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/0_dplyr_transformer_610463a1360/metadata/part-00000:0+1267
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2362 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 9 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 3 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 21:59:21 INFO DAGScheduler: Job 3 finished: first at ReadWrite.scala:379, took 0.013919 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 237.3 KB, free 365.3 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.3 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 7 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 4 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 4 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 4 (/tmp/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[17] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.3 KB, free 365.3 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1993.0 B, free 365.3 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:46104 (size: 1993.0 B, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (/tmp/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[17] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6080 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1294 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 4 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 21:59:21 INFO DAGScheduler: Job 4 finished: first at ReadWrite.scala:379, took 0.014932 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 237.3 KB, free 365.0 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.1 KB, free 365.0 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 9 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 5 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 5 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 5 (/tmp/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[19] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 3.3 KB, free 365.0 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1993.0 B, free 365.0 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:46104 (size: 1993.0 B, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (/tmp/saved_model/stages/1_binarizer_61041cbbcaf0/metadata MapPartitionsRDD[19] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6080 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/1_binarizer_61041cbbcaf0/metadata/part-00000:0+204
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1294 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 5 (first at ReadWrite.scala:379) finished in 0.008 s
18/01/24 21:59:21 INFO DAGScheduler: Job 5 finished: first at ReadWrite.scala:379, took 0.013493 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 237.3 KB, free 364.8 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.7 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 11 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 6 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 6 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 6 (/tmp/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[21] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.3 KB, free 364.7 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1999.0 B, free 364.7 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:46104 (size: 1999.0 B, free: 366.2 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (/tmp/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[21] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6080 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1359 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 6 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 21:59:21 INFO DAGScheduler: Job 6 finished: first at ReadWrite.scala:379, took 0.012136 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 237.3 KB, free 364.5 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.5 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 13 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 7 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 7 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 7 (/tmp/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[23] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 3.3 KB, free 364.5 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 1994.0 B, free 364.5 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:46104 (size: 1994.0 B, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (/tmp/saved_model/stages/2_bucketizer_61049871837/metadata MapPartitionsRDD[23] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6080 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/2_bucketizer_61049871837/metadata/part-00000:0+269
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1272 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 7 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 21:59:21 INFO DAGScheduler: Job 7 finished: first at ReadWrite.scala:379, took 0.010491 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 237.3 KB, free 364.3 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.2 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 15 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 8 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 8 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 8 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[25] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 3.3 KB, free 364.2 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1996.0 B, free 364.2 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:46104 (size: 1996.0 B, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[25] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6080 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1278 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 8 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 21:59:21 INFO DAGScheduler: Job 8 finished: first at ReadWrite.scala:379, took 0.011175 s
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 237.3 KB, free 364.0 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 23.1 KB, free 364.0 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 17 from textFile at ReadWrite.scala:379
18/01/24 21:59:21 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:21 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:21 INFO DAGScheduler: Got job 9 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 9 (first at ReadWrite.scala:379)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 9 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[27] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 3.3 KB, free 364.0 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1993.0 B, free 364.0 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:46104 (size: 1993.0 B, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/metadata MapPartitionsRDD[27] at textFile at ReadWrite.scala:379)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6080 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
18/01/24 21:59:21 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/metadata/part-00000:0+191
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1278 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 9 (first at ReadWrite.scala:379) finished in 0.007 s
18/01/24 21:59:21 INFO DAGScheduler: Job 9 finished: first at ReadWrite.scala:379, took 0.011345 s
18/01/24 21:59:21 INFO SparkContext: Starting job: parquet at RFormula.scala:341
18/01/24 21:59:21 INFO DAGScheduler: Got job 10 (parquet at RFormula.scala:341) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 10 (parquet at RFormula.scala:341)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[29] at parquet at RFormula.scala:341), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 70.7 KB, free 363.9 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.3 KB, free 363.9 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:46104 (size: 25.3 KB, free: 366.1 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[29] at parquet at RFormula.scala:341)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6237 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
18/01/24 21:59:21 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1990 bytes result sent to driver
18/01/24 21:59:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 96 ms on localhost (executor driver) (1/1)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/01/24 21:59:21 INFO DAGScheduler: ResultStage 10 (parquet at RFormula.scala:341) finished in 0.097 s
18/01/24 21:59:21 INFO DAGScheduler: Job 10 finished: parquet at RFormula.scala:341, took 0.117120 s
18/01/24 21:59:21 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 21:59:21 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 21:59:21 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
18/01/24 21:59:21 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 21:59:21 INFO CodeGenerator: Code generated in 17.077153 ms
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 283.6 KB, free 363.6 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.5 KB, free 363.6 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:46104 (size: 24.5 KB, free: 366.0 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 20 from head at RFormula.scala:341
18/01/24 21:59:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 21:59:21 INFO SparkContext: Starting job: head at RFormula.scala:341
18/01/24 21:59:21 INFO DAGScheduler: Got job 11 (head at RFormula.scala:341) with 1 output partitions
18/01/24 21:59:21 INFO DAGScheduler: Final stage: ResultStage 11 (head at RFormula.scala:341)
18/01/24 21:59:21 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:21 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:21 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[32] at head at RFormula.scala:341), which has no missing parents
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 9.8 KB, free 363.6 MB)
18/01/24 21:59:21 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.7 KB, free 363.6 MB)
18/01/24 21:59:21 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:46104 (size: 4.7 KB, free: 366.0 MB)
18/01/24 21:59:21 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[32] at head at RFormula.scala:341)
18/01/24 21:59:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
18/01/24 21:59:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6580 bytes)
18/01/24 21:59:21 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
18/01/24 21:59:21 INFO FileScanRDD: Reading File path: file:///tmp/saved_model/stages/3_r_formula_61046ea225dc/data/part-00000-4c76e860-8b4c-4e35-8244-61bdf47c8710.snappy.parquet, range: 0-946, partition values: [empty row]
18/01/24 21:59:21 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
18/01/24 21:59:21 INFO CodeGenerator: Code generated in 17.473802 ms
18/01/24 21:59:21 INFO CodecPool: Got brand-new decompressor [.snappy]
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1599 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 190 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 11 (head at RFormula.scala:341) finished in 0.179 s
18/01/24 21:59:22 INFO DAGScheduler: Job 11 finished: head at RFormula.scala:341, took 0.206218 s
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 22.65572 ms
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 237.3 KB, free 363.3 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.3 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.0 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 22 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 12 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 12 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 12 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[34] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 3.3 KB, free 363.3 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2003.0 B, free 363.3 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:46104 (size: 2003.0 B, free: 366.0 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata MapPartitionsRDD[34] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6094 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/metadata/part-00000:0+240
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1330 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 4 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 12 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 21:59:22 INFO DAGScheduler: Job 12 finished: first at ReadWrite.scala:379, took 0.012642 s
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 237.3 KB, free 363.1 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 23.1 KB, free 363.0 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.0 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 24 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 13 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 13 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 13 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[36] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.3 KB, free 363.0 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 2008.0 B, free 363.0 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:46104 (size: 2008.0 B, free: 366.0 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[36] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6126 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1297 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 13 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 21:59:22 INFO DAGScheduler: Job 13 finished: first at ReadWrite.scala:379, took 0.010617 s
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 237.3 KB, free 362.8 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.8 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 366.0 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 26 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 14 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 14 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 14 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[38] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 3.3 KB, free 362.8 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 2008.0 B, free 362.8 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:46104 (size: 2008.0 B, free: 366.0 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata MapPartitionsRDD[38] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6126 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/0_r_formula_61046ea225dc/metadata/part-00000:0+207
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1384 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 5 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 14 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 21:59:22 INFO DAGScheduler: Job 14 finished: first at ReadWrite.scala:379, took 0.036538 s
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 237.3 KB, free 362.5 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.5 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 28 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 15 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 15 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 15 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[40] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 3.3 KB, free 362.5 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2038.0 B, free 362.5 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:46104 (size: 2038.0 B, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[40] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6136 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1254 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 11 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 15 (first at ReadWrite.scala:379) finished in 0.011 s
18/01/24 21:59:22 INFO DAGScheduler: Job 15 finished: first at ReadWrite.scala:379, took 0.019714 s
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 237.3 KB, free 362.3 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 23.1 KB, free 362.3 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 30 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 16 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 16 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 16 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[42] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 3.3 KB, free 362.3 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 2039.0 B, free 362.3 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:46104 (size: 2039.0 B, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata MapPartitionsRDD[42] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6136 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/metadata/part-00000:0+167
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1254 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 16 (first at ReadWrite.scala:379) finished in 0.004 s
18/01/24 21:59:22 INFO DAGScheduler: Job 16 finished: first at ReadWrite.scala:379, took 0.011351 s
18/01/24 21:59:22 INFO SparkContext: Starting job: parquet at RFormula.scala:503
18/01/24 21:59:22 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:503) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:503)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[44] at parquet at RFormula.scala:503), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 70.7 KB, free 362.2 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 25.3 KB, free 362.2 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:46104 (size: 25.3 KB, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[44] at parquet at RFormula.scala:503)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6292 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1924 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 26 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:503) finished in 0.009 s
18/01/24 21:59:22 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:503, took 0.040759 s
18/01/24 21:59:22 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 21:59:22 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 21:59:22 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
18/01/24 21:59:22 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 48.391139 ms
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 283.3 KB, free 361.9 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 24.4 KB, free 361.9 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:46104 (size: 24.4 KB, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 33 from head at RFormula.scala:503
18/01/24 21:59:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 21:59:22 INFO SparkContext: Starting job: head at RFormula.scala:503
18/01/24 21:59:22 INFO DAGScheduler: Got job 18 (head at RFormula.scala:503) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 18 (head at RFormula.scala:503)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[47] at head at RFormula.scala:503), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 10.3 KB, free 361.9 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.8 KB, free 361.9 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:46104 (size: 4.8 KB, free: 365.9 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[47] at head at RFormula.scala:503)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6635 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
18/01/24 21:59:22 INFO FileScanRDD: Reading File path: file:///tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/1_vectorAttrRewriter_0d65c662ad16/data/part-00000-46d12c43-4d60-4984-8900-332c8821b472.snappy.parquet, range: 0-812, partition values: [empty row]
18/01/24 21:59:22 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 26.141836 ms
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1457 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 42 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 18 (head at RFormula.scala:503) finished in 0.044 s
18/01/24 21:59:22 INFO DAGScheduler: Job 18 finished: head at RFormula.scala:503, took 0.048231 s
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 26.646518 ms
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 237.3 KB, free 361.6 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.6 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 365.8 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 35 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 19 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 19 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 19 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[49] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 3.3 KB, free 361.6 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 2031.0 B, free 361.6 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:46104 (size: 2031.0 B, free: 365.8 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[49] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6129 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1237 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 9 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 19 (first at ReadWrite.scala:379) finished in 0.010 s
18/01/24 21:59:22 INFO DAGScheduler: Job 19 finished: first at ReadWrite.scala:379, took 0.013943 s
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 237.3 KB, free 361.4 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 23.1 KB, free 361.3 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 365.8 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 37 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 20 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 20 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 20 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[51] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 3.3 KB, free 361.3 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 2030.0 B, free 361.3 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:46104 (size: 2030.0 B, free: 365.8 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata MapPartitionsRDD[51] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6130 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/metadata/part-00000:0+150
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1237 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 5 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 20 (first at ReadWrite.scala:379) finished in 0.005 s
18/01/24 21:59:22 INFO DAGScheduler: Job 20 finished: first at ReadWrite.scala:379, took 0.009909 s
18/01/24 21:59:22 INFO SparkContext: Starting job: parquet at RFormula.scala:412
18/01/24 21:59:22 INFO DAGScheduler: Got job 21 (parquet at RFormula.scala:412) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 21 (parquet at RFormula.scala:412)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[53] at parquet at RFormula.scala:412), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 70.7 KB, free 361.3 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 25.3 KB, free 361.2 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:46104 (size: 25.3 KB, free: 365.8 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[53] at parquet at RFormula.scala:412)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6287 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1773 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 13 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 21 (parquet at RFormula.scala:412) finished in 0.010 s
18/01/24 21:59:22 INFO DAGScheduler: Job 21 finished: parquet at RFormula.scala:412, took 0.027556 s
18/01/24 21:59:22 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 21:59:22 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 21:59:22 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
18/01/24 21:59:22 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 21.16247 ms
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 282.9 KB, free 361.0 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.4 KB, free 360.9 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:46104 (size: 24.4 KB, free: 365.8 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 40 from head at RFormula.scala:412
18/01/24 21:59:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 21:59:22 INFO SparkContext: Starting job: head at RFormula.scala:412
18/01/24 21:59:22 INFO DAGScheduler: Got job 22 (head at RFormula.scala:412) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 22 (head at RFormula.scala:412)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[56] at head at RFormula.scala:412), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 8.2 KB, free 360.9 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.3 KB, free 360.9 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:46104 (size: 4.3 KB, free: 365.7 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[56] at head at RFormula.scala:412)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6629 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
18/01/24 21:59:22 INFO FileScanRDD: Reading File path: file:///tmp/saved_model/stages/3_r_formula_61046ea225dc/pipelineModel/stages/2_columnPruner_c7edfa4a6d54/data/part-00000-593de674-2fd9-48f5-b311-77492e49101f.snappy.parquet, range: 0-461, partition values: [empty row]
18/01/24 21:59:22 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 30.287627 ms
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1441 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 43 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 22 (head at RFormula.scala:412) finished in 0.031 s
18/01/24 21:59:22 INFO DAGScheduler: Job 22 finished: head at RFormula.scala:412, took 0.049928 s
18/01/24 21:59:22 INFO CodeGenerator: Code generated in 13.558629 ms
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 237.3 KB, free 360.7 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 23.1 KB, free 360.7 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 365.7 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 42 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:22 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:22 INFO DAGScheduler: Got job 23 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:22 INFO DAGScheduler: Final stage: ResultStage 23 (first at ReadWrite.scala:379)
18/01/24 21:59:22 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:22 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:22 INFO DAGScheduler: Submitting ResultStage 23 (/tmp/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[58] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 3.3 KB, free 360.7 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 2003.0 B, free 360.7 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:46104 (size: 2003.0 B, free: 365.7 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (/tmp/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[58] at textFile at ReadWrite.scala:379)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
18/01/24 21:59:22 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6091 bytes)
18/01/24 21:59:22 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
18/01/24 21:59:22 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 21:59:22 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1650 bytes result sent to driver
18/01/24 21:59:22 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 9 ms on localhost (executor driver) (1/1)
18/01/24 21:59:22 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
18/01/24 21:59:22 INFO DAGScheduler: ResultStage 23 (first at ReadWrite.scala:379) finished in 0.009 s
18/01/24 21:59:22 INFO DAGScheduler: Job 23 finished: first at ReadWrite.scala:379, took 0.013422 s
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 237.3 KB, free 360.4 MB)
18/01/24 21:59:22 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 23.1 KB, free 360.4 MB)
18/01/24 21:59:22 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:46104 (size: 23.1 KB, free: 365.7 MB)
18/01/24 21:59:22 INFO SparkContext: Created broadcast 44 from textFile at ReadWrite.scala:379
18/01/24 21:59:22 INFO FileInputFormat: Total input paths to process : 1
18/01/24 21:59:23 INFO SparkContext: Starting job: first at ReadWrite.scala:379
18/01/24 21:59:23 INFO DAGScheduler: Got job 24 (first at ReadWrite.scala:379) with 1 output partitions
18/01/24 21:59:23 INFO DAGScheduler: Final stage: ResultStage 24 (first at ReadWrite.scala:379)
18/01/24 21:59:23 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:23 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:23 INFO DAGScheduler: Submitting ResultStage 24 (/tmp/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[60] at textFile at ReadWrite.scala:379), which has no missing parents
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 3.3 KB, free 360.4 MB)
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 2003.0 B, free 360.4 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:46104 (size: 2003.0 B, free: 365.7 MB)
18/01/24 21:59:23 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (/tmp/saved_model/stages/4_logistic_regression_610474782d95/metadata MapPartitionsRDD[60] at textFile at ReadWrite.scala:379)
18/01/24 21:59:23 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
18/01/24 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6091 bytes)
18/01/24 21:59:23 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
18/01/24 21:59:23 INFO HadoopRDD: Input split: file:/tmp/saved_model/stages/4_logistic_regression_610474782d95/metadata/part-00000:0+473
18/01/24 21:59:23 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1563 bytes result sent to driver
18/01/24 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
18/01/24 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
18/01/24 21:59:23 INFO DAGScheduler: ResultStage 24 (first at ReadWrite.scala:379) finished in 0.006 s
18/01/24 21:59:23 INFO DAGScheduler: Job 24 finished: first at ReadWrite.scala:379, took 0.013565 s
18/01/24 21:59:23 INFO SparkContext: Starting job: load at LogisticRegression.scala:979
18/01/24 21:59:23 INFO DAGScheduler: Got job 25 (load at LogisticRegression.scala:979) with 1 output partitions
18/01/24 21:59:23 INFO DAGScheduler: Final stage: ResultStage 25 (load at LogisticRegression.scala:979)
18/01/24 21:59:23 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:23 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:23 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[62] at load at LogisticRegression.scala:979), which has no missing parents
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 70.7 KB, free 360.3 MB)
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 25.3 KB, free 360.3 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:46104 (size: 25.3 KB, free: 365.7 MB)
18/01/24 21:59:23 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[62] at load at LogisticRegression.scala:979)
18/01/24 21:59:23 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
18/01/24 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6248 bytes)
18/01/24 21:59:23 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
18/01/24 21:59:23 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2159 bytes result sent to driver
18/01/24 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 30 ms on localhost (executor driver) (1/1)
18/01/24 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
18/01/24 21:59:23 INFO DAGScheduler: ResultStage 25 (load at LogisticRegression.scala:979) finished in 0.030 s
18/01/24 21:59:23 INFO DAGScheduler: Job 25 finished: load at LogisticRegression.scala:979, took 0.048715 s
18/01/24 21:59:23 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 21:59:23 INFO FileSourceStrategy: Post-Scan Filters: 
18/01/24 21:59:23 INFO FileSourceStrategy: Output Data Schema: struct<numClasses: int, numFeatures: int, interceptVector: vector, coefficientMatrix: matrix, isMultinomial: boolean ... 3 more fields>
18/01/24 21:59:23 INFO FileSourceStrategy: Pushed Filters: 
18/01/24 21:59:23 INFO CodeGenerator: Code generated in 195.781387 ms
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 530
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 531
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 532
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:46104 in memory (size: 24.5 KB, free: 365.7 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:46104 in memory (size: 2008.0 B, free: 365.7 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 365.7 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:46104 in memory (size: 2008.0 B, free: 365.7 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:46104 in memory (size: 25.3 KB, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:46104 in memory (size: 1993.0 B, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:46104 in memory (size: 1996.0 B, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:46104 in memory (size: 1994.0 B, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 365.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:46104 in memory (size: 2038.0 B, free: 365.8 MB)
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 288.7 KB, free 361.7 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 365.9 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:46104 in memory (size: 2039.0 B, free: 365.9 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:46104 in memory (size: 25.3 KB, free: 365.9 MB)
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 869
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 870
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 871
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:46104 in memory (size: 24.4 KB, free: 365.9 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:46104 in memory (size: 25.3 KB, free: 365.9 MB)
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 1064
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 1065
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 1066
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:46104 in memory (size: 24.4 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:46104 in memory (size: 4.3 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 25.0 KB, free 362.8 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:46104 (size: 25.0 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:46104 in memory (size: 2003.0 B, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO SparkContext: Created broadcast 47 from head at LogisticRegression.scala:997
18/01/24 21:59:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:46104 in memory (size: 2003.0 B, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:46104 in memory (size: 25.3 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:46104 in memory (size: 4.8 KB, free: 366.0 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:46104 in memory (size: 2031.0 B, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:46104 in memory (size: 2030.0 B, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:46104 in memory (size: 1999.0 B, free: 366.1 MB)
18/01/24 21:59:23 INFO SparkContext: Starting job: head at LogisticRegression.scala:997
18/01/24 21:59:23 INFO DAGScheduler: Got job 26 (head at LogisticRegression.scala:997) with 1 output partitions
18/01/24 21:59:23 INFO DAGScheduler: Final stage: ResultStage 26 (head at LogisticRegression.scala:997)
18/01/24 21:59:23 INFO DAGScheduler: Parents of final stage: List()
18/01/24 21:59:23 INFO DAGScheduler: Missing parents: List()
18/01/24 21:59:23 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[65] at head at LogisticRegression.scala:997), which has no missing parents
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:46104 in memory (size: 1993.0 B, free: 366.1 MB)
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 17.3 KB, free 364.2 MB)
18/01/24 21:59:23 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 6.2 KB, free 364.2 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:46104 (size: 6.2 KB, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:23 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[65] at head at LogisticRegression.scala:997)
18/01/24 21:59:23 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:46104 in memory (size: 1993.0 B, free: 366.1 MB)
18/01/24 21:59:23 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6590 bytes)
18/01/24 21:59:23 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:46104 in memory (size: 1998.0 B, free: 366.1 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:23 INFO FileScanRDD: Reading File path: file:///tmp/saved_model/stages/4_logistic_regression_610474782d95/data/part-00000-d0beedf9-5461-4cb8-8867-676902a6c5f5.snappy.parquet, range: 0-3705, partition values: [empty row]
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:46104 in memory (size: 1998.0 B, free: 366.2 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:46104 in memory (size: 1958.0 B, free: 366.2 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 1
18/01/24 21:59:23 INFO ContextCleaner: Cleaned accumulator 0
18/01/24 21:59:23 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  required int32 numClasses;
  required int32 numFeatures;
  optional group interceptVector {
    required int32 type (INT_8);
    optional int32 size;
    optional group indices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
  }
  optional group coefficientMatrix {
    required int32 type (INT_8);
    required int32 numRows;
    required int32 numCols;
    optional group colPtrs (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group rowIndices (LIST) {
      repeated group list {
        required int32 element;
      }
    }
    optional group values (LIST) {
      repeated group list {
        required double element;
      }
    }
    required boolean isTransposed;
  }
  required boolean isMultinomial;
}

Catalyst form:
StructType(StructField(numClasses,IntegerType,true), StructField(numFeatures,IntegerType,true), StructField(interceptVector,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true), StructField(coefficientMatrix,org.apache.spark.ml.linalg.MatrixUDT@e59e0c69,true), StructField(isMultinomial,BooleanType,true))
       
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.2 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:46104 in memory (size: 2003.0 B, free: 366.2 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:46104 in memory (size: 23.1 KB, free: 366.3 MB)
18/01/24 21:59:23 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:46104 in memory (size: 4.7 KB, free: 366.3 MB)
18/01/24 21:59:23 INFO CodeGenerator: Code generated in 40.805807 ms
18/01/24 21:59:23 INFO CodeGenerator: Code generated in 15.873587 ms
18/01/24 21:59:23 INFO CodeGenerator: Code generated in 22.364578 ms
18/01/24 21:59:23 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1526 bytes result sent to driver
18/01/24 21:59:23 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 126 ms on localhost (executor driver) (1/1)
18/01/24 21:59:23 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
18/01/24 21:59:23 INFO DAGScheduler: ResultStage 26 (head at LogisticRegression.scala:997) finished in 0.122 s
18/01/24 21:59:23 INFO DAGScheduler: Job 26 finished: head at LogisticRegression.scala:997, took 0.133559 s
18/01/24 21:59:23 INFO CodeGenerator: Code generated in 11.259405 ms
18/01/24 21:59:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
18/01/24 21:59:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE ((`month` = 1.0) AND (`dayofmonth` = 24))
18/01/24 21:59:31 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_107909aba44d
18/01/24 21:59:31 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_107909aba44d`) `qibeoammfo`) `qkyoruvxll`
18/01/24 21:59:31 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_a45a95ad166c
18/01/24 21:59:31 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_a45a95ad166c`) `qibeoammfo`) `qkyoruvxll`
18/01/24 21:59:31 INFO SparkSqlParser: Parsing command: dplyr_transformer_610463a1360_aed971f744d6
18/01/24 21:59:31 INFO SparkSqlParser: Parsing command: SELECT CAST(`month` AS DOUBLE) AS `month`, CAST(`dayofmonth` AS DOUBLE) AS `dayofmonth`, CAST(`arrtime` AS DOUBLE) AS `arrtime`, CAST(`arrdelay` AS DOUBLE) AS `arrdelay`, CAST(`depdelay` AS DOUBLE) AS `depdelay`, CAST(`crsarrtime` AS DOUBLE) AS `crsarrtime`, CAST(`crsdeptime` AS DOUBLE) AS `crsdeptime`, CAST(`distance` AS DOUBLE) AS `distance`
FROM (SELECT `month`, `dayofmonth`, `arrtime`, `arrdelay`, `depdelay`, `crsarrtime`, `crsdeptime`, `distance`
FROM (SELECT `year`, `month`, `dayofmonth`, `dayofweek`, `deptime`, `crsdeptime`, `arrtime`, `crsarrtime`, `uniquecarrier`, `flightnum`, `tailnum`, `actualelapsedtime`, `crselapsedtime`, `airtime`, CASE WHEN (`arrdelay` = "NA") THEN (0.0) WHEN NOT(`arrdelay` = "NA") THEN (`arrdelay`) END AS `arrdelay`, CASE WHEN (`depdelay` = "NA") THEN (0.0) WHEN NOT(`depdelay` = "NA") THEN (`depdelay`) END AS `depdelay`, `origin`, `dest`, `distance`, `taxiin`, `taxiout`, `cancelled`, `cancellationcode`, `diverted`, `carrierdelay`, `weatherdelay`, `nasdelay`, `securitydelay`, `lateaircraftdelay`
FROM `dplyr_transformer_610463a1360_aed971f744d6`) `qibeoammfo`) `qkyoruvxll`
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_1a402bf4c997
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_1a402bf4c997` AS `zzz3`
WHERE (0 = 1)
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_1a402bf4c997`
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_1a402bf4c997`
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_1a402bf4c997`
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_1a402bf4c997`
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_1a402bf4c997`
18/01/24 21:59:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
18/01/24 21:59:32 INFO SparkSqlParser: Parsing command: SELECT SUM(`prediction`) AS `late_fligths`
FROM `sparklyr_tmp_1a402bf4c997`
LIMIT 1000
18/01/24 21:59:32 INFO FileSourceStrategy: Pruning directories with: 
18/01/24 21:59:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(month#11),isnotnull(dayofmonth#12),(cast(month#11 as double) = 1.0),(cast(dayofmonth#12 as double) = 24.0)
18/01/24 21:59:32 INFO FileSourceStrategy: Output Data Schema: struct<month: string, dayofmonth: string, crsdeptime: string, arrdelay: string ... 2 more fields>
18/01/24 21:59:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(month),IsNotNull(dayofmonth)
18/01/24 21:59:32 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
18/01/24 21:59:32 INFO CodeGenerator: Code generated in 7.186824 ms
18/01/24 21:59:32 INFO CodeGenerator: Code generated in 34.321093 ms
18/01/24 21:59:32 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 282.1 KB, free 365.7 MB)
18/01/24 21:59:32 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 23.9 KB, free 365.7 MB)
18/01/24 21:59:32 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:46104 (size: 23.9 KB, free: 366.2 MB)
18/01/24 21:59:32 INFO SparkContext: Created broadcast 49 from collect at utils.scala:211
18/01/24 21:59:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
18/01/24 21:59:32 INFO SparkContext: Starting job: collect at utils.scala:211
18/01/24 21:59:32 INFO DAGScheduler: Registering RDD 76 (collect at utils.scala:211)
18/01/24 21:59:32 INFO DAGScheduler: Got job 27 (collect at utils.scala:211) with 1 output partitions
18/01/24 21:59:32 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:211)
18/01/24 21:59:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
18/01/24 21:59:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
18/01/24 21:59:32 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[76] at collect at utils.scala:211), which has no missing parents
18/01/24 21:59:32 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 35.5 KB, free 365.6 MB)
18/01/24 21:59:32 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 15.6 KB, free 365.6 MB)
18/01/24 21:59:32 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:46104 (size: 15.6 KB, free: 366.2 MB)
18/01/24 21:59:32 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:32 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[76] at collect at utils.scala:211)
18/01/24 21:59:32 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks
18/01/24 21:59:32 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6488 bytes)
18/01/24 21:59:32 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 6488 bytes)
18/01/24 21:59:32 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 6488 bytes)
18/01/24 21:59:32 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 6488 bytes)
18/01/24 21:59:32 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
18/01/24 21:59:32 INFO Executor: Running task 1.0 in stage 27.0 (TID 28)
18/01/24 21:59:32 INFO Executor: Running task 2.0 in stage 27.0 (TID 29)
18/01/24 21:59:32 INFO Executor: Running task 3.0 in stage 27.0 (TID 30)
18/01/24 21:59:32 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 268435456-402653184, partition values: [empty row]
18/01/24 21:59:32 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 134217728-268435456, partition values: [empty row]
18/01/24 21:59:32 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 0-134217728, partition values: [empty row]
18/01/24 21:59:32 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 402653184-536870912, partition values: [empty row]
18/01/24 21:59:32 INFO CodeGenerator: Code generated in 16.298537 ms
18/01/24 21:59:33 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:46104 in memory (size: 6.2 KB, free: 366.2 MB)
18/01/24 21:59:33 INFO ContextCleaner: Cleaned accumulator 1310
18/01/24 21:59:34 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/01/24 21:59:34 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/01/24 21:59:40 INFO Executor: Finished task 2.0 in stage 27.0 (TID 29). 2188 bytes result sent to driver
18/01/24 21:59:40 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 31, localhost, executor driver, partition 4, PROCESS_LOCAL, 6488 bytes)
18/01/24 21:59:40 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 29) in 7498 ms on localhost (executor driver) (1/6)
18/01/24 21:59:40 INFO Executor: Running task 4.0 in stage 27.0 (TID 31)
18/01/24 21:59:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 536870912-671088640, partition values: [empty row]
18/01/24 21:59:40 INFO Executor: Finished task 1.0 in stage 27.0 (TID 28). 2101 bytes result sent to driver
18/01/24 21:59:40 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 32, localhost, executor driver, partition 5, PROCESS_LOCAL, 6488 bytes)
18/01/24 21:59:40 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 28) in 7594 ms on localhost (executor driver) (2/6)
18/01/24 21:59:40 INFO Executor: Running task 5.0 in stage 27.0 (TID 32)
18/01/24 21:59:40 INFO FileScanRDD: Reading File path: file:///usr/share/flights/flights_2008.csv, range: 671088640-689413344, partition values: [empty row]
18/01/24 21:59:40 INFO Executor: Finished task 3.0 in stage 27.0 (TID 30). 2101 bytes result sent to driver
18/01/24 21:59:40 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 30) in 8012 ms on localhost (executor driver) (3/6)
18/01/24 21:59:41 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 2101 bytes result sent to driver
18/01/24 21:59:41 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 8454 ms on localhost (executor driver) (4/6)
18/01/24 21:59:41 INFO Executor: Finished task 5.0 in stage 27.0 (TID 32). 2101 bytes result sent to driver
18/01/24 21:59:41 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 32) in 971 ms on localhost (executor driver) (5/6)
18/01/24 21:59:43 INFO Executor: Finished task 4.0 in stage 27.0 (TID 31). 2101 bytes result sent to driver
18/01/24 21:59:43 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 31) in 3555 ms on localhost (executor driver) (6/6)
18/01/24 21:59:43 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
18/01/24 21:59:43 INFO DAGScheduler: ShuffleMapStage 27 (collect at utils.scala:211) finished in 11.054 s
18/01/24 21:59:43 INFO DAGScheduler: looking for newly runnable stages
18/01/24 21:59:43 INFO DAGScheduler: running: Set()
18/01/24 21:59:43 INFO DAGScheduler: waiting: Set(ResultStage 28)
18/01/24 21:59:43 INFO DAGScheduler: failed: Set()
18/01/24 21:59:44 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[79] at collect at utils.scala:211), which has no missing parents
18/01/24 21:59:44 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 7.5 KB, free 365.6 MB)
18/01/24 21:59:44 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 4.0 KB, free 365.6 MB)
18/01/24 21:59:44 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:46104 (size: 4.0 KB, free: 366.2 MB)
18/01/24 21:59:44 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
18/01/24 21:59:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[79] at collect at utils.scala:211)
18/01/24 21:59:44 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
18/01/24 21:59:44 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 33, localhost, executor driver, partition 0, ANY, 5860 bytes)
18/01/24 21:59:44 INFO Executor: Running task 0.0 in stage 28.0 (TID 33)
18/01/24 21:59:44 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 6 blocks
18/01/24 21:59:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/01/24 21:59:44 INFO Executor: Finished task 0.0 in stage 28.0 (TID 33). 2013 bytes result sent to driver
18/01/24 21:59:44 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 33) in 28 ms on localhost (executor driver) (1/1)
18/01/24 21:59:44 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
18/01/24 21:59:44 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:211) finished in 0.028 s
18/01/24 21:59:44 INFO DAGScheduler: Job 27 finished: collect at utils.scala:211, took 11.138209 s
18/01/24 21:59:44 INFO CodeGenerator: Code generated in 5.443121 ms
18/01/24 21:59:44 INFO SparkContext: Invoking stop() from shutdown hook
18/01/24 21:59:44 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/01/24 21:59:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/01/24 21:59:44 INFO MemoryStore: MemoryStore cleared
18/01/24 21:59:44 INFO BlockManager: BlockManager stopped
18/01/24 21:59:44 INFO BlockManagerMaster: BlockManagerMaster stopped
18/01/24 21:59:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/01/24 21:59:44 INFO SparkContext: Successfully stopped SparkContext
18/01/24 21:59:44 INFO ShutdownHookManager: Shutdown hook called
18/01/24 21:59:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-76ba0636-7990-48a5-99a9-44bc3f230d50
