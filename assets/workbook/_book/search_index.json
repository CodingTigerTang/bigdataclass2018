[
["index.html", "Big Data with R - Exercise book", " Big Data with R - Exercise book Learn how to use R with Hive, SQL Server, Oracle and other scalable external data sources along with Big Data clusters in this two-day workshop. We will cover how to connect, retrieve schema information, upload data, and explore data outside of R. For databases, we will focus on the dplyr, DBI and odbc packages. These packages enable us to use the same dplyr verbs inside R but are translated and sent as SQL queries. For Big Data clusters, we will also learn how to use the sparklyr package to run models inside Spark and return the results to R. We will review recommendations for connection settings, security best practices and deployment options. Throughout the workshop, we will take advantage of the new data connections available with the RStudio IDE. "],
["access-a-database.html", "1 Access a database 1.1 Connect to a database 1.2 Explore the database using the RStudio IDE 1.3 List drivers and DSNs 1.4 Connect to a database using code 1.5 Connect to a database without a DSN 1.6 Secure credentials in a file 1.7 Environment variables 1.8 Use options()", " 1 Access a database 1.1 Connect to a database The simpliest way to connect to a database. More complex examples will be examined later in the class. Click on the Connections tab Click on the New Connection button Select Postgres Dev Click OK 1.2 Explore the database using the RStudio IDE Becoming familiar with the new interface for databases inside the RStudio IDE Expand the datawarehouse schema Expand the airport table Click on the table icon to the right of the airport table (Optional) Expand and explore the other tables Click on the disconnect icon to close the connection 1.3 List drivers and DSNs Learn how to use the odbc package to get DB info from your machine To get a list of drivers available in the server library(odbc) odbcListDrivers()[1:2] ## name attribute ## 1 PostgreSQL ANSI Description ## 2 PostgreSQL ANSI Driver ## 3 PostgreSQL ANSI Setup ## 4 PostgreSQL ANSI Debug ## 5 PostgreSQL ANSI CommLog ## 6 PostgreSQL ANSI UsageCount ## 7 PostgreSQL Unicode Description ## 8 PostgreSQL Unicode Driver ## 9 PostgreSQL Unicode Setup ## 10 PostgreSQL Unicode Debug ## 11 PostgreSQL Unicode CommLog ## 12 PostgreSQL Unicode UsageCount ## 13 AmazonRedshift Driver ## 14 Hive Driver ## 15 Impala Driver ## 16 Oracle Driver ## 17 PostgreSQL Driver ## 18 Salesforce Driver ## 19 SQLServer Driver ## 20 Teradata Driver Click on the ellipsis button located in the Files tab Type: /etc Locate and open the odbcinst.ini file To see a list of DSNs available in the server odbcListDataSources() ## name description ## 1 Postgres Dev PostgreSQL ## 2 Postgres Prod PostgreSQL Using the ellipsis button again, navigate to /etc/odbc.ini 1.4 Connect to a database using code Use the odbc package along with DBI to open a connection to a database Run the following code to connect library(DBI) con &lt;- dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) Use dbListTables() to retrieve a list of tables dbListTables(con) ## [1] &quot;airport&quot; &quot;carrier&quot; &quot;flight&quot; &quot;vflight&quot; Use dbGetQuery() to run a quick query odbc::dbGetQuery(con, &quot;SELECT * FROM datawarehouse.airport LIMIT 10&quot;) ## airport airportname city state country ## 1 ABE Lehigh Valley International Allentown PA USA ## 2 ABI Abilene Regional Abilene TX USA ## 3 ABQ Albuquerque International Albuquerque NM USA ## 4 ABY Southwest Georgia Regional Albany GA USA ## 5 ACK Nantucket Memorial Nantucket MA USA ## 6 ACT Waco Regional Waco TX USA ## 7 ACV Arcata Arcata/Eureka CA USA ## 8 ACY Atlantic City International Atlantic City NJ USA ## 9 ADK Adak Adak AK USA ## 10 ADQ Kodiak Kodiak AK USA ## lat long ## 1 40.65236 -75.44040 ## 2 32.41132 -99.68190 ## 3 35.04022 -106.60919 ## 4 31.53552 -84.19447 ## 5 41.25305 -70.06018 ## 6 31.61129 -97.23052 ## 7 40.97812 -124.10862 ## 8 39.45758 -74.57717 ## 9 51.87796 -176.64603 ## 10 57.74997 -152.49386 Use the SQL chunk SELECT * FROM datawarehouse.airport LIMIT 10 Table 1.1: Displaying records 1 - 10 airport airportname city state country lat long ABE Lehigh Valley International Allentown PA USA 40.65236 -75.44040 ABI Abilene Regional Abilene TX USA 32.41132 -99.68190 ABQ Albuquerque International Albuquerque NM USA 35.04022 -106.60919 ABY Southwest Georgia Regional Albany GA USA 31.53552 -84.19447 ACK Nantucket Memorial Nantucket MA USA 41.25305 -70.06018 ACT Waco Regional Waco TX USA 31.61129 -97.23052 ACV Arcata Arcata/Eureka CA USA 40.97812 -124.10862 ACY Atlantic City International Atlantic City NJ USA 39.45758 -74.57717 ADK Adak Adak AK USA 51.87796 -176.64603 ADQ Kodiak Kodiak AK USA 57.74997 -152.49386 Use the output.var option to load results to a variable SELECT * FROM datawarehouse.airport LIMIT 10 Test the variable sql_top10 ## airport airportname city state country ## 1 ABE Lehigh Valley International Allentown PA USA ## 2 ABI Abilene Regional Abilene TX USA ## 3 ABQ Albuquerque International Albuquerque NM USA ## 4 ABY Southwest Georgia Regional Albany GA USA ## 5 ACK Nantucket Memorial Nantucket MA USA ## 6 ACT Waco Regional Waco TX USA ## 7 ACV Arcata Arcata/Eureka CA USA ## 8 ACY Atlantic City International Atlantic City NJ USA ## 9 ADK Adak Adak AK USA ## 10 ADQ Kodiak Kodiak AK USA ## lat long ## 1 40.65236 -75.44040 ## 2 32.41132 -99.68190 ## 3 35.04022 -106.60919 ## 4 31.53552 -84.19447 ## 5 41.25305 -70.06018 ## 6 31.61129 -97.23052 ## 7 40.97812 -124.10862 ## 8 39.45758 -74.57717 ## 9 51.87796 -176.64603 ## 10 57.74997 -152.49386 Disconnect from the database using dbDisconnect() dbDisconnect(con) 1.5 Connect to a database without a DSN A more complex way of connecting to a database, using best practices: http://db.rstudio.com/best-practices/managing-credentials/#prompt-for-credentials Use the following code to start a new connection that does not use the pre-defined DSN con &lt;- dbConnect( odbc::odbc(), Driver = &quot;PostgreSQL&quot;, Server = &quot;localhost&quot;, UID = rstudioapi::askForPassword(&quot;Database user&quot;), PWD = rstudioapi::askForPassword(&quot;Database password&quot;), Port = 5432, Database = &quot;postgres&quot; ) When prompted, type in rstudio_dev for the user, and dev_user as the password Disconnect from the database using dbDisconnect() dbDisconnect(con) ## Warning: Connection already closed. 1.6 Secure credentials in a file Credentials can be saved in a YAML file and then read using the config package: http://db.rstudio.com/best-practices/managing-credentials/#stored-in-a-file-with-config Open and explore the config.yml file available in your working directory Load the datawarehouse-dev vaelus to a variable dw &lt;- config::get(&quot;datawarehouse-dev&quot;) Check that the variable loaded propery, by checking the driver value dw$driver ## [1] &quot;PostgreSQL&quot; Use info in the config.yml file to connect to the database con &lt;- dbConnect(odbc::odbc(), Driver = dw$driver, Server = dw$server, UID = dw$uid, PWD = dw$pwd, Port = dw$port, Database = dw$database ) Disconnect from the database using dbDisconnect() dbDisconnect(con) 1.7 Environment variables Use .Renviron file to store credentials Open and explore the .Renviron file available in your working directory Confirm that the environment variables are loaded by using Sys.getenv() Sys.getenv(&quot;uid&quot;) ## [1] &quot;rstudio_dev&quot; Pass the credentials using the environment variables con &lt;- dbConnect( odbc::odbc(), Driver = &quot;PostgreSQL&quot;, Server = &quot;localhost&quot;, UID = Sys.getenv(&quot;uid&quot;), PWD = Sys.getenv(&quot;pwd&quot;), Port = 5432, Database = &quot;postgres&quot; ) Disconnect from the database using dbDisconnect() dbDisconnect(con) 1.8 Use options() Set options() in a separate R script Open and explore the options.R script available in your working directory Source the options.R script source(&quot;options.R&quot;) Confirm that the environment variables are loaded by using Sys.getenv() getOption(&quot;database_userid&quot;) ## [1] &quot;rstudio_dev&quot; Pass the credentials using the environment variables con &lt;- dbConnect( odbc::odbc(), Driver = &quot;PostgreSQL&quot;, Server = &quot;localhost&quot;, UID = getOption(&quot;database_userid&quot;), PWD = getOption(&quot;database_password&quot;), Port = 5432, Database = &quot;postgres&quot; ) Disconnect from the database using dbDisconnect() dbDisconnect(con) ## Warning: Connection already closed. "],
["dplyr-basics.html", "2 dplyr Basics 2.1 Create a table variable 2.2 Under the hood 2.3 Un-translated R commands 2.4 Using bang-bang 2.5 knitr SQL engine 2.6 Basic aggregation", " 2 dplyr Basics 2.1 Create a table variable Basics to how to point a variable in R to a table or view inside the database Load the dplyr, DBI and dbplyr libraries library(dplyr) library(dbplyr) library(DBI) (Optional) Open a connection to the database if it’s currently closed con &lt;- dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) Use the tbl() and in_schema() functions to create a reference to a table tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;airport&quot;)) ## # Source: table&lt;datawarehouse.airport&gt; [?? x 7] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## airport airportname city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ABE Lehigh Valley International Allento… PA USA 40.7 - 75.4 ## 2 ABI Abilene Regional Abilene TX USA 32.4 - 99.7 ## 3 ABQ Albuquerque International Albuque… NM USA 35.0 -107 ## 4 ABY Southwest Georgia Regional Albany GA USA 31.5 - 84.2 ## 5 ACK Nantucket Memorial Nantuck… MA USA 41.3 - 70.1 ## 6 ACT Waco Regional Waco TX USA 31.6 - 97.2 ## 7 ACV Arcata Arcata/… CA USA 41.0 -124 ## 8 ACY Atlantic City International Atlanti… NJ USA 39.5 - 74.6 ## 9 ADK Adak Adak AK USA 51.9 -177 ## 10 ADQ Kodiak Kodiak AK USA 57.7 -152 ## # ... with more rows Load the reference, not the table data, into a variable airports &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;airport&quot;)) Call the variable to see preview the data in the table airports ## # Source: table&lt;datawarehouse.airport&gt; [?? x 7] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## airport airportname city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ABE Lehigh Valley International Allento… PA USA 40.7 - 75.4 ## 2 ABI Abilene Regional Abilene TX USA 32.4 - 99.7 ## 3 ABQ Albuquerque International Albuque… NM USA 35.0 -107 ## 4 ABY Southwest Georgia Regional Albany GA USA 31.5 - 84.2 ## 5 ACK Nantucket Memorial Nantuck… MA USA 41.3 - 70.1 ## 6 ACT Waco Regional Waco TX USA 31.6 - 97.2 ## 7 ACV Arcata Arcata/… CA USA 41.0 -124 ## 8 ACY Atlantic City International Atlanti… NJ USA 39.5 - 74.6 ## 9 ADK Adak Adak AK USA 51.9 -177 ## 10 ADQ Kodiak Kodiak AK USA 57.7 -152 ## # ... with more rows Set up the pointers to the other of the tables flights &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;vflight&quot;)) carriers &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;carrier&quot;)) 2.2 Under the hood Use show_query() to preview the SQL statement that will be sent to the database* SQL statement that actually runs when we ran airports as a command show_query(airports) ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport Easily view the resulting query by adding show_query() in another piped command airports %&gt;% show_query() ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport Insert head() in between the two statements to see how the SQL changes airports %&gt;% head() %&gt;% show_query() ## &lt;SQL&gt; ## SELECT * ## FROM datawarehouse.airport ## LIMIT 6 Use sql_render() and simulate_mssql() to see how the SQL statement changes from vendor to vendor airports %&gt;% head() %&gt;% sql_render(con = simulate_mssql()) ## &lt;SQL&gt; SELECT TOP 6 * ## FROM datawarehouse.airport 2.3 Un-translated R commands Review of how dbplyr handles R commands that have not been translated into a like-SQL command Preview how Sys.time() is translated airports %&gt;% mutate(today = Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, SYS.TIME() AS &quot;today&quot; ## FROM datawarehouse.airport Use PostgreSQL’s native commands, in this case now() airports %&gt;% mutate(today = now()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, NOW() AS &quot;today&quot; ## FROM datawarehouse.airport Run the dplyr code to confirm it works airports %&gt;% mutate(today = now()) %&gt;% select(today) %&gt;% head() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## today ## &lt;dttm&gt; ## 1 2018-01-26 21:29:44 ## 2 2018-01-26 21:29:44 ## 3 2018-01-26 21:29:44 ## 4 2018-01-26 21:29:44 ## 5 2018-01-26 21:29:44 ## 6 2018-01-26 21:29:44 2.4 Using bang-bang Intro on passing unevaluated code to a dplyr verb Preview how Sys.time() is translated airports %&gt;% mutate(today = Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, SYS.TIME() AS &quot;today&quot; ## FROM datawarehouse.airport Preview how Sys.time() is translated when prefixing !! airports %&gt;% mutate(today = !!Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, &#39;2018-01-26T21:29:44Z&#39; AS &quot;today&quot; ## FROM datawarehouse.airport Preview how Sys.time() is translated when prefixing !! airports %&gt;% mutate(today = !!Sys.time()) %&gt;% select(today) %&gt;% head() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## today ## &lt;chr&gt; ## 1 2018-01-26T21:29:44Z ## 2 2018-01-26T21:29:44Z ## 3 2018-01-26T21:29:44Z ## 4 2018-01-26T21:29:44Z ## 5 2018-01-26T21:29:44Z ## 6 2018-01-26T21:29:44Z 2.5 knitr SQL engine Copy the result of the latest show_query() exercise airports %&gt;% mutate(today = !!Sys.time()) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, &#39;2018-01-26T21:29:44Z&#39; AS &quot;today&quot; ## FROM datawarehouse.airport Paste the result in this SQL chunk SELECT &quot;airport&quot;, &quot;airportname&quot;, &quot;city&quot;, &quot;state&quot;, &quot;country&quot;, &quot;lat&quot;, &quot;long&quot;, &#39;2018-01-26T14:50:10Z&#39; AS &quot;today&quot; FROM datawarehouse.airport Table 2.1: Displaying records 1 - 10 airport airportname city state country lat long today ABE Lehigh Valley International Allentown PA USA 40.65236 -75.44040 2018-01-26T14:50:10Z ABI Abilene Regional Abilene TX USA 32.41132 -99.68190 2018-01-26T14:50:10Z ABQ Albuquerque International Albuquerque NM USA 35.04022 -106.60919 2018-01-26T14:50:10Z ABY Southwest Georgia Regional Albany GA USA 31.53552 -84.19447 2018-01-26T14:50:10Z ACK Nantucket Memorial Nantucket MA USA 41.25305 -70.06018 2018-01-26T14:50:10Z ACT Waco Regional Waco TX USA 31.61129 -97.23052 2018-01-26T14:50:10Z ACV Arcata Arcata/Eureka CA USA 40.97812 -124.10862 2018-01-26T14:50:10Z ACY Atlantic City International Atlantic City NJ USA 39.45758 -74.57717 2018-01-26T14:50:10Z ADK Adak Adak AK USA 51.87796 -176.64603 2018-01-26T14:50:10Z ADQ Kodiak Kodiak AK USA 57.74997 -152.49386 2018-01-26T14:50:10Z 2.6 Basic aggregation A couple of dplyr commands that run in-database How many records are in the airport table? tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;airport&quot;)) %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 305 What is the average character length of the airport codes? How many characters is the longest and the shortest airport name? airports %&gt;% summarise( avg_airport_length = mean(str_length(airport), na.rm = TRUE), max_airport_name = max(str_length(airportname), na.rm = TRUE), min_airport_name = min(str_length(airportname), na.rm = TRUE), total_records = n() ) ## # Source: lazy query [?? x 4] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## avg_airport_length max_airport_name min_airport_name total_records ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;S3: integer64&gt; ## 1 3.00 40 3 305 How many records are in the carrier table? carriers %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 20 How many characters is the longest carriername? carriers %&gt;% summarise(x = max(str_length(carriername), na.rm = TRUE)) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## x ## &lt;int&gt; ## 1 83 What is the SQL statement sent in exercise 4? carriers %&gt;% summarise(x = max(str_length(carriername), na.rm = TRUE)) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT MAX(LENGTH(&quot;carriername&quot;)) AS &quot;x&quot; ## FROM datawarehouse.carrier "],
["data-transformation.html", "3 Data transformation 3.1 Group and sort records 3.2 Answering questions with dplyr 3.3 Aggregate mulitple columns 3.4 View record level data 3.5 Case statements 3.6 Data enrichment", " 3 Data transformation 3.1 Group and sort records Learn how to use group_by() and arrange() to better understand aggregated data How many flights are there per month? flights %&gt;% group_by(month) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 10.0 556205 ## 2 4.00 598126 ## 3 12.0 544958 ## 4 5.00 606293 ## 5 2.00 569236 ## 6 7.00 627931 ## 7 11.0 523272 ## 8 9.00 540908 ## 9 1.00 605765 ## 10 3.00 616090 ## # ... with more rows Order the results by the month number by using arrange() flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(month) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: month ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 1.00 605765 ## 2 2.00 569236 ## 3 3.00 616090 ## 4 4.00 598126 ## 5 5.00 606293 ## 6 6.00 608665 ## 7 7.00 627931 ## 8 8.00 612279 ## 9 9.00 540908 ## 10 10.0 556205 ## # ... with more rows Order the results by the number of flights, starting with the month with most flights by using desc() inside the arrange() command flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(desc(n)) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 7.00 627931 ## 2 3.00 616090 ## 3 8.00 612279 ## 4 6.00 608665 ## 5 5.00 606293 ## 6 1.00 605765 ## 7 4.00 598126 ## 8 2.00 569236 ## 9 10.0 556205 ## 10 12.0 544958 ## # ... with more rows 3.2 Answering questions with dplyr Quick review of how to translate questions into dplyr code Which are the top 4 months with the most flight activity? flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(4) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## month n ## &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 7.00 627931 ## 2 3.00 616090 ## 3 8.00 612279 ## 4 6.00 608665 What were the top 5 calendar days with most flight activity? flights %&gt;% group_by(month, dayofmonth) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Groups: month ## # Ordered by: desc(n) ## month dayofmonth n ## &lt;dbl&gt; &lt;dbl&gt; &lt;S3: integer64&gt; ## 1 7.00 18.0 21128 ## 2 7.00 11.0 21125 ## 3 7.00 25.0 21102 ## 4 7.00 10.0 21058 ## 5 7.00 17.0 21055 Which are the top 5 carriers (airlines) with the most flights? flights %&gt;% group_by(carriername) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## carriername n ## &lt;chr&gt; &lt;S3: integ&gt; ## 1 Southwest Airlines Co. 1201754 ## 2 American Airlines Inc. 604885 ## 3 Skywest Airlines Inc. 567159 ## 4 American Eagle Airlines Inc. 490693 ## 5 US Airways Inc. (Merged with America West 9/05. Reporting f… 453589 Figure the percent ratio of flights per month flights %&gt;% group_by(month) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% mutate(percent = n/sum(n, na.rm = TRUE)) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## month n percent ## &lt;dbl&gt; &lt;S3: integer64&gt; &lt;dbl&gt; ## 1 7.00 627931 0.0896 ## 2 3.00 616090 0.0879 ## 3 8.00 612279 0.0873 ## 4 6.00 608665 0.0868 ## 5 5.00 606293 0.0865 ## 6 1.00 605765 0.0864 ## 7 4.00 598126 0.0853 ## 8 2.00 569236 0.0812 ## 9 10.0 556205 0.0793 ## 10 12.0 544958 0.0777 ## # ... with more rows Figure the percent ratio of flights per carrier flights %&gt;% group_by(carriername) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% mutate(percent = n/sum(n, na.rm = TRUE)) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## carriername n percent ## &lt;chr&gt; &lt;S3: inte&gt; &lt;dbl&gt; ## 1 Southwest Airlines Co. 1201754 0.171 ## 2 American Airlines Inc. 604885 0.0863 ## 3 Skywest Airlines Inc. 567159 0.0809 ## 4 American Eagle Airlines Inc. 490693 0.0700 ## 5 US Airways Inc. (Merged with America West 9/05. Rep… 453589 0.0647 ## 6 Delta Air Lines Inc. 451931 0.0645 ## 7 United Air Lines Inc. 449515 0.0641 ## 8 Expressjet Airlines Inc. 374510 0.0534 ## 9 Northwest Airlines Inc. 347652 0.0496 ## 10 Continental Air Lines Inc. 298455 0.0426 ## # ... with more rows 3.3 Aggregate mulitple columns Practice using summarise _ functions Use summarise_all() to send the same function to all fields flights %&gt;% select(depdelay, arrdelay) %&gt;% summarise_all(mean, na.rm = TRUE) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## depdelay arrdelay ## &lt;dbl&gt; &lt;dbl&gt; ## 1 9.78 7.99 Use summarise_at() to pre-select the fields that will receive the function flights %&gt;% summarise_at(c(&quot;depdelay&quot;, &quot;arrdelay&quot;), mean, na.rm = TRUE) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## depdelay arrdelay ## &lt;dbl&gt; &lt;dbl&gt; ## 1 9.78 7.99 Use summarise_if() to summarize only if the field meets a criterion flights %&gt;% summarise_if(is.numeric,mean, na.rm = TRUE) ## Applying predicate on the first 100 rows ## # Source: lazy query [?? x 19] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## originlat originlong destlat destlong year month dayofmonth dayofweek ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 36.9 -95.1 36.9 -95.1 2008 6.38 15.7 3.92 ## # ... with 11 more variables: deptime &lt;dbl&gt;, crsdeptime &lt;dbl&gt;, ## # arrtime &lt;dbl&gt;, crsarrtime &lt;dbl&gt;, flightnum &lt;dbl&gt;, ## # actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, ## # arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, distance &lt;dbl&gt; Combine with group_by() to create more complex results flights %&gt;% select(month, depdelay, arrdelay) %&gt;% group_by(month) %&gt;% summarise_all(mean, na.rm = TRUE) ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## month depdelay arrdelay ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 10.0 3.78 0.412 ## 2 4.00 8.06 6.68 ## 3 12.0 16.8 16.1 ## 4 5.00 7.56 5.91 ## 5 2.00 13.2 12.6 ## 6 7.00 11.6 9.78 ## 7 11.0 5.38 2.00 ## 8 9.00 3.89 0.684 ## 9 1.00 11.1 9.88 ## 10 3.00 12.2 10.9 ## # ... with more rows 3.4 View record level data Important tips to record preview data How many flights in July 18th were one or more hours late? flights %&gt;% filter( depdelay &gt;= 60, month == 7, dayofmonth == 18 ) %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 1239 Use filter() to retrieve only the needed data, and head() to limit the preview even further. flights %&gt;% filter( depdelay &gt;= 60, month == 7, dayofmonth == 18 ) %&gt;% head(100) ## # Source: lazy query [?? x 32] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier carriername origin originname origincity originstate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 WN Southwest Ai… BNA Nashville In… Nashville TN ## 2 WN Southwest Ai… BNA Nashville In… Nashville TN ## 3 WN Southwest Ai… BNA Nashville In… Nashville TN ## 4 WN Southwest Ai… BUR Burbank-Glen… Burbank CA ## 5 WN Southwest Ai… BWI Baltimore-Wa… Baltimore MD ## 6 WN Southwest Ai… BWI Baltimore-Wa… Baltimore MD ## 7 WN Southwest Ai… BWI Baltimore-Wa… Baltimore MD ## 8 WN Southwest Ai… DAL Dallas Love Dallas TX ## 9 WN Southwest Ai… DAL Dallas Love Dallas TX ## 10 WN Southwest Ai… DAL Dallas Love Dallas TX ## # ... with more rows, and 26 more variables: origincountry &lt;chr&gt;, ## # originlat &lt;dbl&gt;, originlong &lt;dbl&gt;, dest &lt;chr&gt;, destname &lt;chr&gt;, ## # destcity &lt;chr&gt;, deststate &lt;chr&gt;, destcountry &lt;chr&gt;, destlat &lt;dbl&gt;, ## # destlong &lt;dbl&gt;, year &lt;dbl&gt;, month &lt;dbl&gt;, dayofmonth &lt;dbl&gt;, ## # dayofweek &lt;dbl&gt;, deptime &lt;dbl&gt;, crsdeptime &lt;dbl&gt;, arrtime &lt;dbl&gt;, ## # crsarrtime &lt;dbl&gt;, flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, ## # actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, ## # arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, distance &lt;dbl&gt; Use collect() and View() to preview the data in the IDE. Make sure to always limit the number of returned rows. https://github.com/tidyverse/tibble/issues/373 flights %&gt;% filter( depdelay &gt;= 60, month == 7, dayofmonth == 18 ) %&gt;% collect() %&gt;% head(100) %&gt;% View(&quot;my_preview&quot;) 3.5 Case statements See how to use the flexibility of case statements for special cases Use case_when() to bucket each month one of four seasons flights %&gt;% mutate( season = case_when( month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, TRUE ~ &quot;Winter&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1620385 ## 2 Spring 1820509 ## 3 Winter 1719959 ## 4 Summer 1848875 Add a specific case for “Winter” flights %&gt;% mutate( season = case_when( month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1620385 ## 2 Spring 1820509 ## 3 Winter 1719959 ## 4 Summer 1848875 Append an entry for Monday at the end of the case statement flights %&gt;% mutate( season = case_when( month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot;, dayofweek == 1 ~ &quot;Monday&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1620385 ## 2 Spring 1820509 ## 3 Winter 1719959 ## 4 Summer 1848875 Move the “Monday” entry to the top of the case statement flights %&gt;% mutate( season = case_when( dayofweek == 1 ~ &quot;Monday&quot;, month &gt;= 3 &amp;&amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp;&amp; month &lt;= 8 ~ &quot;Summer&quot;, month &gt;= 9 &amp;&amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% group_by(season) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 Fall 1376740 ## 2 Spring 1554210 ## 3 Winter 1464948 ## 4 Summer 1577629 ## 5 Monday 1036201 3.6 Data enrichment Upload a small dataset in order to combine it with the datawarehouse data Load the planes data into memory planes &lt;- nycflights13::planes Using DBI, copy the planes data to the datawarehouse as a temporary table, and load it to a variable dbWriteTable(con, &quot;planes&quot;, planes, temporary = TRUE) tbl_planes &lt;- tbl(con, &quot;planes&quot;) Create a “lazy” variable that joins the flights table to the new temp table combined &lt;- flights %&gt;% left_join(tbl_planes, by = &quot;tailnum&quot;) View a sample of flights of planes with more than 100 seats combined %&gt;% filter(seats &gt; 100) %&gt;% head() ## # Source: lazy query [?? x 40] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier carriername origin originname origincity originstate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 WN Southwest Airlin… DAL Dallas Lo… Dallas TX ## 2 WN Southwest Airlin… DAL Dallas Lo… Dallas TX ## 3 WN Southwest Airlin… DAL Dallas Lo… Dallas TX ## 4 WN Southwest Airlin… DAL Dallas Lo… Dallas TX ## 5 WN Southwest Airlin… DAL Dallas Lo… Dallas TX ## 6 WN Southwest Airlin… DAL Dallas Lo… Dallas TX ## # ... with 34 more variables: origincountry &lt;chr&gt;, originlat &lt;dbl&gt;, ## # originlong &lt;dbl&gt;, dest &lt;chr&gt;, destname &lt;chr&gt;, destcity &lt;chr&gt;, ## # deststate &lt;chr&gt;, destcountry &lt;chr&gt;, destlat &lt;dbl&gt;, destlong &lt;dbl&gt;, ## # year.x &lt;dbl&gt;, month &lt;dbl&gt;, dayofmonth &lt;dbl&gt;, dayofweek &lt;dbl&gt;, ## # deptime &lt;dbl&gt;, crsdeptime &lt;dbl&gt;, arrtime &lt;dbl&gt;, crsarrtime &lt;dbl&gt;, ## # flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, actualelapsedtime &lt;dbl&gt;, ## # crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, ## # distance &lt;dbl&gt;, year.y &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;, ## # model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt; How many flights are from McDonnel Douglas planes combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 137250 See how many flights each plane McDonnel Douglas had combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% group_by(tailnum) %&gt;% tally() ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## tailnum n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 N599AA 1243 ## 2 N494AA 1360 ## 3 N492AA 1331 ## 4 N505AA 1373 ## 5 N777NC 1850 ## 6 N475AA 1358 ## 7 N583AA 1403 ## 8 N560AA 1340 ## 9 N480AA 1204 ## 10 N470AA 1455 ## # ... with more rows Get the total number of planes, and the average, minimum &amp; maximum number of flights for the manufacturer combined %&gt;% filter(manufacturer == &quot;MCDONNELL DOUGLAS&quot;) %&gt;% group_by(tailnum) %&gt;% tally() %&gt;% summarise(planes = n(), avg_flights = mean(n, na.rm = TRUE), max_flights = max(n, na.rm = TRUE), min_flights = min(n, na.rm = TRUE)) ## # Source: lazy query [?? x 4] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## planes avg_flights max_flights min_flights ## &lt;S3: integer64&gt; &lt;dbl&gt; &lt;S3: integer64&gt; &lt;S3: integer64&gt; ## 1 102 1346 1850 1068 Disconnect from the database dbDisconnect(con) "],
["data-visualizations.html", "4 Data Visualizations 4.1 Simple plot 4.2 Plot in one code segment 4.3 Plot specific data segments 4.4 Two or more queries 4.5 Visualize using dbplot 4.6 Plot a different aggregation 4.7 Create a histogram 4.8 Raster plot 4.9 Using the calculate functions 4.10 Under the hood (II)", " 4 Data Visualizations 4.1 Simple plot Practice pushing the calculations to the database Use collect() bring back the aggregated results into a “pass-through” variable called by_month by_month &lt;- flights %&gt;% group_by(month) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% collect() head(by_month) ## # A tibble: 6 x 2 ## month n ## &lt;dbl&gt; &lt;dbl&gt; ## 1 10.0 556205 ## 2 4.00 598126 ## 3 12.0 544958 ## 4 5.00 606293 ## 5 2.00 569236 ## 6 7.00 627931 Plot results using ggplot2 library(ggplot2) ggplot(by_month) + geom_line(aes(x = month, y = n)) 4.2 Plot in one code segment Practice going from dplyr to ggplot2 without using pass-through variable, great for EDA Using the code from the previous section, create a single piped code set which also creates the plot flights %&gt;% group_by(month) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% collect() %&gt;% ggplot() + # &lt; Don&#39;t forget to switch to `+` geom_line(aes(x = month, y = n)) Change the aggregation to the average of arrdelay. Tip: Use x as the summarize variable flights %&gt;% group_by(month) %&gt;% summarise(x = mean(arrdelay, na.rm = TRUE)) %&gt;% mutate(x = as.numeric(x)) %&gt;% collect() %&gt;% ggplot() + geom_line(aes(x = month, y = x)) Plot the average distance. Copy the code from the previous exercise and change the variable flights %&gt;% group_by(month) %&gt;% summarise(x = mean(distance, na.rm = TRUE)) %&gt;% mutate(x = as.numeric(x)) %&gt;% collect() %&gt;% ggplot() + geom_line(aes(x = month, y = x)) 4.3 Plot specific data segments Combine skills from previous units to create more sophisticated plots Start with getting the top 5 carriers flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## # Ordered by: desc(n) ## uniquecarrier n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 WN 1201754 ## 2 AA 604885 ## 3 OO 567159 ## 4 MQ 490693 ## 5 US 453589 Pipe the top 5 carriers to a plot flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% collect() %&gt;% ggplot() + geom_col(aes(x = uniquecarrier, y = n)) Improve the plot’s look flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% mutate(n = as.numeric(n)) %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% collect() %&gt;% ggplot() + #Don&#39;t forget to switch to `+` geom_col(aes(x = uniquecarrier, y = n, fill = n)) + #Add fill theme(legend.position=&quot;none&quot;) + # Turn legend off coord_flip() + # Rotate cols into rows labs(title = &quot;Top 5 Carriers&quot;, subtitle = &quot;Source: Datawarehouse&quot;, x = &quot;Carrier Name&quot;, y = &quot;# of Flights&quot;) 4.4 Two or more queries Learn how to use pull() to pass a set of values to be used on a secondary query Use pull() to get the top 5 carriers loaded in a vector top5 &lt;- flights %&gt;% group_by(uniquecarrier) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% head(5) %&gt;% pull(uniquecarrier) top5 ## [1] &quot;WN&quot; &quot;AA&quot; &quot;OO&quot; &quot;MQ&quot; &quot;US&quot; Use %in% to pass the top5 vector to a filter flights %&gt;% filter(uniquecarrier %in% top5) ## # Source: lazy query [?? x 32] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier carriername origin originname origincity originstate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 2 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 3 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 4 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 5 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 6 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 7 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 8 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 9 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## 10 WN Southwest Airli… DAL Dallas Lo… Dallas TX ## # ... with more rows, and 26 more variables: origincountry &lt;chr&gt;, ## # originlat &lt;dbl&gt;, originlong &lt;dbl&gt;, dest &lt;chr&gt;, destname &lt;chr&gt;, ## # destcity &lt;chr&gt;, deststate &lt;chr&gt;, destcountry &lt;chr&gt;, destlat &lt;dbl&gt;, ## # destlong &lt;dbl&gt;, year &lt;dbl&gt;, month &lt;dbl&gt;, dayofmonth &lt;dbl&gt;, ## # dayofweek &lt;dbl&gt;, deptime &lt;dbl&gt;, crsdeptime &lt;dbl&gt;, arrtime &lt;dbl&gt;, ## # crsarrtime &lt;dbl&gt;, flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, ## # actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, ## # arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, distance &lt;dbl&gt; Group by carrier and get the average arrival delay flights %&gt;% filter(uniquecarrier %in% top5) %&gt;% group_by(uniquecarrier) %&gt;% summarise(n = mean(arrdelay, na.rm = TRUE)) ## # Source: lazy query [?? x 2] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## uniquecarrier n ## &lt;chr&gt; &lt;dbl&gt; ## 1 US 2.80 ## 2 MQ 9.50 ## 3 OO 6.44 ## 4 WN 5.12 ## 5 AA 12.2 Copy the final ggplot() code from the Plot specific segment section. Update the y labs. flights %&gt;% filter(uniquecarrier %in% top5) %&gt;% group_by(uniquecarrier) %&gt;% summarise(n = mean(arrdelay, na.rm = TRUE)) %&gt;% # From previous section ---------------------------------------------- collect() %&gt;% ggplot() + #Don&#39;t forget to switch to `+` geom_col(aes(x = uniquecarrier, y = n, fill = n)) + #Add fill theme(legend.position=&quot;none&quot;) + # Turn legend off coord_flip() + # Rotate cols into rows labs(title = &quot;Top 5 Carriers&quot;, subtitle = &quot;Source: Datawarehouse&quot;, x = &quot;Carrier Name&quot;, y = &quot;Average Delay&quot;) 4.5 Visualize using dbplot Review how to use dbplot to make it easier to plot with databases Install and load dbplot library(dbplot) Create a line plot using the helper function dbplot_line() flights %&gt;% dbplot_line(month) Update the plot’s labels flights %&gt;% dbplot_line(month) + labs(title = &quot;Monthly flights&quot;, x = &quot;Month&quot;, y = &quot;Number of flights&quot;) 4.6 Plot a different aggregation dbplot allows for aggregate functions, other than record count, to be used for plotting Plot the average departure delay by day of week flights %&gt;% dbplot_bar(dayofweek, mean(depdelay, na.rm = TRUE)) Change the day numbers to day name labels flights %&gt;% dbplot_bar(dayofweek, mean(depdelay, na.rm = TRUE)) + scale_x_continuous( labels = c(&quot;Mon&quot;, &quot;Tue&quot;, &quot;Wed&quot;, &quot;Thu&quot;, &quot;Fri&quot;, &quot;Sat&quot;, &quot;Sun&quot;), breaks = 1:7 ) 4.7 Create a histogram Use the package’s function to easily create a histogram Use the dbplot_histogram() to build the histogram flights %&gt;% dbplot_histogram(distance) Adjust the binwidth to 300 flights %&gt;% dbplot_histogram(distance, binwidth = 300) 4.8 Raster plot Use a dbplot_raster() to visualize deptime versus depdelay flights %&gt;% dbplot_raster(deptime, arrtime) Change the plot’s resolution to 500 flights %&gt;% dbplot_raster(deptime, arrtime, resolution = 500) 4.9 Using the calculate functions Use the db_comptue_raster() function to get the underlying results that feed the plot departure &lt;- flights %&gt;% db_compute_raster(deptime, arrtime) departure ## # A tibble: 3,362 x 3 ## deptime arrtime `n()` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 136345 ## 2 1440 1584 11899 ## 3 1440 1704 12455 ## 4 1248 2208 20.0 ## 5 744 2112 1.00 ## 6 840 1344 1578 ## 7 2112 936 34.0 ## 8 936 2208 1.00 ## 9 648 816 17227 ## 10 336 528 42.0 ## # ... with 3,352 more rows Plot the results “manually” departure %&gt;% filter(`n()` &gt; 1000) %&gt;% ggplot() + geom_raster(aes(x = deptime, y = arrtime, fill = `n()`)) 4.10 Under the hood (II) Review how dbplot pushes histogram and raster calculations to the database Use the db_bin() command to see the resulting tidy eval formula db_bin(field) ## (((max(field, na.rm = TRUE) - min(field, na.rm = TRUE))/(30)) * ## ifelse((as.integer(floor(((field) - min(field, na.rm = TRUE))/((max(field, ## na.rm = TRUE) - min(field, na.rm = TRUE))/(30))))) == ## (30), (as.integer(floor(((field) - min(field, na.rm = TRUE))/((max(field, ## na.rm = TRUE) - min(field, na.rm = TRUE))/(30))))) - ## 1, (as.integer(floor(((field) - min(field, na.rm = TRUE))/((max(field, ## na.rm = TRUE) - min(field, na.rm = TRUE))/(30))))))) + ## min(field, na.rm = TRUE) Use trasnlate_sql() and simulate_odbc_postgresql() to see an example of what the resulting SQL statement looks like translate_sql(!! db_bin(field), con = simulate_odbc_postgresql()) ## &lt;SQL&gt; (((max(`field`) OVER () - min(`field`) OVER ()) / (30.0)) * CASE WHEN ((CAST(FLOOR(((`field`) - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / (30.0))) AS INTEGER)) = (30.0)) THEN ((CAST(FLOOR(((`field`) - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / (30.0))) AS INTEGER)) - 1.0) WHEN NOT((CAST(FLOOR(((`field`) - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / (30.0))) AS INTEGER)) = (30.0)) THEN ((CAST(FLOOR(((`field`) - min(`field`) OVER ()) / ((max(`field`) OVER () - min(`field`) OVER ()) / (30.0))) AS INTEGER))) END) + min(`field`) OVER () Disconnect from the database dbDisconnect(con) "],
["modeling.html", "5 Modeling 5.1 SQL Native sampling 5.2 Sample with ID 5.3 Sample manually 5.4 Create a model &amp; test 5.5 Score inside database 5.6 Parsed model", " 5 Modeling 5.1 SQL Native sampling Use PostgreSQL TABLESAMPLE clause Use build_sql() and remote_query() to combine a the dplyr command with a custom SQL statement sql_sample &lt;- dbGetQuery(con, build_sql(remote_query(table_flights), &quot; TABLESAMPLE SYSTEM (0.1)&quot;)) Preview the sample data sql_sample ## year month dayofmonth dayofweek deptime crsdeptime arrtime crsarrtime ## 1 2008 2 16 6 1520 1525 1645 1659 ## 2 2008 2 16 6 1053 1105 1207 1210 ## 3 2008 2 16 6 1436 1436 1536 1540 ## 4 2008 2 16 6 1257 1257 1355 1402 ## 5 2008 2 16 6 1550 1534 1710 1710 ## 6 2008 2 16 6 835 828 922 915 ## 7 2008 2 16 6 1250 1243 1340 1330 ## 8 2008 2 16 6 1640 1638 1740 1725 ## 9 2008 2 16 6 1853 1853 1948 1940 ## 10 2008 2 16 6 2108 2108 2200 2155 ## 11 2008 2 16 6 1130 1028 1222 1115 ## 12 2008 2 16 6 1945 1950 2100 2108 ## 13 2008 2 16 6 1435 1442 1625 1638 ## 14 2008 2 16 6 0 1100 0 1247 ## 15 2008 2 16 6 0 620 0 820 ## 16 2008 2 16 6 620 620 708 700 ## 17 2008 2 16 6 825 830 910 910 ## 18 2008 2 16 6 1245 1230 1330 1310 ## 19 2008 2 16 6 2105 2030 2155 2110 ## 20 2008 2 16 6 1045 1030 1125 1110 ## 21 2008 2 16 6 1505 1430 1557 1510 ## 22 2008 2 16 6 1935 1830 2007 1910 ## 23 2008 2 16 6 850 855 849 903 ## 24 2008 2 16 6 2300 2300 132 142 ## 25 2008 2 16 6 2345 2355 52 110 ## 26 2008 2 16 6 1605 1616 1735 1750 ## 27 2008 2 16 6 1255 1300 1350 1356 ## 28 2008 2 16 6 2354 2354 210 214 ## 29 2008 2 16 6 1720 1727 1922 1936 ## 30 2008 2 16 6 2010 2014 2211 2226 ## 31 2008 2 16 6 0 2359 0 110 ## 32 2008 2 6 3 0 727 0 821 ## 33 2008 2 6 3 553 600 552 602 ## uniquecarrier flightnum tailnum actualelapsedtime crselapsedtime ## 1 YV 2966 N931LR 145 154 ## 2 YV 2615 N905FJ 74 65 ## 3 YV 2670 N927LR 60 64 ## 4 YV 2673 N938LR 58 65 ## 5 YV 2643 N921FJ 80 96 ## 6 YV 1035 N693BR 47 47 ## 7 YV 1037 N693BR 50 47 ## 8 YV 1039 N646BR 60 47 ## 9 YV 1042 N651BR 55 47 ## 10 YV 1043 N651BR 52 47 ## 11 YV 1044 N655BR 52 47 ## 12 YV 2698 N921FJ 75 78 ## 13 YV 7304 N77278 110 116 ## 14 YV 7388 N75996 0 107 ## 15 YV 2629 N918FJ 0 120 ## 16 YV 1010 N651BR 48 40 ## 17 YV 1011 N651BR 45 40 ## 18 YV 1015 N651BR 45 40 ## 19 YV 1019 N693BR 50 40 ## 20 YV 1024 N646BR 40 40 ## 21 YV 1025 N651BR 52 40 ## 22 YV 1029 N655BR 32 40 ## 23 YV 7220 N77331 59 68 ## 24 YV 2876 N934FJ 92 102 ## 25 YV 2791 N935LR 67 75 ## 26 YV 2770 N7291Z 90 94 ## 27 YV 2820 N7291Z 55 56 ## 28 YV 2842 N929LR 76 80 ## 29 YV 2846 N939LR 62 69 ## 30 YV 2885 N926LR 61 72 ## 31 YV 2792 N991HA 0 71 ## 32 OO 6028 N923SW 0 54 ## 33 OO 6029 N910SW 59 62 ## airtime arrdelay depdelay origin dest distance taxiin taxiout ## 1 122 -14 -5 ICT PHX 870 8 15 ## 2 40 -3 -12 ILM CLT 185 18 16 ## 3 43 -4 0 ILM CLT 185 7 10 ## 4 38 -7 0 ILM CLT 185 13 7 ## 5 65 0 16 IND CLT 428 9 6 ## 6 36 7 7 ITO HNL 216 5 6 ## 7 38 10 7 ITO HNL 216 6 6 ## 8 38 15 2 ITO HNL 216 6 16 ## 9 30 8 0 ITO HNL 216 13 12 ## 10 38 5 0 ITO HNL 216 3 11 ## 11 40 67 62 ITO HNL 216 5 7 ## 12 57 -8 -5 JAX CLT 329 10 8 ## 13 91 -13 -7 JAX IAD 631 10 9 ## 14 0 0 0 JAX IAD 631 0 0 ## 15 0 0 0 JFK CLT 541 0 0 ## 16 30 8 0 KOA HNL 163 5 13 ## 17 30 0 -5 KOA HNL 163 8 7 ## 18 30 20 15 KOA HNL 163 6 9 ## 19 39 45 35 KOA HNL 163 6 5 ## 20 29 15 15 KOA HNL 163 6 5 ## 21 29 47 35 KOA HNL 163 13 10 ## 22 24 57 65 KOA HNL 163 3 5 ## 23 42 -14 -5 LAN ORD 179 6 11 ## 24 72 -10 0 LAS ELP 584 5 15 ## 25 44 -18 -10 LAS FAT 258 6 17 ## 26 67 -15 -11 LAS OAK 407 5 18 ## 27 34 -6 -5 LAS ONT 197 6 15 ## 28 39 -4 0 LAS PHX 256 5 32 ## 29 36 -14 -7 LAS PHX 256 16 10 ## 30 42 -15 -4 LAS PHX 256 4 15 ## 31 0 0 0 LAS PSP 173 0 0 ## 32 0 0 0 ORD MSN 109 0 0 ## 33 40 -10 -7 FWA ORD 157 8 11 ## cancelled cancellationcode diverted carrierdelay weatherdelay ## 1 0 &lt;NA&gt; 0 0 0 ## 2 0 &lt;NA&gt; 0 0 0 ## 3 0 &lt;NA&gt; 0 0 0 ## 4 0 &lt;NA&gt; 0 0 0 ## 5 0 &lt;NA&gt; 0 0 0 ## 6 0 &lt;NA&gt; 0 0 0 ## 7 0 &lt;NA&gt; 0 0 0 ## 8 0 &lt;NA&gt; 0 0 0 ## 9 0 &lt;NA&gt; 0 0 0 ## 10 0 &lt;NA&gt; 0 0 0 ## 11 0 &lt;NA&gt; 0 0 0 ## 12 0 &lt;NA&gt; 0 0 0 ## 13 0 &lt;NA&gt; 0 0 0 ## 14 1 A 0 0 0 ## 15 1 B 0 0 0 ## 16 0 &lt;NA&gt; 0 0 0 ## 17 0 &lt;NA&gt; 0 0 0 ## 18 0 &lt;NA&gt; 0 0 0 ## 19 0 &lt;NA&gt; 0 45 0 ## 20 0 &lt;NA&gt; 0 15 0 ## 21 0 &lt;NA&gt; 0 0 0 ## 22 0 &lt;NA&gt; 0 0 0 ## 23 0 &lt;NA&gt; 0 0 0 ## 24 0 &lt;NA&gt; 0 0 0 ## 25 0 &lt;NA&gt; 0 0 0 ## 26 0 &lt;NA&gt; 0 0 0 ## 27 0 &lt;NA&gt; 0 0 0 ## 28 0 &lt;NA&gt; 0 0 0 ## 29 0 &lt;NA&gt; 0 0 0 ## 30 0 &lt;NA&gt; 0 0 0 ## 31 1 A 0 0 0 ## 32 1 C 0 0 0 ## 33 0 &lt;NA&gt; 0 0 0 ## nasdelay securitydelay lateaircraftdelay flightid ## 1 0.000000 0 0 16643 ## 2 0.000000 0 0 16644 ## 3 0.000000 0 0 16645 ## 4 0.000000 0 0 16646 ## 5 0.000000 0 0 16647 ## 6 0.000000 0 0 16648 ## 7 0.000000 0 0 16649 ## 8 0.000000 0 15 16650 ## 9 0.000000 0 0 16651 ## 10 0.000000 0 0 16652 ## 11 0.000000 0 67 16653 ## 12 0.000000 0 0 16654 ## 13 0.000000 0 0 16655 ## 14 0.000000 0 0 16656 ## 15 0.000000 0 0 16657 ## 16 0.000000 0 0 16658 ## 17 0.000000 0 0 16659 ## 18 0.000000 0 20 16660 ## 19 0.000000 0 0 16661 ## 20 0.000000 0 0 16662 ## 21 0.000000 0 47 16663 ## 22 0.000000 0 57 16664 ## 23 0.000000 0 0 16665 ## 24 0.000000 0 0 16666 ## 25 0.000000 0 0 16667 ## 26 0.000000 0 0 16668 ## 27 0.000000 0 0 16669 ## 28 0.000000 0 0 16670 ## 29 0.000000 0 0 16671 ## 30 0.000000 0 0 16672 ## 31 0.000000 0 0 16673 ## 32 0.000000 0 0 52429 ## 33 0.000000 0 0 52430 ## [ reached getOption(&quot;max.print&quot;) -- omitted 6934 rows ] Test the efficacy of the sampling with a plot dbplot_histogram(sql_sample, distance) 5.2 Sample with ID Use a record’s unique ID to produce a sample Use max() to get the upper limit for flightid limit &lt;- table_flights %&gt;% summarise( max = max(flightid, na.rm = TRUE), min = min(flightid, na.rm = TRUE) ) %&gt;% collect() Use sample to get 0.1% of IDs sampling &lt;- sample( limit$min:limit$max, round((limit$max -limit$min) * 0.001)) Use %in% to match the sample IDs in the flight table id_sample &lt;- table_flights %&gt;% filter(flightid %in% sampling) %&gt;% collect() Verify sample with a histogram dbplot_histogram(id_sample, distance) 5.3 Sample manually Use row_number(), sample() and map_df() to create a sample data set Create a filtered dataset for with 1 month of data db_month &lt;- table_flights %&gt;% filter(month == 1) Get the row count rows &lt;- as.integer(pull(tally(db_month))) Use row_number() to create a new column to number each row db_month &lt;- db_month %&gt;% mutate(row = row_number()) Create a random set of 600 numbers, limited by the number of rows sampling &lt;- sample(1:rows, 600) Use %in% to filter the matched sample row IDs with the random set db_month &lt;- db_month %&gt;% filter(row %in% sampling) Verify number of rows tally(db_month) ## # Source: lazy query [?? x 1] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## n ## &lt;S3: integer64&gt; ## 1 600 Create a function with the previous steps, but replacing the month number with an argument. Collect the data at the end sample_segment &lt;- function(x, size = 600) { db_month &lt;- table_flights %&gt;% filter(month == x) rows &lt;- as.integer(pull(tally(db_month))) db_month &lt;- db_month %&gt;% mutate(row = row_number()) sampling &lt;- sample(1:rows, size) db_month %&gt;% filter(row %in% sampling) %&gt;% collect() } Test the function head(sample_segment(3), 100) ## # A tibble: 100 x 31 ## year month dayofmonth dayofweek deptime crsdeptime arrtime crsarrtime ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 3.00 3.00 1.00 1255 1300 1757 1755 ## 2 2008 3.00 4.00 2.00 0 1100 0 1205 ## 3 2008 3.00 4.00 2.00 2014 2020 2313 2330 ## 4 2008 3.00 4.00 2.00 1234 1240 1538 1555 ## 5 2008 3.00 4.00 2.00 910 910 1611 1615 ## 6 2008 3.00 5.00 3.00 1503 1505 1843 1900 ## 7 2008 3.00 5.00 3.00 1501 1500 1624 1630 ## 8 2008 3.00 6.00 4.00 2044 1800 2138 1855 ## 9 2008 3.00 7.00 5.00 2105 1745 2317 1945 ## 10 2008 3.00 7.00 5.00 1740 1700 2345 2300 ## # ... with 90 more rows, and 23 more variables: uniquecarrier &lt;chr&gt;, ## # flightnum &lt;dbl&gt;, tailnum &lt;chr&gt;, actualelapsedtime &lt;dbl&gt;, ## # crselapsedtime &lt;dbl&gt;, airtime &lt;dbl&gt;, arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, distance &lt;dbl&gt;, taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, ## # cancelled &lt;dbl&gt;, cancellationcode &lt;chr&gt;, diverted &lt;dbl&gt;, ## # carrierdelay &lt;dbl&gt;, weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, ## # securitydelay &lt;dbl&gt;, lateaircraftdelay &lt;dbl&gt;, flightid &lt;int&gt;, row &lt;S3: ## # integer64&gt; Use map_df() to run the function for each month strat_sample &lt;- 1:12 %&gt;% map_df(~sample_segment(.x)) Verify sample with a histogram dbplot_histogram(strat_sample, distance) 5.4 Create a model &amp; test Prepare a model data set model_data &lt;- strat_sample %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select(arrdelay, season, depdelay) Create a simple lm() model model_lm &lt;- lm(arrdelay ~ . , data = model_data) summary(model_lm) ## ## Call: ## lm(formula = arrdelay ~ ., data = model_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -121.950 -7.407 -1.334 5.527 164.537 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.652840 0.328666 -11.114 &lt; 2e-16 *** ## seasonSpring 1.798175 0.464260 3.873 0.000108 *** ## seasonSummmer 2.353423 0.464506 5.067 4.15e-07 *** ## seasonWinter 3.109000 0.465762 6.675 2.65e-11 *** ## depdelay 1.006544 0.004825 208.614 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 13.91 on 7195 degrees of freedom ## Multiple R-squared: 0.8602, Adjusted R-squared: 0.8601 ## F-statistic: 1.107e+04 on 4 and 7195 DF, p-value: &lt; 2.2e-16 Create a test data set by combining the sampling and model data set routines test_sample &lt;- 1:12 %&gt;% map_df(~sample_segment(.x, 100)) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select(arrdelay, season, depdelay) Run a simple routine to check accuracy test_sample %&gt;% mutate(p = predict(model_lm, test_sample), over = abs(p - arrdelay) &lt; 10) %&gt;% group_by(over) %&gt;% tally() %&gt;% mutate(percent = round(n / sum(n), 2)) ## # A tibble: 2 x 3 ## over n percent ## &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 F 379 0.320 ## 2 T 821 0.680 5.5 Score inside database Learn about tidypredict to run predictions inside the database Load the library, and see the results of passing the model as an argument to tidypredict_fit() library(tidypredict) tidypredict_fit(model_lm) ## ((((-3.65284013396606) + ((ifelse((season) == (&quot;Spring&quot;), 1, ## 0)) * (1.79817516392108))) + ((ifelse((season) == (&quot;Summmer&quot;), ## 1, 0)) * (2.35342251313206))) + ((ifelse((season) == (&quot;Winter&quot;), ## 1, 0)) * (3.10900007425407))) + ((depdelay) * (1.00654356566678)) Use tidypredict_sql() to see the resulting SQL statement tidypredict_sql(model_lm, con) ## &lt;SQL&gt; ((((-3.65284013396606) + ((CASE WHEN ((&quot;season&quot;) = (&#39;Spring&#39;)) THEN (1.0) WHEN NOT((&quot;season&quot;) = (&#39;Spring&#39;)) THEN (0.0) END) * (1.79817516392108))) + ((CASE WHEN ((&quot;season&quot;) = (&#39;Summmer&#39;)) THEN (1.0) WHEN NOT((&quot;season&quot;) = (&#39;Summmer&#39;)) THEN (0.0) END) * (2.35342251313206))) + ((CASE WHEN ((&quot;season&quot;) = (&#39;Winter&#39;)) THEN (1.0) WHEN NOT((&quot;season&quot;) = (&#39;Winter&#39;)) THEN (0.0) END) * (3.10900007425407))) + ((&quot;depdelay&quot;) * (1.00654356566678)) Run the prediction inside dplyr table_flights %&gt;% filter(month == 2, dayofmonth == 1) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select( season, depdelay) %&gt;% tidypredict_to_column(model_lm) %&gt;% head() ## # Source: lazy query [?? x 3] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## season depdelay fit ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Winter 19.0 18.6 ## 2 Winter 0 - 0.544 ## 3 Winter - 5.00 - 5.58 ## 4 Winter - 9.00 - 9.60 ## 5 Winter - 6.00 - 6.58 ## 6 Winter 50.0 49.8 View the SQL behind the dplyr command table_flights %&gt;% filter(month == 2, dayofmonth == 1) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% select( season, depdelay) %&gt;% tidypredict_to_column(model_lm) %&gt;% remote_query() ## &lt;SQL&gt; SELECT &quot;season&quot;, &quot;depdelay&quot;, ((((-3.65284013396606) + ((CASE WHEN ((&quot;season&quot;) = (&#39;Spring&#39;)) THEN (1.0) WHEN NOT((&quot;season&quot;) = (&#39;Spring&#39;)) THEN (0.0) END) * (1.79817516392108))) + ((CASE WHEN ((&quot;season&quot;) = (&#39;Summmer&#39;)) THEN (1.0) WHEN NOT((&quot;season&quot;) = (&#39;Summmer&#39;)) THEN (0.0) END) * (2.35342251313206))) + ((CASE WHEN ((&quot;season&quot;) = (&#39;Winter&#39;)) THEN (1.0) WHEN NOT((&quot;season&quot;) = (&#39;Winter&#39;)) THEN (0.0) END) * (3.10900007425407))) + ((&quot;depdelay&quot;) * (1.00654356566678)) AS &quot;fit&quot; ## FROM (SELECT &quot;season&quot;, &quot;depdelay&quot; ## FROM (SELECT &quot;year&quot;, &quot;month&quot;, &quot;dayofmonth&quot;, &quot;dayofweek&quot;, &quot;deptime&quot;, &quot;crsdeptime&quot;, &quot;arrtime&quot;, &quot;crsarrtime&quot;, &quot;uniquecarrier&quot;, &quot;flightnum&quot;, &quot;tailnum&quot;, &quot;actualelapsedtime&quot;, &quot;crselapsedtime&quot;, &quot;airtime&quot;, &quot;arrdelay&quot;, &quot;depdelay&quot;, &quot;origin&quot;, &quot;dest&quot;, &quot;distance&quot;, &quot;taxiin&quot;, &quot;taxiout&quot;, &quot;cancelled&quot;, &quot;cancellationcode&quot;, &quot;diverted&quot;, &quot;carrierdelay&quot;, &quot;weatherdelay&quot;, &quot;nasdelay&quot;, &quot;securitydelay&quot;, &quot;lateaircraftdelay&quot;, &quot;flightid&quot;, CASE ## WHEN (&quot;month&quot; &gt;= 3.0 AND &quot;month&quot; &lt;= 5.0) THEN (&#39;Spring&#39;) ## WHEN (&quot;month&quot; &gt;= 6.0 AND &quot;month&quot; &lt;= 8.0) THEN (&#39;Summmer&#39;) ## WHEN (&quot;month&quot; &gt;= 9.0 AND &quot;month&quot; &lt;= 11.0) THEN (&#39;Fall&#39;) ## WHEN (&quot;month&quot; = 12.0 OR &quot;month&quot; &lt;= 2.0) THEN (&#39;Winter&#39;) ## END AS &quot;season&quot; ## FROM (SELECT * ## FROM datawarehouse.flight ## WHERE ((&quot;month&quot; = 2.0) AND (&quot;dayofmonth&quot; = 1.0))) &quot;rdmsrldtdf&quot;) &quot;xsktnwfckl&quot;) &quot;pifkbjpiqq&quot; Compare predictions to ensure results are within range test &lt;- tidypredict_test(model_lm) test ## tidypredict test results ## Difference threshold: 1e-12 ## ## All results are within the difference threshold View the records that exceeded the threshold test$raw_results %&gt;% filter(fit_threshold) ## [1] rowid fit fit_te fit_diff fit_threshold ## &lt;0 rows&gt; (or 0-length row.names) 5.6 Parsed model Quick review of the model parser Use the parse_model() function to see how tidypredict interprets the model pm &lt;- parse_model(model_lm) pm ## # A tibble: 10 x 11 ## labels estimate type field_1 field_2 qr_1 qr_2 qr_3 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercep… - 3.65 term &lt;NA&gt; &lt;NA&gt; - 0.0118 - 0.00680 - 0.00962 ## 2 seasonSpr… 1.80 term &lt;NA&gt; Spring 0 0.0272 0.00962 ## 3 seasonSum… 2.35 term &lt;NA&gt; Summmer 0 0 0.0289 ## 4 seasonWin… 3.11 term &lt;NA&gt; Winter 0 0 0 ## 5 depdelay 1.01 term {{:}} &lt;NA&gt; 0 0 0 ## 6 labels 0 varia… depdel… season NA NA NA ## 7 model NA varia… &lt;NA&gt; &lt;NA&gt; NA NA NA ## 8 version NA varia… &lt;NA&gt; &lt;NA&gt; NA NA NA ## 9 residual NA varia… &lt;NA&gt; &lt;NA&gt; NA NA NA ## 10 sigma2 NA varia… &lt;NA&gt; &lt;NA&gt; NA NA NA ## # ... with 3 more variables: qr_4 &lt;dbl&gt;, qr_5 &lt;dbl&gt;, vals &lt;chr&gt; Verify that the resulting table can be used to get the fit formula tidypredict_fit(pm) ## ((((-3.65284013396606) + ((ifelse((season) == (&quot;Spring&quot;), 1, ## 0)) * (1.79817516392108))) + ((ifelse((season) == (&quot;Summmer&quot;), ## 1, 0)) * (2.35342251313206))) + ((ifelse((season) == (&quot;Winter&quot;), ## 1, 0)) * (3.10900007425407))) + ((depdelay) * (1.00654356566678)) Save the parsed model for later use library(readr) write_csv(pm, &quot;parsedmodel.csv&quot;) Disconnect from the database dbDisconnect(con) "],
["intro-to-sparklyr.html", "6 Intro to sparklyr 6.1 New Spark session 6.2 Data transfer 6.3 Simple dplyr example 6.4 Map data 6.5 Caching data 6.6 sdf Functions 6.7 Feature transformers 6.8 Fit a model with sparklyr 6.9 Run predictions in Spark", " 6 Intro to sparklyr 6.1 New Spark session Learn to open a new Spark session Use spark_connect() to create a new local Spark session sc &lt;- spark_connect(master = &quot;local&quot;, version = &quot;2.0.0&quot;) Click on the SparkUI button to view the current Spark session’s UI Click on the Log button to see the message history 6.2 Data transfer Practice uploading data to Spark Copy the mtcars dataset into the session spark_mtcars &lt;- sdf_copy_to(sc, mtcars, &quot;my_mtcars&quot;) In the Connections pane, expande the my_mtcars table Go to the Spark UI, note the new jobs In the UI, click the Storage button, note the new table Click on the In-memory table my_mtcars link 6.3 Simple dplyr example See how Spark handles dplyr commands Run the following code snipett spark_mtcars %&gt;% group_by(am) %&gt;% summarise(avg_wt = mean(wt, na.rm = TRUE)) ## # Source: lazy query [?? x 2] ## # Database: spark_connection ## am avg_wt ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 3.77 ## 2 1.00 2.41 Go to the Spark UI and click the SQL button Click on the top item inside the Completed Queries table At the bottom of the diagram, expand Details 6.4 Map data See the machanics of how Spark is able to use files as a data source Examine the contents of the /usr/share/flights/data folder Read the top 5 rows of the flight_2008_1 CSV file. It is located under /usr/share/flights library(readr) top_rows &lt;- read.csv(&quot;/usr/share/flights/data/flight_2008_1.csv&quot;, nrows = 5) Create a list based on the column names, and add a list item with “character” as its value. library(purrr) file_columns &lt;- top_rows %&gt;% rename_all(tolower) %&gt;% map(function(x) &quot;character&quot;) head(file_columns) ## $year ## [1] &quot;character&quot; ## ## $month ## [1] &quot;character&quot; ## ## $dayofmonth ## [1] &quot;character&quot; ## ## $dayofweek ## [1] &quot;character&quot; ## ## $deptime ## [1] &quot;character&quot; ## ## $crsdeptime ## [1] &quot;character&quot; Use spark_read() to “map” the file’s structure and location to the Spark context spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/flights/data/&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) In the Connections pane, click on the table icon by the flights variable Verify that the new variable pointer work using tally() spark_flights %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: spark_connection ## n ## &lt;dbl&gt; ## 1 7009728 6.5 Caching data Learn how to cache a subset of the data in Spark Create a subset of the flights table object cached_flights &lt;- spark_flights %&gt;% mutate( arrdelay = ifelse(arrdelay == &quot;NA&quot;, 0, arrdelay), depdelay = ifelse(depdelay == &quot;NA&quot;, 0, depdelay) ) %&gt;% select( month, dayofmonth, arrtime, arrdelay, depdelay, crsarrtime, crsdeptime, distance ) %&gt;% mutate_all(as.numeric) Use compute() to extract the data into Spark memory cached_flights &lt;- compute(cached_flights, &quot;sub_flights&quot;) Confirm new variable pointer works cached_flights %&gt;% tally() ## # Source: lazy query [?? x 1] ## # Database: spark_connection ## n ## &lt;dbl&gt; ## 1 7009728 6.6 sdf Functions Overview of a few sdf_ functions: http://spark.rstudio.com/reference/#section-spark-dataframes Use sdf_pivot to create a column for each value in month cached_flights %&gt;% arrange(month) %&gt;% sdf_pivot(month ~ dayofmonth) ## # Source: table&lt;sparklyr_tmp_79d710c4023&gt; [?? x 32] ## # Database: spark_connection ## month `1.0` `2.0` `3.0` `4.0` `5.0` `6.0` `7.0` `8.0` `9.0` `10.0` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 2 2.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 3 3.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 4 4.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 5 5.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 6 6.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 7 7.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 8 8.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 9 9.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## 10 10.0 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.0 ## # ... with more rows, and 21 more variables: `11.0` &lt;dbl&gt;, `12.0` &lt;dbl&gt;, ## # `13.0` &lt;dbl&gt;, `14.0` &lt;dbl&gt;, `15.0` &lt;dbl&gt;, `16.0` &lt;dbl&gt;, `17.0` &lt;dbl&gt;, ## # `18.0` &lt;dbl&gt;, `19.0` &lt;dbl&gt;, `20.0` &lt;dbl&gt;, `21.0` &lt;dbl&gt;, `22.0` &lt;dbl&gt;, ## # `23.0` &lt;dbl&gt;, `24.0` &lt;dbl&gt;, `25.0` &lt;dbl&gt;, `26.0` &lt;dbl&gt;, `27.0` &lt;dbl&gt;, ## # `28.0` &lt;dbl&gt;, `29.0` &lt;dbl&gt;, `30.0` &lt;dbl&gt;, `31.0` &lt;dbl&gt; Use sdf_partition() to sepparate the data into discrete groups partition &lt;- cached_flights %&gt;% sdf_partition(training = 0.01, testing = 0.09, other = 0.9) tally(partition$training) ## # Source: lazy query [?? x 1] ## # Database: spark_connection ## n ## &lt;dbl&gt; ## 1 70508 6.7 Feature transformers See how to use Spark’s feature transformers: http://spark.rstudio.com/reference/#section-spark-feature-transformers Use ft_binarizer() to identify “delayed” flights cached_flights %&gt;% ft_binarizer( input.col = &quot;depdelay&quot;, output.col = &quot;delayed&quot;, threshold = 15 ) %&gt;% select( depdelay, delayed ) %&gt;% head(100) ## # Source: lazy query [?? x 2] ## # Database: spark_connection ## depdelay delayed ## &lt;dbl&gt; &lt;dbl&gt; ## 1 - 4.00 0 ## 2 - 1.00 0 ## 3 15.0 0 ## 4 - 2.00 0 ## 5 2.00 0 ## 6 - 4.00 0 ## 7 19.0 1.00 ## 8 1.00 0 ## 9 0 0 ## 10 - 3.00 0 ## # ... with more rows Use ft_bucketizer() to split the data into groups cached_flights %&gt;% ft_bucketizer( input.col = &quot;crsdeptime&quot;, output.col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% select( crsdeptime, dephour ) %&gt;% head(100) ## # Source: lazy query [?? x 2] ## # Database: spark_connection ## crsdeptime dephour ## &lt;dbl&gt; &lt;dbl&gt; ## 1 910 2.00 ## 2 835 2.00 ## 3 1555 3.00 ## 4 730 1.00 ## 5 2045 5.00 ## 6 1135 2.00 ## 7 1310 3.00 ## 8 1220 3.00 ## 9 1515 3.00 ## 10 630 1.00 ## # ... with more rows 6.8 Fit a model with sparklyr Build on the recently learned transformation techniques to feed data into a model Combine the ft_ and sdf_ functions to prepare the da sample_data &lt;- cached_flights %&gt;% filter(!is.na(arrdelay)) %&gt;% ft_binarizer( input.col = &quot;arrdelay&quot;, output.col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input.col = &quot;crsdeptime&quot;, output.col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% mutate(dephour = paste0(&quot;h&quot;, as.integer(dephour))) %&gt;% sdf_partition(training = 0.01, testing = 0.09, other = 0.9) Cache the training data training &lt;- sdf_register(sample_data$training, &quot;training&quot;) tbl_cache(sc, &quot;training&quot;) Run a logistic regression model in Spark delayed_model &lt;- training %&gt;% ml_logistic_regression(delayed ~ depdelay + dephour) View the model results summary(delayed_model) ## Call: ml_logistic_regression.tbl_spark(., delayed ~ depdelay + dephour) ## ## Coefficients: ## (Intercept) depdelay dephour_h2 dephour_h4 dephour_h3 dephour_h1 ## -3.1825324 0.1370932 0.5944019 0.5064744 0.4882511 0.6989113 ## dephour_h5 ## 0.4356597 6.9 Run predictions in Spark Quick review of running predictions and reviewing accuracy Use sdf_predict() agains the test dataset delayed_testing &lt;- sdf_predict(delayed_model, sample_data$testing) delayed_testing %&gt;% head() ## # Source: lazy query [?? x 19] ## # Database: spark_connection ## month dayofmonth arrtime arrdelay depdelay crsarrtime crsdeptime ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3.00 1.00 0 0 0 742 600 ## 2 3.00 1.00 0 0 0 812 630 ## 3 3.00 1.00 0 0 0 916 630 ## 4 3.00 1.00 0 0 0 921 640 ## 5 3.00 1.00 0 0 0 1115 915 ## 6 3.00 1.00 0 0 0 1342 1145 ## # ... with 12 more variables: distance &lt;dbl&gt;, delayed &lt;dbl&gt;, ## # dephour &lt;chr&gt;, features &lt;list&gt;, label79d75b902957 &lt;dbl&gt;, label &lt;dbl&gt;, ## # rawPrediction &lt;list&gt;, probability &lt;list&gt;, prediction &lt;dbl&gt;, ## # predicted_label &lt;chr&gt;, probability_0_0 &lt;dbl&gt;, probability_1_0 &lt;dbl&gt; Use group_by() to see how effective the new model is delayed_testing %&gt;% group_by(delayed, prediction) %&gt;% tally() ## # Source: lazy query [?? x 3] ## # Database: spark_connection ## # Groups: delayed ## delayed prediction n ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 1.00 10553 ## 2 0 0 488041 ## 3 1.00 0 40952 ## 4 1.00 1.00 90773 "],
["distributed-r.html", "7 Distributed R 7.1 Basic distribution 7.2 Use group_by 7.3 Distributing packages", " 7 Distributed R 7.1 Basic distribution Use spark_apply() to to view the partition row size Cache a sample of fligths flights_sample &lt;- spark_flights %&gt;% sample_frac(0.01) %&gt;% mutate(arrdelay = as.numeric(arrdelay)) %&gt;% ft_binarizer( input.col = &quot;arrdelay&quot;, output.col = &quot;delayed&quot;, threshold = 15 ) %&gt;% compute(&quot;flights_sample&quot;) Navigate to the Storage page in the Spark UI Pass nrow to spark_apply() to get the row count by partition spark_apply(flights_sample, nrow) ## # Source: table&lt;sparklyr_tmp_79d74dc4ac4d&gt; [?? x 1] ## # Database: spark_connection ## year ## &lt;int&gt; ## 1 12511 ## 2 12216 ## 3 12227 ## 4 11755 ## 5 10927 ## 6 10464 Pass a function to operate the average distance in each partition spark_apply( flights_sample, function(x) mean(as.numeric(x$distance)) ) ## # Source: table&lt;sparklyr_tmp_79d72d968eba&gt; [?? x 1] ## # Database: spark_connection ## year ## &lt;dbl&gt; ## 1 644 ## 2 634 ## 3 635 ## 4 629 ## 5 601 ## 6 602 7.2 Use group_by Pass a grouping field to be used instead of partitions Use the group_by argument to partition by the month field spark_apply(flights_sample, nrow, group_by = &quot;month&quot;, columns = &quot;count&quot;) ## # Source: table&lt;sparklyr_tmp_79d74f0a9219&gt; [?? x 2] ## # Database: spark_connection ## month count ## &lt;chr&gt; &lt;int&gt; ## 1 6 6135 ## 2 7 6253 ## 3 1 6078 ## 4 10 5617 ## 5 8 6081 ## 6 2 5707 ## 7 11 5111 ## 8 9 5353 ## 9 3 6258 ## 10 12 5310 ## # ... with more rows Pass the same function from the previous exercise to calculate the average distance by month spark_apply( flights_sample, function(x) mean(as.numeric(x$distance)), group_by = &quot;month&quot;, columns = &quot;avg_distance&quot; ) ## # Source: table&lt;sparklyr_tmp_79d7110f3c61&gt; [?? x 2] ## # Database: spark_connection ## month avg_distance ## &lt;chr&gt; &lt;dbl&gt; ## 1 6 564 ## 2 7 588 ## 3 1 549 ## 4 10 523 ## 5 8 562 ## 6 2 553 ## 7 11 528 ## 8 9 537 ## 9 3 560 ## 10 12 537 ## # ... with more rows 7.3 Distributing packages Use non-base-R packages to run the code in Spark Use broom::tidy() to run one glm() model per month models &lt;- spark_apply( flights_sample, function(e) broom::tidy(glm(delayed ~ arrdelay, data = e, family = &quot;binomial&quot;)), names = c(&quot;term&quot;, &quot;estimate&quot;, &quot;std_error&quot;, &quot;statistic&quot;, &quot;p_value&quot;), group_by = &quot;month&quot; ) models ## # Source: table&lt;sparklyr_tmp_79d77d249d54&gt; [?? x 6] ## # Database: spark_connection ## month term estimate std_error statistic p_value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6 (Intercept) -494 5190 -0.0953 0.924 ## 2 6 arrdelay 31.9 335 0.0952 0.924 ## 3 7 (Intercept) -484 4828 -0.100 0.920 ## 4 7 arrdelay 31.2 311 0.100 0.920 ## 5 1 (Intercept) -499 5378 -0.0928 0.926 ## 6 1 arrdelay 32.2 347 0.0928 0.926 ## 7 10 (Intercept) -500 6676 -0.0749 0.940 ## 8 10 arrdelay 32.2 431 0.0748 0.940 ## 9 8 (Intercept) -480 5342 -0.0898 0.928 ## 10 8 arrdelay 31.0 345 0.0897 0.929 ## # ... with more rows Close Spark connection spark_disconnect(sc) "],
["spark-pipelines.html", "8 Spark pipelines 8.1 Recreate the transformations 8.2 Fit, evaluate, save 8.3 Reload model 8.4 Reload pipeline", " 8 Spark pipelines 8.1 Recreate the transformations Overview of how most of the existing code will be reused Register a new table called current containing a sample of the base flights table model_data &lt;- sdf_partition( tbl(sc, &quot;flights&quot;), training = 0.01, testing = 0.01, rest = 0.98 ) Recreate the dplyr code in the cached_flights variable from the previous unit pipeline_df &lt;- model_data$training %&gt;% mutate( arrdelay = ifelse(arrdelay == &quot;NA&quot;, 0, arrdelay), depdelay = ifelse(depdelay == &quot;NA&quot;, 0, depdelay) ) %&gt;% select( month, dayofmonth, arrtime, arrdelay, depdelay, crsarrtime, crsdeptime, distance ) %&gt;% mutate_all(as.numeric) Create a new Spark pipeline flights_pipeline &lt;- ml_pipeline(sc) %&gt;% ft_dplyr_transformer( tbl = pipeline_df ) %&gt;% ft_binarizer( input_col = &quot;arrdelay&quot;, output_col = &quot;delayed&quot;, threshold = 15 ) %&gt;% ft_bucketizer( input_col = &quot;crsdeptime&quot;, output_col = &quot;dephour&quot;, splits = c(0, 400, 800, 1200, 1600, 2000, 2400) ) %&gt;% ft_r_formula(delayed ~ arrdelay + dephour) %&gt;% ml_logistic_regression() flights_pipeline ## Pipeline (Estimator) with 5 stages ## &lt;pipeline_79d74ce9299&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_79d77aa3744&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_79d7b77e15d&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_79d71c3c9139&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormula (Estimator) ## | &lt;r_formula_79d74e641f39&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Parameters) ## | formula: delayed ~ arrdelay + dephour ## |--5 LogisticRegression (Estimator) ## | &lt;logistic_regression_79d77cec2a0c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Parameters) ## | elastic_net_param: 0 ## | fit_intercept: TRUE ## | max_iter: 100 ## | reg_param: 0 ## | standardization: TRUE ## | threshold: 0.5 ## | tol: 1e-06 8.2 Fit, evaluate, save Fit (train) the pipeline’s model model &lt;- ml_fit(flights_pipeline, model_data$training) model ## PipelineModel (Transformer) with 5 stages ## &lt;pipeline_79d74ce9299&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_79d77aa3744&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_79d7b77e15d&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_79d71c3c9139&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormulaModel (Transformer) ## | &lt;r_formula_79d74e641f39&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Transformer Info) ## | formula: chr &quot;delayed ~ arrdelay + dephour&quot; ## |--5 LogisticRegressionModel (Transformer) ## | &lt;logistic_regression_79d77cec2a0c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Transformer Info) ## | coefficients: num [1:2] 26.892 0.448 ## | intercept: num -418 ## | num_classes: int 2 ## | num_features: int 2 ## | threshold: num 0.5 Use the newly fitted model to perform predictions using ml_transform() predictions &lt;- ml_transform( x = model, dataset = model_data$testing ) Use group_by() to see how the model performed predictions %&gt;% group_by(delayed, prediction) %&gt;% tally() ## # Source: lazy query [?? x 3] ## # Database: spark_connection ## # Groups: delayed ## delayed prediction n ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 55152 ## 2 1.00 1.00 14858 Save the model into disk using ml_save() ml_save(model, &quot;saved_model&quot;, overwrite = TRUE) ## NULL list.files(&quot;saved_model&quot;) ## [1] &quot;metadata&quot; &quot;stages&quot; Save the pipeline using ml_save() ml_save(flights_pipeline, &quot;saved_pipeline&quot;, overwrite = TRUE) ## NULL list.files(&quot;saved_pipeline&quot;) ## [1] &quot;metadata&quot; &quot;stages&quot; Close the Spark session spark_disconnect(sc) 8.3 Reload model Use the saved model inside a different Spark session Open a new Spark connection and reload the data library(sparklyr) sc &lt;- spark_connect(master = &quot;local&quot;, version = &quot;2.0.0&quot;) spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/flights/flights_2008.csv&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) Use ml_load() to reload the model directly into the Spark session reload &lt;- ml_load(sc, &quot;saved_model&quot;) reload ## PipelineModel (Transformer) with 5 stages ## &lt;pipeline_79d74ce9299&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_79d77aa3744&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_79d7b77e15d&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_79d71c3c9139&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormulaModel (Transformer) ## | &lt;r_formula_79d74e641f39&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## |--5 LogisticRegressionModel (Transformer) ## | &lt;logistic_regression_79d77cec2a0c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Transformer Info) ## | coefficients: num [1:2] 26.892 0.448 ## | intercept: num -418 ## | num_classes: int 2 ## | num_features: int 2 ## | threshold: num 0.5 Create a new table called current. It needs to pull today’s flights library(lubridate) current &lt;- tbl(sc, &quot;flights&quot;) %&gt;% filter( month == !! month(now()), dayofmonth == !! day(now()) ) show_query(current) ## &lt;SQL&gt; ## SELECT * ## FROM `flights` ## WHERE ((`month` = 1.0) AND (`dayofmonth` = 26)) Create a new table called current. It needs to pull today’s flights head(current) ## # Source: lazy query [?? x 29] ## # Database: spark_connection ## year month dayofmonth dayofweek deptime crsdeptime arrtime crsarrtime ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2008 1 26 6 1945 1950 2139 2145 ## 2 2008 1 26 6 854 900 1408 1435 ## 3 2008 1 26 6 1728 1735 1948 2010 ## 4 2008 1 26 6 1507 1510 1724 1745 ## 5 2008 1 26 6 918 920 1141 1155 ## 6 2008 1 26 6 640 645 751 810 ## # ... with 21 more variables: uniquecarrier &lt;chr&gt;, flightnum &lt;chr&gt;, ## # tailnum &lt;chr&gt;, actualelapsedtime &lt;chr&gt;, crselapsedtime &lt;chr&gt;, ## # airtime &lt;chr&gt;, arrdelay &lt;chr&gt;, depdelay &lt;chr&gt;, origin &lt;chr&gt;, ## # dest &lt;chr&gt;, distance &lt;chr&gt;, taxiin &lt;chr&gt;, taxiout &lt;chr&gt;, ## # cancelled &lt;chr&gt;, cancellationcode &lt;chr&gt;, diverted &lt;chr&gt;, ## # carrierdelay &lt;chr&gt;, weatherdelay &lt;chr&gt;, nasdelay &lt;chr&gt;, ## # securitydelay &lt;chr&gt;, lateaircraftdelay &lt;chr&gt; Run predictions against the new data set new_predictions &lt;- ml_transform( x = reload, dataset = current ) Get a quick count of expected delayed flights new_predictions %&gt;% summarise(late_fligths = sum(prediction, na.rm = TRUE)) ## # Source: lazy query [?? x 1] ## # Database: spark_connection ## late_fligths ## &lt;dbl&gt; ## 1 3260 8.4 Reload pipeline Overview of how to use new data to re-fit the pipeline, thus creating a new pipeline model Use ml_load() to reload the pipeline into the Spark session pipeline &lt;- ml_load(sc, &quot;saved_pipeline&quot;) pipeline ## Pipeline (Estimator) with 5 stages ## &lt;pipeline_79d74ce9299&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_79d77aa3744&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_79d7b77e15d&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_79d71c3c9139&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormula (Estimator) ## | &lt;r_formula_79d74e641f39&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Parameters) ## | formula: delayed ~ arrdelay + dephour ## |--5 LogisticRegression (Estimator) ## | &lt;logistic_regression_79d77cec2a0c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Parameters) ## | elastic_net_param: 0 ## | fit_intercept: TRUE ## | max_iter: 100 ## | reg_param: 0 ## | standardization: TRUE ## | threshold: 0.5 ## | tol: 1e-06 Create a new sample data set using sample_frac() sample &lt;- tbl(sc, &quot;flights&quot;) %&gt;% sample_frac(0.001) Re-fit the model using ml_fit() and the new sample data new_model &lt;- ml_fit(pipeline, sample) new_model ## PipelineModel (Transformer) with 5 stages ## &lt;pipeline_79d74ce9299&gt; ## Stages ## |--1 SQLTransformer (Transformer) ## | &lt;dplyr_transformer_79d77aa3744&gt; ## | (Parameters -- Column Names) ## |--2 Binarizer (Transformer) ## | &lt;binarizer_79d7b77e15d&gt; ## | (Parameters -- Column Names) ## | input_col: arrdelay ## | output_col: delayed ## |--3 Bucketizer (Transformer) ## | &lt;bucketizer_79d71c3c9139&gt; ## | (Parameters -- Column Names) ## | input_col: crsdeptime ## | output_col: dephour ## |--4 RFormulaModel (Transformer) ## | &lt;r_formula_79d74e641f39&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | (Transformer Info) ## | formula: chr &quot;delayed ~ arrdelay + dephour&quot; ## |--5 LogisticRegressionModel (Transformer) ## | &lt;logistic_regression_79d77cec2a0c&gt; ## | (Parameters -- Column Names) ## | features_col: features ## | label_col: label ## | prediction_col: prediction ## | probability_col: probability ## | raw_prediction_col: rawPrediction ## | (Transformer Info) ## | coefficients: num [1:2] 25.2015 -0.0936 ## | intercept: num -390 ## | num_classes: int 2 ## | num_features: int 2 ## | threshold: num 0.5 Save the newly fitted model ml_save(new_model, &quot;new_model&quot;, overwrite = TRUE) ## NULL list.files(&quot;new_model&quot;) ## [1] &quot;metadata&quot; &quot;stages&quot; Disconnect from Spark spark_disconnect(sc) "],
["intro-to-dashboards.html", "9 Intro to dashboards 9.1 Basic structure 9.2 Dropdown data 9.3 Update dashboard items 9.4 Integrate the dropdown", " 9 Intro to dashboards 9.1 Basic structure Preview a simple shinydashboard Create and preview a simple shinydashboard ui &lt;- dashboardPage( dashboardHeader(title = &quot;Quick Example&quot;), dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, c(&quot;one&quot;, &quot;two&quot;))), dashboardBody( valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) ) server &lt;- function(input, output, session) { output$total &lt;- renderValueBox(valueBox(100, subtitle = &quot;Flights&quot;)) output$monthly &lt;- renderDataTable(datatable(mtcars)) } shinyApp(ui, server) 9.2 Dropdown data Review a technique to populate a dropdown Use purrr to create a list with the correct structure for the shiny drop down airline_list &lt;- carriers %&gt;% select(carrier, carriername) %&gt;% # In case more fields are added collect() %&gt;% # All would be collected anyway split(.$carriername) %&gt;% # Create a list item for each name map(~.$carrier) # Add the carrier code to each item head(airline_list) ## $`AirTran Airways Corporation` ## [1] &quot;FL&quot; ## ## $`Alaska Airlines Inc.` ## [1] &quot;AS&quot; ## ## $`Aloha Airlines Inc.` ## [1] &quot;AQ&quot; ## ## $`American Airlines Inc.` ## [1] &quot;AA&quot; ## ## $`American Eagle Airlines Inc.` ## [1] &quot;MQ&quot; ## ## $`Atlantic Southeast Airlines` ## [1] &quot;EV&quot; In the app code, replace c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;) with airline_list # Goes from this: dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, c(&quot;one&quot;, &quot;two&quot;))), # To this: dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, airline_list)), Re-run the app 9.3 Update dashboard items Create base query for the dashboard using dplyr and pass the results to the dashboard Save the base “query” to a variable. It will contain a carrier selection. To transition into shiny programming easier, the variable will be a function. base_dashboard &lt;- function(){ flights %&gt;% filter(uniquecarrier == &quot;DL&quot;) } head(base_dashboard()) ## # Source: lazy query [?? x 30] ## # Database: postgres [rstudio_dev@localhost:/postgres] ## year month dayofmonth dayofweek deptime crsdeptime arrtime crsarrtime ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 1.00 25.0 5.00 856 900 1723 1748 ## 2 2008 1.00 25.0 5.00 1652 1618 1956 1925 ## 3 2008 1.00 25.0 5.00 1709 1630 1835 1810 ## 4 2008 1.00 25.0 5.00 901 900 1550 1610 ## 5 2008 1.00 25.0 5.00 828 830 1349 1406 ## 6 2008 1.00 25.0 5.00 1935 1935 2049 2101 ## # ... with 22 more variables: uniquecarrier &lt;chr&gt;, flightnum &lt;dbl&gt;, ## # tailnum &lt;chr&gt;, actualelapsedtime &lt;dbl&gt;, crselapsedtime &lt;dbl&gt;, ## # airtime &lt;dbl&gt;, arrdelay &lt;dbl&gt;, depdelay &lt;dbl&gt;, origin &lt;chr&gt;, ## # dest &lt;chr&gt;, distance &lt;dbl&gt;, taxiin &lt;dbl&gt;, taxiout &lt;dbl&gt;, ## # cancelled &lt;dbl&gt;, cancellationcode &lt;chr&gt;, diverted &lt;dbl&gt;, ## # carrierdelay &lt;dbl&gt;, weatherdelay &lt;dbl&gt;, nasdelay &lt;dbl&gt;, ## # securitydelay &lt;dbl&gt;, lateaircraftdelay &lt;dbl&gt;, flightid &lt;int&gt; Use the base query to figure the number of flights for that carrier base_dashboard() %&gt;% tally() %&gt;% pull() ## integer64 ## [1] 451931 In the app, remove the 100 number and pipe the dplyr code into the valueBox() function # Goes from this: output$total &lt;- renderValueBox(valueBox(100, subtitle = &quot;Flights&quot;)) # To this: output$total &lt;- renderValueBox( base_dashboard() %&gt;% tally() %&gt;% pull() %&gt;% valueBox(subtitle = &quot;Flights&quot;)) Create a table with the month name and the number of flights for that month base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month) ## # A tibble: 12 x 2 ## month flights ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 38256 ## 2 2.00 36275 ## 3 3.00 39829 ## 4 4.00 37049 ## 5 5.00 36349 ## 6 6.00 37844 ## 7 7.00 39335 ## 8 8.00 38173 ## 9 9.00 36304 ## 10 10.0 38645 ## 11 11.0 36939 ## 12 12.0 36933 In the app, replace head(mtcars) with the piped code, and re-run the app # Goes from this: output$monthly &lt;- renderTable(head(mtcars)) # To this: output$monthly &lt;- renderDataTable(datatable( base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month))) 9.4 Integrate the dropdown Use shiny’s reactive() function to integrate the user input in one spot In the original base_dashboard() code, replace function with reactive, and &quot;DL&quot; with input$select # Goes from this base_dashboard &lt;- function(){ flights %&gt;% filter(uniquecarrier == &quot;DL&quot;)} # To this base_dashboard &lt;- reactive({ flights %&gt;% filter(uniquecarrier == input$select)}) Insert the new code right after the server &lt;- function(input, output, session) line. The full code should now look like this: ui &lt;- dashboardPage( dashboardHeader(title = &quot;Quick Example&quot;), dashboardSidebar(selectInput(&quot;select&quot;, &quot;Selection&quot;, airline_list)), dashboardBody( valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) ) server &lt;- function(input, output, session) { base_dashboard &lt;- reactive({ flights %&gt;% filter(uniquecarrier == input$select) }) output$total &lt;- renderValueBox( base_dashboard() %&gt;% tally() %&gt;% pull() %&gt;% valueBox(subtitle = &quot;Flights&quot;) ) output$monthly &lt;- renderDataTable(datatable( base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month) )) } shinyApp(ui, server) Re-run the app Disconnect form database dbDisconnect(con) "],
["dashboard-drill-down.html", "10 Dashboard drill-down 10.1 Add a tabset to the dashboard 10.2 Add interactivity 10.3 Add title to the new tab 10.4 pool pakcage", " 10 Dashboard drill-down 10.1 Add a tabset to the dashboard Prepare the ui to accept new tabs based on the user’s input Wrap the “output” functions in the ui with a tabPanel() # Goes from this valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) # To this tabPanel( valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) Set the panel’s title and value. The new code should look like this tabPanel( title = &quot;Dashboard&quot;, value = &quot;page1&quot;, valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) Wrap that code inside a tabsetPanel(), set the id to tabs tabsetPanel( id = &quot;tabs&quot;, tabPanel( title = &quot;Dashboard&quot;, value = &quot;page1&quot;, valueBoxOutput(&quot;total&quot;), dataTableOutput(&quot;monthly&quot;) ) ) Re-run the app 10.2 Add interactivity Add an click-event that creates a new tab Set the selection and rownames in the current datatable() function output$monthly &lt;- renderDataTable(datatable({ base_dashboard() %&gt;% group_by(month) %&gt;% tally() %&gt;% collect() %&gt;% mutate(n = as.numeric(n)) %&gt;% rename(flights = n) %&gt;% arrange(month)}, list( target = &quot;cell&quot;), # New code rownames = FALSE)) # New code Use observeEvent() and appendTab() to add the interactivity observeEvent(input$monthly_cell_clicked, { appendTab( inputId = &quot;tabs&quot;, # This is the tabsets panel&#39;s ID tabPanel( &quot;test_new&quot;, # This will be the label of the new tab renderDataTable(mtcars, rownames = FALSE) ) ) }) Re-run the app Click on a row inside the datatable and then select the new tab called test_new to see the mtcars data 10.3 Add title to the new tab Use the input’s info to create a custom label Load the clicked cell’s info into a variable, and create a new lable by concatenating the cell’s month and the selected airline’s code observeEvent(input$monthly_cell_clicked, { cell &lt;- input$monthly_cell_clicked # New code if (!is.null(cell$value)) { # New code tab_title &lt;- paste0(month.name[cell$value], &quot;_&quot;, input$select) appendTab( inputId = &quot;tabs&quot;, tabPanel( tab_title, # Changed code renderDataTable(mtcars, rownames = FALSE) ) ) } }) Re-run the app, and click on one of the month’s to confirm that the new label works Use updateTabsetPanel to switch the dashboard’s focus to the newly created tab. It goes after the tabPanel() code updateTabsetPanel(session, &quot;tabs&quot;, selected = tab_title) 10.4 pool pakcage Improve connectivity using the pool package 1.Change dbConnect() to dbPool() # Goes from this con &lt;- DBI::dbConnect(odbc::odbc(), &quot;Postgres Dev&quot;) # To this con &lt;- pool::dbPool(odbc::odbc(), dsn = &quot;Postgres Dev&quot;) Add an onStop() step to close the pool connection onStop(function() { poolClose(con) }) "],
["share-and-production.html", "11 Share and Production 11.1 Publish dashboard 11.2 Schedule scoring 11.3 Scheduled pipeline", " 11 Share and Production 11.1 Publish dashboard Use RStudio Connect to publish work internally in the enterprise Open the dashboard app.R file Click on File Click on Publish Connect Account click Next Select RStudio Connect Copy and paste your RStudio Server URL and add :3939 Enter your credentials Complete the form Click Proceed Click on Connect Click Publish 11.2 Schedule scoring Use the tidypredict model to score and write back to the database Create a new RMarkdown Copy the code from the excercise library(tidyverse) library(dbplyr) library(tidypredict) library(DBI) library(lubridate) dw &lt;- config::get(&quot;datawarehouse-dev&quot;) con &lt;- dbConnect( odbc::odbc(), Driver = dw$driver, Server = dw$server, UID = dw$uid, PWD = dw$pwd, Port = dw$port, Database = dw$database ) flights &lt;- tbl(con, in_schema(&quot;datawarehouse&quot;, &quot;flight&quot;)) # head(flights) parsedmodel &lt;- read_csv(&quot;parsedmodel.csv&quot;) predictions &lt;- flights %&gt;% filter( month == !! month(now()), dayofmonth == !! day(now()) ) %&gt;% mutate( season = case_when( month &gt;= 3 &amp; month &lt;= 5 ~ &quot;Spring&quot;, month &gt;= 6 &amp; month &lt;= 8 ~ &quot;Summmer&quot;, month &gt;= 9 &amp; month &lt;= 11 ~ &quot;Fall&quot;, month == 12 | month &lt;= 2 ~ &quot;Winter&quot; ) ) %&gt;% tidypredict_to_column(parsedmodel) %&gt;% select( pred_flightid = flightid, pred_fit = fit, check_score = nasdelay ) update_statement &lt;- build_sql( &quot;UPDATE datawarehouse.flight SET nasdelay = pred_fit FROM (&quot;, remote_query(predictions), &quot;) as p &quot;, &quot;WHERE pred_flightid = flightid&quot;, con = con ) dbSendQuery(con, update_statement) Click on File and then Publish Select Publish just this document Click Publish anyway on the warning In RStudio Connect, select Schedule Click on Schedule output for default Click on Run every weekday (Monday to Friday) Click Save 11.3 Scheduled pipeline See how to automate the pipeline model to run on a daily basis Create a new RMarkdown document Copy the code from the Reload Pipeline exercise into the new document Add the top_rows and file_columns code from the Intro to sparklyr section Move the saved_model folder under /tmp Change the ml_load() location to &quot;/tmp/saved_model&quot; library(tidyverse) library(lubridate) library(sparklyr) top_rows &lt;- read.csv(&quot;/usr/share/flights/data/flight_2008_1.csv&quot;, nrows = 5) file_columns &lt;- top_rows %&gt;% rename_all(tolower) %&gt;% map(function(x) &quot;character&quot;) sc &lt;- spark_connect(master = &quot;local&quot;, version = &quot;2.1.0&quot;) spark_flights &lt;- spark_read_csv( sc, name = &quot;flights&quot;, path = &quot;/usr/share/flights/flights_2008.csv&quot;, memory = FALSE, columns = file_columns, infer_schema = FALSE ) reload &lt;- ml_load(sc, &quot;/tmp/saved_model&quot;) current &lt;- tbl(sc, &quot;flights&quot;) %&gt;% filter( month == !! month(now()), dayofmonth == !! day(now()) ) new_predictions &lt;- ml_transform( x = reload, dataset = current ) new_predictions %&gt;% summarise(late_fligths = sum(prediction, na.rm = TRUE)) spark_disconnect(sc) Click on File and then Publish Select Publish just this document Click Publish anyway on the warning In RStudio Connect, select Schedule Click on Schedule output for default Click on Run every weekday (Monday to Friday) Click Save "]
]
